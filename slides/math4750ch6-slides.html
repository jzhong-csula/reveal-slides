<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>MATH 4750 - Introduction to Mathematical Statistics</title>
<meta name="author" content="\\
Jie Zhong \\
Department of Mathematics \\
California State University, Los Angeles"/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="../dist/reveal.css"/>

<link rel="stylesheet" href="../dist/theme/serif.css" id="theme"/>

<link rel="stylesheet" href="../reveal.js-plugins/chalkboard/style.css"/>

<link rel="stylesheet" href="../reveal.js-plugins/menu/font-awesome/css/fontawesome.css"/>

<link rel="stylesheet" href="../gnohz.css"/>
<script>window.MathJax = { TeX: {Macros: {range: "\\text{Range}", ow: "\\text{otherwise}"}} }</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide">
<h1>MATH 4750 - Introduction to Mathematical Statistics</h1><h2></h2><h6> <br />
Jie Zhong <br />
Department of Mathematics <br />
California State University, Los Angeles</h6>
</section>

<section>
<section id="slide-org35819c4">
<h2 id="org35819c4">Chapter 6 Large Random Samples</h2>
<div class="outline-text-2" id="text-org35819c4">
</div>
</section>
</section>
<section>
<section id="slide-orgcfd27be">
<h3 id="orgcfd27be">6.2 The Law of Large Numbers</h3>
<div class="outline-text-3" id="text-orgcfd27be">
</div>
</section>
</section>
<section>
<section id="slide-orgceff0d5">
<h4 id="orgceff0d5">Theorem 6.2.1 (Markov Inequality)</h4>
<p class="fragment">
Suppose that \(X\) is a random variable such that \(\mathbb{P}(X \ge 0) = 1\). Then for any \(t>0\),
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(X \ge t) \le \frac{\mathbb{E}(X)}{t}.
\end{align*}

</div>

<p class="fragment">
Proof. (continuous case)
</p>
<div class="fragment">
\begin{align*}
  \mathbb{E}(X) & = \int_0^{\infty} x f_X(x)\, dx = \int_0^t x f_X(x)\, dx + \int_t^{\infty} x f_X(x)\, dx\\
& \ge \int_t^{\infty} x f_X(x)\, dx \ge \int_t^{\infty} t f_X(x)\, dx\\
& = t \int_t^{\infty} f_X(x) \, dx = t \mathbb{P}(X \ge t),
\end{align*}

</div>
<p class="fragment">
which implies the desired inequality by dividing by \(t\).
</p>

</section>
</section>
<section>
<section id="slide-orgc2009d9">
<h4 id="orgc2009d9">Theorem 6.2.2 (Chebyshev Inequality)</h4>
<p class="fragment">
Let \(X\) be a random variable for which \(\text{Var}(X)\) exists. Then for any \(t>0\),
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(|X- \mathbb{E}(X)| \ge t) \le \frac{\text{Var} (X)}{t^2},
\end{align*}

</div>
<p class="fragment">
or equivalently,
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(|X- \mathbb{E}(X)| < t) > 1 - \frac{\text{Var} (X)}{t^2}.
\end{align*}

</div>

<p class="fragment">
<span style="color: rgb(24,116,205)">Question</span>: Can you provide an example of a random variable which does not have a variance?
</p>

</section>
</section>
<section>
<section id="slide-orgdbda1ea">
<h4 id="orgdbda1ea">Proof</h4>
<p class="fragment">
Let \(Y = (X - \mathbb{E}(X))^2\), then \(\mathbb{P}(Y \ge 0) = 1\).
</p>

<p class="fragment">
Furthermore, \(\mathbb{E}(Y) = \text{Var} (X)\).
</p>
<p class="fragment">
By the Markov inequality,
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(Y \ge t^2) & \le \frac{\mathbb{E}(Y)}{t^2} = \frac{\text{Var} (X)
}{t^2}.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orgb0fd99c">
<h4 id="orgb0fd99c">Special Case</h4>
<p class="fragment">
Choose \(t = 3 \sigma\), where \(\sigma = \sqrt{\text{Var} (X)}\).
</p>
<p class="fragment">
Then the Chebyshev inequality says
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(|X - \mu| \ge 3 \sigma) \le \frac{\text{Var} (X)}{9\sigma^2} = \frac{1}{9},
\end{align*}

</div>
<p class="fragment">
or equivalently,
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(|X - \mu| < 3 \sigma) >  \frac{8}{9} \approx 0.89\dots
\end{align*}

</div>

<p class="fragment">
At least \(89\%\) of the value in a set of values fall within \(3\) standard deviations of the mean.
</p>

</section>
</section>
<section>
<section id="slide-org9b84206">
<h4 id="org9b84206">Determine Sample Size (revisited)</h4>
<p class="fragment">
Recall that if \(X_1, X_2, \dots, X_n\) form a random sample (i.i.d.) with \(\mu = \mathbb{E}(X_1), \sigma^2 = \text{Var} (X_1)\), then
</p>
<div class="fragment">
\begin{align*}
  \overline{X}_n = \frac{\sum_{i=1}^n X_i}{n}
\end{align*}

</div>
<p class="fragment">
is called the sample mean and is a random variable.
</p>
<p class="fragment">
Moreover,
</p>
<div class="fragment">
\begin{align*}
  \mathbb{E}(\overline{X}_n) = \mu, \quad \text{Var} (\overline{X}_n) = \frac{\sigma^2}{n}.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orgfcdefef">
<h4 id="orgfcdefef">Example 6.2.1</h4>
<p>
Assume \(X_1, X_2, \dots, X_n\) form a random sample from an <b>unknown</b> distribution.
</p>
<p class="fragment">
The mean \(\mu\) is unknown, but the standard deviation \(\sigma \le 2\).
</p>
<p class="fragment">
Determine the minimum sample size \(n\) such that
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(|\overline{X}_n - \mu| < 1) \ge 0.99.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orgc442f78">
<h4 id="orgc442f78">Example 6.2.1 - Continued</h4>
<p class="fragment">
By Chebyshev inequality,
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(|\overline{X}_n - \mu | < 1) & \ge 1 - \frac{\text{Var}(\overline{X}_n)}{1^2} = 1 - \frac{\sigma^2}{n}\\
& \ge 1 - \frac{4}{n} \ge 0.99.
\end{align*}

</div>
<p class="fragment">
So we require
</p>
<div class="fragment">
\begin{align*}
  n \ge \frac{4}{0.01} = 400.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org934cc45">
<h4 id="org934cc45">The Law of Large Numbers (LLN)</h4>
<p>
<span style="color: rgb(24,116,205)">Theorem 6.2.4</span>
Suppose \(X_1, X_2, \dots, X_n\) form a random sample from a distribution for which the mean is \(\mu\) and the variance \(\sigma^2\) exists. Then
</p>
<div class="fragment">
\begin{align*}
  \overline{X}_n \xrightarrow{\mathbb{P}} \mu.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orgea6939f">
<h4 id="orgea6939f">Convergence in Probability</h4>
<p class="fragment">
Let \(Z_1, Z_2, \dots\) be a sequence of random variables. The sequence <i>converges to a number \(b\) in probability</i> if for every \(\varepsilon >0\),
</p>
<div class="fragment">
\begin{align*}
  \lim_{n\to \infty} \mathbb{P}(|Z_n - b| < \varepsilon) = 1.
\end{align*}

</div>

<p class="fragment">
Write \(Z_n \xrightarrow{\mathbb{P}} b\) as \(n\to \infty\).
</p>

</section>
</section>
<section>
<section id="slide-org63fce38">
<h4 id="org63fce38">Proof of LLN</h4>
<p class="fragment">
By the Chebyshev inequality,
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(|\overline{X}_n - \mu| \ge t) \le \frac{\text{Var} (\overline{X}_n)}{t^2} = \frac{\sigma^2}{nt^2}.
\end{align*}

</div>
<p class="fragment">
Choose \(t = \varepsilon\), then
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(|\overline{X}_n - \mu|< \varepsilon) & > 1 - \frac{\sigma^2}{n \varepsilon^2}\\
& \to 1 ~\text{as} ~n \to \infty.
\end{align*}

</div>
</section>
</section>
<section>
<section id="slide-org26280e7">
<h4 id="org26280e7">Continuous Functions of Random Variables</h4>
<p>
<span style="color: rgb(24,116,205)">Theorem 6.2.5</span>
</p>
<p class="fragment">
If \(Z_n \xrightarrow{\mathbb{P}} b\), and if \(g(z)\) is a function that is continuous at \(z = b\), then \(g(Z_n) \xrightarrow{\mathbb{P}} g(b)\).
</p>

<p class="fragment">
This result can be useful if we observe random variables with mean \(\mu\) but are interested in \(\mu^2\) or \(\log(u)\) or some other continuous function of \(\mu\).
</p>


</section>
</section>
<section>
<section id="slide-org429e730">
<h3 id="org429e730">6.3 The Central Limit Theorem (CLT)</h3>
<div class="outline-text-3" id="text-org429e730">
</div>
</section>
</section>
<section>
<section id="slide-org7881cb3">
<h4 id="org7881cb3">Theorem 6.3.1 (CLT for sample mean)</h4>
<p class="fragment">
Let \(X_1, X_2, \dots, X_n\) be a random sample from a given distribution with <b>finite</b> mean \(\mu\) and variance \(\sigma^2\), then for each fixed number \(x\),
</p>
<div class="fragment">
\begin{align*}
  \lim_{n\to \infty} \mathbb{P} \left( \frac{\overline{X}_n-\mu}{\sigma/\sqrt{n}} \le x \right) = \Phi(x).
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org6770057">
<h4 id="org6770057">Example 6.3.2</h4>
<p>
Toss a fair coin \(900\) times.
</p>
<p class="fragment">
Compute the probability of obtaining more than \(495\) heads.
</p>

<p class="fragment">
Let
</p>
<div class="fragment">
\begin{align*}
  X = ~\text{number of heads} \sim \text{Bin} (900, 1/2).
\end{align*}

</div>
<p class="fragment">
Then
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(X > 495)
& = \sum_{k=496}^{900} \binom{900}{k} \left(  \frac{1}{2}\right)^{k} \left( \frac{1}{2} \right)^{900-k}\\
& = \sum_{k=496}^{900} \binom{900}{k} \left(  \frac{1}{2}\right)^{900} = ?
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org10147ac">
<h4 id="org10147ac">Example 6.3.2 - Continued</h4>
<p>
However,
</p>
<div>
\begin{align*}
  X & = X_1 + X_2 + \cdots + X_n, \quad X_i \sim \text{Ber} (1/2)\\
  \overline{X}_n & = \frac{X}{n}, \quad n = 900.
\end{align*}

</div>
<p class="fragment">
By CLT,
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(X > 495)
& = \mathbb{P}(\overline{X}_n > 495/900)\\
& = \mathbb{P}\left( \frac{\overline{X}_n - 1/2}{\frac{1}{2}/30} > \frac{495/900 - 1/2}{\frac{1}{2}/30} \right)\\
& \approx \mathbb{P}(Z > 3) = 1 - \Phi(3) = 0.0013.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orgf622b18">
<h4 id="orgf622b18">Theorem 6.3.3 (CLT for the sum of independent r.v.)</h4>
<p>
Let \(X_1, X_2, \dots, X_n\) be independent random variables. Assume \(\mu_i = \mathbb{E}(X_i)\), \(\sigma_i^2 = \text{Var} (X_i)\), \(\mathbb{E}(|X_i - \mu_i|^3) < \infty\), for each \(1 \le i \le n\), and
</p>
<div class="fragment">
\begin{align}
\tag{6.3.9}
\label{eq:6.3.9}
  \lim_{n\to \infty} \frac{\sum_{i=1}^n \mathbb{E}(|X_i-\mu_i|^3)}{\left( \sum_{i=1}^n \sigma_i^2 \right)^{3/2}} = 0,
\end{align}

</div>
<p class="fragment">
then
</p>
<div class="fragment">
\begin{align*}
  \lim_{n\to\infty} \mathbb{P}(Y_n \le x) = \Phi(x),
\end{align*}

</div>
<p class="fragment">
where
</p>
<div class="fragment">
\begin{align*}
  Y_n = \frac{\sum_{i=1}^n X_i - \sum_{i=1}^n \mu_i}{\left( \sum_{i=1}^n \sigma_i^2 \right)^{1/2}}.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orge1af2d0">
<h4 id="orge1af2d0">Remark</h4>
<p class="fragment">
When additionally \(X_1, X_2, \dots, X_n\) are identically distribution, the Eq.\eqref{eq:6.3.9} will automatically be satisfied.
</p>
<p class="fragment">
In fact,
</p>
<div class="fragment">
\begin{align*}
  \frac{\sum_{i=1}^n \mathbb{E}(|X_i-\mu_i|^3)}{\left( \sum_{i=1}^n \sigma_i^2 \right)^{3/2}}
&  = \frac{\sum_{i=1}^n \mathbb{E}(|X_1-\mu|^3)}{\left( n \sigma^2 \right)^{3/2}}\\
&  = \frac{n \mathbb{E}(|X_1-\mu|^3)}{\left( n^{3/2}\sigma^3 \right)} \xrightarrow{n\to\infty} 0.
\end{align*}

</div>
</section>
</section>
<section>
<section id="slide-orgbef8901">
<h4 id="orgbef8901">Theorem 6.3.4 (CLT for Bernoulli random variables)</h4>
<p class="fragment">
Let \(X_1, X_2, \dots, X_n\) be independent random variables, and \(X_i \sim \text{Ber}(p_i), 1 \le i \le n\).
Assume \(\sum_{i=1}^\infty p_i(1- p_i)\) diverges, then
</p>
<div class="fragment">
\begin{align*}
  \lim_{n\to\infty}\mathbb{P}(Y_n \le x) = \Phi(x),
\end{align*}

</div>
<p class="fragment">
where
</p>
<div class="fragment">
\begin{align*}
  Y_n = \frac{\sum_{i=1}^n X_i- \sum_{i=1}^n \mu_i}{\left( \sum_{i=1}^n p_i(1-p_i) \right)^{1/2}}.
\end{align*}

</div>
</section>
</section>
</div>
</div>
<script src="../dist/reveal.js"></script>
<script src="../plugin/markdown/markdown.js"></script>
<script src="../plugin/notes/notes.js"></script>
<script src="../plugin/search/search.js"></script>
<script src="../plugin/zoom/zoom.js"></script>
<script src="../plugin/reveal.js-menu/menu.js"></script>
<script src="../reveal.js-plugins/chalkboard/plugin.js"></script>
<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

controls: true,
progress: true,
history: false,
center: true,
slideNumber: false,
rollingLinks: false,
keyboard: true,
mouseWheel: false,
fragmentInURL: false,
hashOneBasedIndex: false,
pdfSeparateFragments: true,
overview: true,

transition: 'none',
transitionSpeed: 'default',

// Plugins with reveal.js 4.x
plugins: [ RevealMarkdown, RevealNotes, RevealSearch, RevealZoom, RevealMenu, RevealChalkboard ],

// Optional libraries used to extend reveal.js
dependencies: [
]

,chalkboard: {src: "chalkboard/chalkboard.json", storage: "chalkboard-demo", toggleChalkboardButton: { left: "80px" },	toggleNotesButton: { left: "130px" },	colorButtons: 5}});
</script>
</body>
</html>

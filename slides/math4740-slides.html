<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>MATH 4740 - Theory of Probability</title>
<meta name="author" content="\\
Jie Zhong \\
Department of Mathematics \\
California State University, Los Angeles"/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="../dist/reveal.css"/>

<link rel="stylesheet" href="../dist/theme/serif.css" id="theme"/>

<link rel="stylesheet" href="../reveal.js-plugins/chalkboard/style.css"/>

<link rel="stylesheet" href="../reveal.js-plugins/menu/font-awesome/css/fontawesome.css"/>

<link rel="stylesheet" href="../gnohz.css"/>
<script>window.MathJax = { TeX: {Macros: {range: "\\text{Range}"}} }</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide">
<h1>MATH 4740 - Theory of Probability</h1><h2></h2><h6> <br />
Jie Zhong <br />
Department of Mathematics <br />
California State University, Los Angeles</h6>
</section>

<section>
<section id="slide-org23401f6">
<h2 id="org23401f6">Chapter 1 - Introduction to Probability</h2>
<div class="outline-text-2" id="text-org23401f6">
</div>
</section>
</section>
<section>
<section id="slide-org624516b">
<h3 id="org624516b">1.4. Set Theory</h3>
</section>
</section>
<section>
<section id="slide-org0ca70d4">
<h3 id="org0ca70d4">1.5. The Definition of Probability</h3>
</section>
</section>
<section>
<section id="slide-org9798fea">
<h3 id="org9798fea">1.6. Finite Sample Spaces</h3>
</section>
</section>
<section>
<section id="slide-org123eaef">
<h3 id="org123eaef">1.7. Counting Methods</h3>
</section>
</section>
<section>
<section id="slide-org6fb6167">
<h3 id="org6fb6167">1.8. Combinatorial Methods</h3>
<div class="outline-text-3" id="text-org6fb6167">
</div>
</section>
</section>
<section>
<section id="slide-org0753336">
<h4 id="org0753336">Example 1.8.1 (choosing subsets)</h4>
<p class="fragment">
Consider the set \(\{a, b, c, d\}\).
</p>

<p class="fragment">
How many distinct subsets of size two?
</p>

<p class="fragment">
<span style="color: rgb(30,144,255)">Note</span>: \(\{a, b\} = \{b, a\}\), where the order does not matter!
</p>
<p class="fragment">
All subsets of size two:
\[
\{a, b\}, \{a, c\}, \{a, d\}, \{b, c\}, \{b, d\}, \{c, d\},
\]
and the total is \(6\).
</p>

</section>
</section>
<section>
<section id="slide-org7114727">
<h4 id="org7114727">Combination</h4>
<p class="fragment">
A selection of items from a set such that the order of the selection does not matter.
</p>

<p class="fragment">
In fact, a combination is an <span style="color: rgb(30,144,255)">unordered</span> sampling <span style="color: rgb(30,144,255)">without replacement</span>.
</p>

<p class="fragment">
<b>Question</b>: How many combinations of \(k\) items selected from a set of \(n\) distinct items are possible?
</p>

<p class="fragment">
We call this number &ldquo;\(n\) choose \(k\)&rdquo;, denoted by
\[
C_{n, k}, \quad\text{or}\quad C^n_k, \quad\text{or}\quad \binom{n}{k}
\]
</p>
</section>
</section>
<section>
<section id="slide-org5ebe3ad">
<h4 id="org5ebe3ad">How to find this number \(C_{n,k}\)?</h4>
<p class="fragment">
We will use a different way to compute \(P_{n,k}\).
</p>

<p class="fragment">
Making an ordered selection of \(k\) items (\(k\text{-permutation}\)) is the same as choosing a combination of \(k\) items and then ordering them.
</p>

<p class="fragment">
This is a \(2\text{-step}\) procedure:
</p>

<div class="fragment">
\begin{align*}
&\text{"number of $k\text{-permutations}$"}\\
 = &\text{"number of combination of $k$ items"}\\
 &\quad \times \text{"number of ways to order $k$ items"}
\end{align*}

</div>

<p class="fragment">
So,
\[
P_{n, k} = C_{n,k} \cdot k!.
\]
</p>

</section>
<section>
<p>
Thus,
\[
C_{n,k} = \frac{P_{n,k}}{k!} = \frac{n!}{(n-k)! k!}.
\]
</p>

</section>
</section>
<section>
<section id="slide-org68d2f9a">
<h4 id="org68d2f9a">Example</h4>
<p class="fragment">
Select \(5\) of \(30\) students in a class without regard to the order:
</p>

<p class="fragment">
\[
C_{30, 5} = \frac{30!}{25!5!}
\]
</p>

</section>
</section>
<section>
<section id="slide-orga8f3f6b">
<h4 id="orga8f3f6b">Binomial coefficient</h4>
<p class="fragment">
\[
\binom{n}{k} = C_{n,k} = \frac{n!}{(n-k)! k!}
\]
</p>

<p class="fragment">
<b>Theorem</b>. For any real numbers \(x\) and \(y\), \(n\in \mathbb{N}\),
\[
(x + y)^n = \sum_{k=0}^n \binom{n}{k} x^k y^{n-k}.
\]
</p>

<p class="fragment">
For the case \(n=2\):
</p>

<div class="fragment">
\begin{align*}
  (x + y)^2
& = \binom{2}{0} x^0 y^{2 -0} + \binom{2}{1} x^1 y^{2-1} + \binom{2}{2}x^2 y^{2-2}\\
& = 1 \cdot 1 \cdot y^2 + 2\cdot x\cdot y + 1\cdot x^2 \cdot y^0\\
& = x^2 + 2xy + y^2.
\end{align*}

</div>

</section>
<section>
<p>
\[
(x + y)^n = \sum_{k=0}^n \binom{n}{k} x^k y^{n-k}.
\]
</p>

<p class="fragment">
Idea of the proof
</p>

<p class="fragment">
\[
(x + y)^n = (x + y)(x + y)\cdots (x + y).
\]
</p>

<p class="fragment">
After expansion, a typical term should look like
</p>
<p class="fragment">
\[
\text{const}\times x^k y^j, \quad k + j = n; \quad \text{or}\quad \text{const}\times x^k y^{n-k}.
\]
</p>

<p class="fragment">
This &ldquo;const&rdquo; is the number of copies of each \(x^ky^{n-k}\), which is a combination number selecting \(k\) times of \(x\) out of total number \(n\).
</p>

</section>
<section>
<p>
<b>Note</b>:
</p>

<p class="fragment">
(1) \(\binom{n}{0} = \binom{n}{n} = 1\).
</p>

<p class="fragment">
(2) \(\binom{n}{k} = \binom{n}{n-k}\)
</p>

<p class="fragment">
Proof of (2):
</p>
<div class="fragment">
\begin{align*}
  \text{LHS}
& = \frac{n!}{(n-k)!k!} = \frac{n!}{k!(n-k)!}\\
& = \frac{n!}{(n-(n-k))!(n-k)!} = \text{RHS}.
\end{align*}

</div>

<p class="fragment">
The second formula above suggests that choosing \(k\) items from a set of \(n\) distinct items is the same as choosing \((n-k)\) items.
</p>

<p class="fragment">
In other words, a combination is in fact a <span style="color: rgb(30,144,255)">partition</span> of a set into two parts.
</p>

</section>
</section>
<section>
<section id="slide-orgf9b4164">
<h4 id="orgf9b4164">Example</h4>
<p>
Flip a fair coin \(10\) times.
</p>

<p class="fragment">
(1) What&rsquo;s the probability \(p\) of obtaining exactly three heads?
</p>

<p class="fragment">
One typical (possible) outcome could be \(H T \dots T\), or \(10\dots 0\).
</p>

<p class="fragment">
Thus, the sample space here is
</p>

<p class="fragment">
\[
S = \{(i_1, \dots, i_{10}) \mid i_j = 0 ~\text{or}~ 1, j = 1, \dots, 10 \}.
\]
</p>

<p class="fragment">
Let \(A\) be the event that we obtain exactly three heads when flipping a coin \(10\) times, so
</p>

<p class="fragment">
\[
p = \frac{\# A}{\# S} = \frac{\binom{10}{3}}{2^{10}}.
\]
</p>

</section>
<section>

<p>
Flip a fair coin \(10\) times.
</p>

<p>
(2) What&rsquo;s the probability \(p'\) of obtaining three or fewer heads?
</p>

<p class="fragment">
Let \(A'\) be the event that we obtain three or fewer heads. Then
</p>

<p class="fragment">
\[
\# A' = \binom{10}{0} + \binom{10}{1} + \binom{10}{2} + \binom{10}{3},
\]
and so
</p>

<p class="fragment">
\[
p' = \frac{\# A'}{\# S} = \frac{\binom{10}{0} + \binom{10}{1} + \binom{10}{2} + \binom{10}{3}}{2^{10}}.
\]
</p>
</section>
</section>
<section>
<section id="slide-org274d6f4">
<h4 id="org274d6f4">Sampling with replacement but unordered</h4>
<p class="fragment">
Recall: sampling with replacement but ordered
\[
n^k.
\]
</p>

</section>
</section>
<section>
<section id="slide-org0233838">
<h4 id="org0233838">Example 1.8.4 (Blood types)</h4>
<p class="fragment">
The gene for human blood types consists of a pair of alleles chosen from three alleles, called \(A, B\) and \(O\).
</p>

<p class="fragment">
\(OA\) is the same as \(AO\): <span style="color: rgb(30,144,255)">order does not matter</span>.
</p>

<p class="fragment">
\(AA, BB, OO\) are valid types: <span style="color: rgb(30,144,255)">with replacement</span>.
</p>

<p class="fragment">
<b>Question</b>: How many genotypes are there for the blood type?
</p>

<p class="fragment">
We can simply list all cases: \(AA, BB, OO, AB, BO, AO\), and there are \(6\) in total.
</p>

<p class="fragment">
<b><span style="color: rgb(255,0,0)">Warning</span></b>: \(6\) here is not \(C_{3,2} = 3\), nor \(3^2 = 9\).
</p>

</section>
<section>
<p>
What if a gene consists of a pair chosen from a set of \(n\) different alleles? How many genotypes?
</p>

<p class="fragment">
Case 1: there \(n\) pairs where both alleles are the same.
</p>

<p class="fragment">
Case 2: there are \(\binom{n}{2}\) pairs where two alleles are different.
</p>

<p class="fragment">
Then the total is
</p>

<div class="fragment">
\begin{align*}
  n + \binom{n}{2}
& = n + \frac{n(n-1)}{2}\\
& = n + \frac{n^2 - n}{2}\\
& = \frac{n^{2} + n}{2}.
\end{align*}

</div>

</section>
<section>
<p>
In general, the number of unordered sampling of size \(k\) items with replacement for \(n\) items is
\[
\binom{n+k-1}{k}, \qquad \text{see Exercise 19}.
\]
</p>

<p class="fragment">
When \(k=2\),
</p>

<p class="fragment">
\[
\frac{n^{2} + n}{2} = \frac{n(n+1)}{2} = \binom{n+1}{2}.
\]
</p>
</section>
</section>
<section>
<section id="slide-org2ba5a7a">
<h4 id="org2ba5a7a">Summary</h4>
<ul>
<li data-fragment-index="1" class="fragment">Sampling with replacement, order matters.<br />
Example: flip a fair coin \(10\) times, then \(\# S = 2^{10} (n^k)\).</li>
<li data-fragment-index="2" class="fragment">Sampling without replacement, order matters.<br />
Example: pick \(5\) students out of 30 to form a line: \(P_{30, 5}, \quad(P_{n,k})\).</li>
<li data-fragment-index="3" class="fragment">Sampling without replacement, order does not matter.<br />
Example: pick \(5\) students out of \(30\) to form a team/committee: \(C_{30, 5} = \binom{30}{5}\).<br /></li>
<li data-fragment-index="4" class="fragment">Sampling with replacement, order does not matter (tricky).
Example 1.8.4, Exercise 19.</li>

</ul>

</section>
</section>
<section>
<section id="slide-org894c305">
<h4 id="org894c305">Example</h4>
<p>
Suppose we have a class of \(24\) children. We consider three different scenarios that each involves choosing \(3\) children.
</p>

<p>
Every day a random child is chosen to lead the class to lunch, without regard to previous choices.
</p>

</section>
<section>
<p>
(1) What is the probability that Carlos was chosen on Monday and Wednesday, Aaron on Tuesday?
</p>

<p class="fragment">
Let \(A\) denote the event that Carlos was chosen on Monday and Wednesday, Aaron on Tuesday.
</p>

<p class="fragment">
There are two ways to count in this problem:
</p>
<p class="fragment">
\[
\# S = 24^3,~ \# A = 1\qquad \text{or}\qquad \# S = 24^5, ~ \# A = 24^2,
\]
but both give you
</p>
<p class="fragment">
\[
\mathbb{P}(A) = \frac{1}{24^{3}}.
\]
</p>

</section>
<section>
<p>
(2) Three children are chosen randomly to be the class president, vice president and treasurer. No student can hold more than one position. What&rsquo;s the probability that Mary is president, Cory is vice president and Matt is treasurer?
</p>

<p class="fragment">
Let \(A'\) be the event that Mary is president, Cory is vice president and Matt is treasurer. Then
</p>
<p class="fragment">
\[
\# S = P_{24, 3}, \quad \# A' = 1,
\]
and
</p>
<p class="fragment">
\[
\mathbb{P}(A') = \frac{1}{P_{24,3}}.
\]
</p>

</section>
<section>
<p>
(3) A team of three children is chosen at random. What&rsquo;s the probability that Mary is on the team?
</p>

<p class="fragment">
Let \(A''\) be the event that Mary is on the team. Then
</p>

<p class="fragment">
\[
\# S = \binom{24}{3}, \quad \# A'' = \binom{1}{1} \binom{23}{2},
\]
</p>
<p class="fragment">
and
\[
\mathbb{P}(A') = \frac{\binom{1}{1} \binom{23}{2}}{\binom{24}{3}}.
\]
</p>

</section>
</section>
<section>
<section id="slide-orgcc85727">
<h3 id="orgcc85727">1.9. Multinomial Coefficients</h3>
<p>
Recall: Binomial coefficient
\[\binom{n}{k} = C_{n, k} = \binom{n}{n-k}\]
</p>

</section>
</section>
<section>
<section id="slide-orgc27f86d">
<h4 id="orgc27f86d">Partitions</h4>
<p class="fragment">
A combination is a choice of \(k\) items of an \(n\text{-item}\) set, and the order does not matter.
</p>

<p class="fragment">
This is the same as partitioning the set into two parts. One part contains \(k\) items, and the other contains the remaining \(n-k\) items.
</p>

<p class="fragment">
Now consider partitions into more than two parts.
</p>

</section>
</section>
<section>
<section id="slide-org19b184d">
<h4 id="org19b184d">Example</h4>
<p>
Suppose that \(20\) members of an organization are to be divided into three committees \(A, B\) and \(C\), in such a way \(A\) and \(B\) each has \(8\) members, \(C\) has \(4\) members. Each member can be assigned to only one committee.
</p>

<p class="fragment">
<b>Question</b>: How many ways to assign the members?
</p>

<p class="fragment">
\(3\text{-step}\) procedure: in each step we choose the members to one committee.
</p>
<div class="fragment">
\begin{align*}
  & \binom{20}{8} \cdot \binom{12}{8} \cdot \binom{4}{4}\\
  = & \frac{20!}{8!12!} \cdot \frac{12!}{8!4!} \cdot 1\\
  = & \frac{20!}{8!8!4!}
\end{align*}

</div>
</section>
</section>
<section>
<section id="slide-orgc3e9940">
<h4 id="orgc3e9940">Partitions - General Case</h4>
<p class="fragment">
Given a set of \(n\) distinct items and non-negative integers \(n_{1}, n_{2}, \dots, n_{r}\) with \(n_1 + n_2 + \cdots +n _r = n\).
</p>

<p class="fragment">
<b>Question</b>: How many ways can the set be partitioned into \(r\) disjoint subsets with \(n_i\) items in its \(i^{\text{th}}\) subset?
</p>

<p class="fragment">
We call this number
\[
  \binom{n}{n_1, n_{2}, \dots, n_{r}}
\]
</p>

</section>
<section>
<p>
This is  a \(r\text{-step}\) procedure:
</p>
<div class="fragment">
\begin{align*}
  &\binom{n}{n_1, n_{2}, \dots, n_{r}}=
 \binom{n}{n_{1}} \cdot \binom{n-n_{1}}{n_{2}} \cdots \binom{n-n_{1}-n_{2}-\cdots - n_{r-1}}{n_{r}}\\
  = & \frac{n!}{n_{1}!(n-n_{1})!} \cdot \frac{(n-n_{1})!}{n_{2}!(n-n_{1} - n_{2})!} \cdot \frac{(n-n_{1} -n_{2})!}{n_{3}!(n-n_{1} - n_{2}-n_{3})!}\\
   &  \qquad \cdots \frac{(n-n_{1} -n_{2}- \cdots n_{r-1})!}{n_{r}!(n-n_{1} - n_{2}-\cdots - n_{r-1} - n_{r})!}\\
= & \frac{n!}{n_{1}!n_{2}! \cdots n_{r}!}
\end{align*}

</div>

<p class="fragment">
Check for \(r=2\): \(n_1 = k, n_2 = n-k\),
\[
\binom{n}{k} = \binom{n}{n-k} = \binom{n}{k, n-k} = \frac{n!}{k!(n-k)!}
\]
</p>


</section>
</section>
<section>
<section id="slide-org9e6a4e0">
<h4 id="org9e6a4e0">Example</h4>
<p>
How many arrangements are there of the letters &ldquo;BANANA&rdquo;?
</p>


</section>
<section>
<p>
Solution (1):
</p>

<p class="fragment">
There are \(6\) positions for the \(3\) letters.
</p>

<p class="fragment">
Each arrangement is a partition of the set of \(6\) positions into a subset of size \(3\) (the positions that get the letter \(A\)), and subset of size \(2\) (the positions that get the letter \(N\)), and a subset of size \(1\) (the position that gets the letter \(B\)).
</p>

<p class="fragment">
For example,
</p>
<p class="fragment">
\[
A A A B N N \leftrightarrow \{1, 2, 3\}, \{4\}, \{5, 6\}
\]
</p>
<p class="fragment">
\[
B A N A N A \leftrightarrow \{2, 4, 6\}, \{1\}, \{3, 5\}
\]
</p>

<p class="fragment">
Total number of arrangements:
</p>
<p class="fragment">
\[
\binom{6}{3,2,1} = \frac{6!}{3!2!1!} = 60.
\]
</p>

</section>
<section>
<p>
Solution (2):
</p>

<p class="fragment">
We first pretend the \(6\) letters are distinct:
</p>
<p class="fragment">
\[
B, A_1, A_2, A_3, N_1, N_2.
\]
</p>
<p class="fragment">
There are \(6!\) ways to arrange them.
</p>

<p class="fragment">
But each of \(3!\) ways to arrange \(A\)&rsquo;s and each of the 2! ways to arrange \(N\)&rsquo;s correspond to the same arrangement.
</p>

<p class="fragment">
For example,
\[
B A_1 N_1 A_2 N_2 A_3 \quad\text{and}\quad B A_2 N_1 A_3 N_2 A_{1}
\]
both spell as \(BANANA\).
</p>

<p class="fragment">
So we need to divide it by \(3!2!\), and the total number ways is
\[
\frac{6!}{3!2!} = 60 = \binom{6}{3, 2, 1}.
\]
</p>

</section>
</section>
<section>
<section id="slide-org4c8d896">
<h4 id="org4c8d896">Example 1.9.4</h4>
<p>
A deck of \(52\) cards, containing \(13\) hearts. Suppose cards are shuffled and distributed among \(A, B, C\) and \(D\) four players.
</p>

<p>
What is the probability that \(A\) gets \(6\) hearts, \(B\) gets \(4\) hearts, \(C\) gets \(2\) hearts, and \(D\) gets \(1\) heart?
</p>

</section>
<section>
<p>
Solution (1):
</p>
<p class="fragment">
\[
\# S = \binom{52}{13, 13, 13, 13} = \frac{52!}{(13!)^4}.
\]
</p>
<p class="fragment">
Let \(E\) be the event that \(A\) gets \(6\) hearts, \(B\) gets \(4\) hearts, \(C\) gets \(2\) hearts, and \(D\) gets \(1\) heart, then
</p>
<p class="fragment">
\[
\# E = \binom{13}{6, 4, 2, 1} \cdot \binom{39}{7, 9, 11, 12}.
\]
</p>
<p class="fragment">
Thus,
\[
\mathbb{P}(E) = \frac{\# E}{\# S} = \frac{13!}{6!4!2!} \cdot \frac{39!}{7!9!11!12!} \cdot \frac{(13!)^{4}}{52!}.
\]
</p>

</section>
<section>
<p>
Solution (2):
</p>
<p class="fragment">
Consider \(52\) cards are distributed one by one.
</p>

<p class="fragment">
So there are \(\# S = \binom{52}{13}\) total number of combinations of positions of \(13\) hearts, and
</p>
<p class="fragment">
\[
\# E = \binom{13}{6} \binom{13}{4} \binom{13}{2} \binom{13}{1}.
\]
</p>
<p class="fragment">
Of course, the probability \(\mathbb{P}(E)\) is the same as before.
</p>

</section>
</section>
<section>
<section id="slide-orge158c2c">
<h3 id="orge158c2c">1.10. The Probability of a Union of Events</h3>
<p>
Recall: Inclusion-Exclusion formula
</p>
<p class="fragment">
\[
\mathbb{P}(A\cup B) = \mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A \cap B).
\]
</p>


<div id="org0555355" class="figure">
<p><img src="../img/20220610-164412intersection-of-two-sets.png" alt="20220610-164412intersection-of-two-sets.png" class="fragment middle" width="600px" />
</p>
</div>

</section>
<section>
<p>
<b>Theorem</b>
</p>

<p>
(1) Three events:
</p>
<div>
\begin{align*}
\mathbb{P}(A\cup B\cup C)
& = \mathbb{P}(A) + \mathbb{P}(B) + \mathbb{P}(C) - \mathbb{P}(A\cap B) - \mathbb{P}(A\cap C)\\
& \quad  - \mathbb{P}(B\cap C) + \mathbb{P}(A\cap B\cap C).
\end{align*}

</div>


<div id="orgfc6a338" class="figure">
<p><img src="../img/20220610-164431intersection-venn-diagram.png" alt="20220610-164431intersection-venn-diagram.png" class="fragment middle" width="400px" />
</p>
</div>

</section>
<section>
<p>
(2) General case:
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(\cup_{i=1}^n A_i)
& = \sum_{i=1}^n \mathbb{P}(A_i) - \sum_{i < j}  \mathbb{P}(A_i \cap A_j)\\
& \quad + \sum_{i< j < k } \mathbb{P}(A_i \cap A_j \cap A_{k})  \\
& \quad - \sum_{i < j < k < l} \mathbb{P}(A_i \cap A_j \cap A_k \cap A_{l})\\
& \quad + \cdots + (-1)^{n+1} \mathbb{P}(A_1\cap A_2\cap \cdots \cap A_n).
\end{align*}

</div>

<p class="fragment">
Example 1.10.1 (easy, read by yourself)
</p>

</section>
</section>
<section>
<section id="slide-orgc35f821">
<h4 id="orgc35f821">Matching Problem</h4>
<p class="fragment">
Suppose \(3\) men throw their hats into the center of a room. The hats are mixed up, and then each man randomly selects a hat.
</p>

<p class="fragment">
What&rsquo;s the probability that at least one man selects his own hat?
</p>

<p class="fragment">
<b>Want</b>: \(\mathbb{P}(A)\), where \(A\) is the event that at least one man selects his own hat.
</p>


</section>
<section>
<p>
What is the sample space \(S\)?
</p>

<p class="fragment">
Consider each outcome is a vector of \(3\) members.
</p>

<p class="fragment">
For example,
</p>

<p class="fragment">
\((1, 2, 3)\) means each man selects his own hat;
</p>

<p class="fragment">
\((2, 1, 3)\) means 1st man selects the hat \(2\), 2nd man selects the hat \(1\), and 3rd man selects his own.
</p>

<p class="fragment">
Therefore,
</p>

<p class="fragment">
\(\# S = 3! = 6\).
</p>

</section>
<section>
<p>
What is the event \(A\)?
</p>

<p class="fragment">
Denote by \(E_i\) the event that \(i^{\text{th}}\) man selects his own hat, then
</p>

<p class="fragment">
\[
A = E_1\cup E_2\cup E_3.
\]
</p>

</section>
<section>
<p>
To compute \(\mathbb{P}(A)\), we need \(\mathbb{P}(E_{i}), \mathbb{P}(E_{i}\cap E_j)\) and \(\mathbb{P}(E_1\cap E_2\cap E_3)\):
</p>
<div class="fragment">
\begin{align*}
  & \mathbb{P}(E_1) = \frac{2}{6} = \mathbb{P}(E_2) = \mathbb{P}(E_3)\\
 & \mathbb{P}(E_1\cap E_2) = \frac{1}{6} = \mathbb{P}(E_2\cap E_3) = \mathbb{P}(E_1\cap E_3)\\
& \mathbb{P}(E_1\cap E_2\cap E_3) = \frac{1}{6}.
\end{align*}

</div>

<p class="fragment">
Therefore,
\[
\mathbb{P}(A) = \frac{1}{3} \cdot 3 - 3 \cdot \frac{1}{6} + \frac{1}{6} = 1 - \frac{1}{2} + \frac{1}{6} = \frac{2}{3}.
\]
</p>

<p class="fragment">
<b>Note</b>: see the &ldquo;hat problem&rdquo; on page 49 for the general case.
</p>

</section>
</section>
<section>
<section id="slide-org1b31458">
<h2 id="org1b31458">Chapter 2 - Conditional Probability</h2>
<div class="outline-text-2" id="text-org1b31458">
</div>
</section>
</section>
<section>
<section id="slide-org82d693b">
<h3 id="org82d693b">2.1. The Definition of Conditional Probability</h3>
<p class="fragment">
Given an experiment with probability model \((S, \mathbb{P}, \mathcal{F})\).
</p>

<p class="fragment">
<span style="color: rgb(30,144,255)">Suppose</span> we know the outcome belongs to a given event \(B\), such that \(\mathbb{P}(B)>0\).
</p>

<p class="fragment">
The probability that the outcome also belongs to the event \(A\) is called the <span style="color: rgb(30,144,255)">conditional probability</span> of \(A\) given \(B\), and is defined by
\[
\mathbb{P}(A|B) = \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}.
\]
</p>

</section>
<section>
<p>
Intuitively, out of the total probability assigned to elements of \(B\), \(\mathbb{P}(A|B)\) is the fraction assigned to elements that also belongs to \(A\):
</p>


<div id="org2f443be" class="figure">
<p><img src="../img/20220610-211829Complement of a Set.svg" alt="20220610-211829Complement of a Set.svg" class="fragment middle" width="400px" />
</p>
</div>

</section>
</section>
<section>
<section id="slide-orgd6ab05c">
<h4 id="orgd6ab05c">Example</h4>
<p>
A fair six-sided die is rolled twice.
</p>

<p class="fragment">
You were told that the sum of two rolls is \(9\). How likely is it that the first roll is \(6\)?
</p>

<p class="fragment">
Let \(A\) be the event that the first roll is \(6\), and \(B\) be the event that the sum of two is \(9\).
</p>

<p class="fragment">
\[
\mathbb{P}(A) = \frac{6}{36} = \frac{1}{6}.
\]
</p>
<p class="fragment">
What about \(\mathbb{P}(A|B)\)?
</p>

</section>
<section>
<p>
By definition,
</p>

<div>
\begin{align*}
  \mathbb{P}(A|B)
& = \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)} = \frac{\frac{\# (A\cap B)}{\# S}}{\frac{\# B}{\# S}}\\
& = \frac{\# (A\cap B)}{\# B}.
\end{align*}

</div>

<p class="fragment">
\[
B = \{(3, 6), (6, 3), (4, 5), (5, 4)\}, \quad\text{so,}~\# B = 4.
\]
</p>

<p class="fragment">
\[
A\cap B = \{(6, 3)\}, \quad\text{so,}~\# A = 1.
\]
</p>

<p class="fragment">
Therefore,
\[
\mathbb{P}(A|B) = \frac{1}{4}.
\]
</p>

</section>
</section>
<section>
<section id="slide-org53a7b7b">
<h4 id="org53a7b7b">Theorem</h4>
<p>
If we have a simple sample space, then
\[
\mathbb{P}(A|B)
 = \frac{\# (A\cap B)}{\# B}.
\]
</p>

</section>
</section>
<section>
<section id="slide-orgd3f1aae">
<h4 id="orgd3f1aae">Example</h4>
<p>
Toss a fair coin \(5\) times.
</p>

<p class="fragment">
What is the probability that there are more heads than tails given that the first toss is heads?
</p>

</section>
<section>
<p>
Let \(A\) be the event that there are more heads than tails, and \(B\) be the event that the first toss is heads.
</p>

<p class="fragment">
\[
\# B = 1\cdot 2\cdot 2\cdot 2 \cdot 2 = 2^4,
\]
</p>
<p class="fragment">
and
\[
\# (A\cap B) = \binom{4}{2} + \binom{4}{3} + \binom{4}{4} = 11.
\]
</p>
<p class="fragment">
So
\[
\mathbb{P}(A|B) = \frac{\# (A\cap B)}{\# B} = \frac{11}{2^{4}} = \frac{11}{16}.
\]
</p>

</section>
</section>
<section>
<section id="slide-org2975291">
<h4 id="org2975291">Important Fact</h4>
<p>
<span style="color: rgb(30,144,255)">A conditional probability is a probability measure.</span>
</p>

<p class="fragment">
Specifically, given a probability model \((S, \mathbb{P}, \mathcal{F})\), an event \(B\) with \(\mathbb{P}(B)>0\), then the set function \(\mathbb{P}(\cdot | B)\) satisfies the probability axioms and consequences, i.e.,
</p>

<p class="fragment">
(1) \(\mathbb{P}(A|B) \ge 0\), for all event \(A\).
</p>

<p class="fragment">
(2) \(\mathbb{P}(S | B) = 1\).
</p>

<p class="fragment">
(3) If \(A_1, A_2, \dots\) is any countable sequence of disjoint events.
\[
\mathbb{P}(\cup_i A_i | B) = \sum_i \mathbb{P}(A_i| B).
\]
</p>
</section>
</section>
<section>
<section id="slide-org084f2a2">
<h4 id="org084f2a2">Example</h4>
<p class="fragment">
Exercise. 11.
\[
\mathbb{P}(A^c|B) = 1 - \mathbb{P}(A|B).
\]
</p>

<p class="fragment">
Exercise. 12.
\[
\mathbb{P}(A\cup B|C) = \mathbb{P}(A|C) + \mathbb{P}(B | C) - \mathbb{P}(A\cap B| C).
\]
</p>

</section>
</section>
<section>
<section id="slide-orgeff1438">
<h4 id="orgeff1438">Multiplication rule for conditional probability</h4>
<p class="fragment">
Recall:
\[
\mathbb{P}(A|B) = \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}, \quad \mathbb{P}(B|A) = \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}.
\]
</p>
<p class="fragment">
By reordering the terms, we have
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(A\cap B)
& = \mathbb{P}(A|B)\mathbb{P}(B)\\
& = \mathbb{P}(B|A)\mathbb{P}(A).
\end{align*}

</div>

<p class="fragment">
More general version of this rule:
</p>
<div class="fragment">
\begin{multline*}
\mathbb{P}(\cap_{i=1}^nA_i) = \mathbb{P}(A_1) \mathbb{P}(A_2|A_1)\mathbb{P}(A_3|A_1\cap A_2)\\
\cdot \mathbb{P}(A_4| A_1\cap A_2\cap A_3) \cdots \mathbb{P}(A_n |\cap_{i=1}^{n-1}A_i)
\end{multline*}

</div>
</section>
</section>
<section>
<section id="slide-org9921367">
<h4 id="org9921367">Example</h4>
<p>
Draw \(3\) cards from a deck of \(52\) cards without replacement. What&rsquo;s the probability that you draw \(A22\) in that order?
</p>

<p class="fragment">
Let \(B\) be the event of interest, and define
</p>
<div class="fragment">
\begin{align*}
  A_1 & = ~\text{the first card is}~A,\\
  A_2 & = ~\text{the second card is}~2,\\
  A_3 & = ~\text{the third card is}~2.
\end{align*}

</div>
<p class="fragment">
So, \(B = A_1 \cap A_2 \cap A_3\), and thus,
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(B)
& = \mathbb{P}(A_1\cap A_2\cap A_3)\\
& = \mathbb{P}(A_1) \mathbb{P}(A_2|A_1)\mathbb{P}(A_3|A_1\cap A_2)\\
& = \frac{4}{52}\cdot \frac{4}{51}\cdot \frac{3}{50}.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orgf8a68bd">
<h4 id="orgf8a68bd">Example (Radar detection)</h4>
<p>
An aircraft is present in a certain area with probability \(0.05\). If an aircraft is present, the radar correctly detects it with probability \(0.99\). If an aircraft is not present, the radar incorrectly registers it with probability \(0.1\).
</p>

<p class="fragment">
(1) What&rsquo;s the probability of a false alarm (no aircraft but radar sees one)?
</p>

<p class="fragment">
Let \(A\) be the event that an aircraft is present, and \(B\) be the event that radar sees one.
</p>

<div class="fragment">
\begin{align*}
  \mathbb{P}(A^c\cap B) & = \mathbb{P}(B)\mathbb{P}(A^c|B) = \mathbb{P}(A^c)\mathbb{P}(B|A^c)\\
& = (1 - \mathbb{P}(A)) \cdot 0.1 = 0.95 \cdot 0.1 = 0.095.
\end{align*}

</div>

</section>
<section>
<p>
(2) What&rsquo;s the probability of a missed detection (that there is an aircraft and radar does not see it)?
</p>

<div class="fragment">
\begin{align*}
  \mathbb{P}(A\cap B^c) & = \mathbb{P}(A)\mathbb{P}(B^c|A) = 0.05 \cdot (1 - \mathbb{P}(B|A))\\
& = 0.05 \cdot (1 - 0.99) = 0.0005.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orga795db2">
<h4 id="orga795db2">Law of total probability</h4>
<p class="fragment">
Let \(B_1, B_2, \dots\) be a countable sequence of events that form a <span style="color: rgb(30,144,255)">partition</span> of the sample space \(S\):
</p>

<p class="fragment">
(1) \(B_1, B_2, \dots\) are disjoint, and
</p>

<p class="fragment">
(2) \(\cup_{i=1}^{\infty} B_i = S\).
</p>

<p class="fragment">
Then for any event \(A\), we have that \(A\cap B_1, A\cap B_2, \dots\) are also disjoint, and
</p>
<p class="fragment">
\[
A = \cup_i (A \cap B_i),
\]
</p>

<p class="fragment">
\[
\mathbb{P}(A) = \sum_i \mathbb{P}(A\cap B_i) = \sum_i \mathbb{P}(A|B_i) \mathbb{P}(B_i).
\]
</p>

</section>
<section>

<div id="org826972e" class="figure">
<p><img src="../img/20220619_191957Total-prob.png" alt="20220619_191957Total-prob.png" class="middle" width="600px" />
</p>
</div>


</section>
<section>
<p>
Special case: \(S = B \cup B^c\).
</p>
<p class="fragment">
\[
A = (A \cap B)\cup (A \cap B^c),
\]
</p>
<p class="fragment">
and
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(A)
& = \mathbb{P}(A\cap B) + \mathbb{P}(A \cap B^c)\\
& = \mathbb{P}(B)\mathbb{P}(A|B) + \mathbb{P}(B^c) \mathbb{P}(A|B^c).
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orge479034">
<h4 id="orge479034">Example</h4>
<p>
There are \(3\) urns. Urn \(1\) has \(3\) red, \(4\) green, and \(5\) blue balls; urn \(2\) has \(3\) red, \(10\) green, and \(1\) blue balls; urn \(3\) has \(3\) red, \(2\) green, and \(2\) blue balls.
</p>

<p class="fragment">
Choose one of the urns at random and draw a ball from this urn. What&rsquo;s the probability that the ball we choose is green?
</p>

</section>
<section>
<p>
Let \(A\) be the event of interest.
</p>

<p class="fragment">
Partition \(S\) into \(3\) events:
\[
B_i = ~\text{the ball chosen is from the $i\text{-th}$ urn}, i = 1, 2, 3.
\]
</p>
<p class="fragment">
Then we have
</p>
<p class="fragment">
\[
S = B_{1} \cup B_2 \cup B_3, \quad B_i\cap B_j = \emptyset, i \neq j,
\]
</p>
<p class="fragment">
and thus
</p>
<div class="fragment">
\begin{align*}
 \mathbb{P}(A)
& = \mathbb{P}(A\cap B_1) + \mathbb{P}(A\cap B_2) + \mathbb{P}(A\cap B_3)\\
& = \mathbb{P}(B_1)\mathbb{P}(A|B_1) + \mathbb{P}(B_2)\mathbb{P}(A|B_2) + \mathbb{P}(B_3)\mathbb{P}(A|B_3)\\
& = \frac{1}{3}\cdot \frac{4}{12} + \frac{1}{3}\cdot \frac{10}{14} + \frac{1}{3} \cdot \frac{2}{7}.
\end{align*}

</div>
</section>
</section>
<section>
<section id="slide-org1aefae2">
<h3 id="org1aefae2">2.2. Independent Events</h3>
<div class="outline-text-3" id="text-org1aefae2">
</div>
</section>
</section>
<section>
<section id="slide-org56b2782">
<h4 id="org56b2782">Definition</h4>
<p>
We say two events \(A\) and \(B\) are <b>independent</b> if
</p>

<p class="fragment">
\[
\mathbb{P}(A\cap B) = \mathbb{P}(A) \mathbb{P}(B).
\]
</p>

<p class="fragment">
<b>Note</b>:
</p>

<p class="fragment">
(1) \(A\) and \(B\) are disjoint if
\[
\mathbb{P}(A\cup B) = \mathbb{P}(A) + \mathbb{P}(B).
\]
</p>

<p class="fragment">
(2) Suppose \(\mathbb{P}(B)>0\), events \(A\) and \(B\) are independent if
\[
\mathbb{P}(A|B) = \mathbb{P}(A). \qquad\text{Why?}
\]
</p>


<p class="fragment">
<b>Intuition</b>: \(A\) and \(B\) are independent if the occurrence of \(B\) does not affect the occurrence of \(A\).
</p>

</section>
</section>
<section>
<section id="slide-org4eb8b9c">
<h4 id="org4eb8b9c">Example</h4>
<p>
Flip two fair coins.
</p>

<p class="fragment">
Let \(A\) be the event that the first coin is heads, and \(B\) be the event that the second is tails.
</p>

<p class="fragment">
By intuition, it seems \(A\) and \(B\) are independent.
</p>

<p class="fragment">
<b>Check</b>: if \(\mathbb{P}(A\cap B) = \mathbb{P}(A) \mathbb{P}(B)\) ?
</p>

<p class="fragment">
\[
\mathbb{P}(A\cap B) = \frac{1}{4}, \quad \mathbb{P}(A) = \mathbb{P}(B) = \frac{1}{2}.
\]
</p>

</section>
</section>
<section>
<section id="slide-orgef0015b">
<h4 id="orgef0015b">Example</h4>
<p>
Roll a six-sided die.
</p>

<p class="fragment">
\[
\mathbb{P}(\{6\}) = \frac{1}{6}.
\]
</p>

<p class="fragment">
If you know the outcome is even, would you change the answer to the probability of getting \(6\)?
</p>

<p class="fragment">
Let \(A\) be the event of obtaining \(6\), and \(B\) be the event that you get an even number. Then
</p>

<p class="fragment">
\[
\mathbb{P}(A|B) = \frac{1}{3} \neq \frac{1}{6} = \mathbb{P}(A).
\]
So \(A\) and \(B\) are <span style="color: rgb(255,0,0)">not</span> independent.
</p>

</section>
</section>
<section>
<section id="slide-org612c451">
<h4 id="org612c451">Equivalent definitions</h4>
<p data-fragment-index="0" class="fragment">
The following statements are equivalent:
</p>

<ul>
<li data-fragment-index="1" class="fragment">\(A\) and \(B\) are independent.</li>
<li data-fragment-index="2" class="fragment">\(\mathbb{P}(A\cap B) = \mathbb{P}(A) \mathbb{P}(B)\).</li>
<li data-fragment-index="3" class="fragment">\(\mathbb{P}(A|B) = \mathbb{P}(A)\).</li>
<li data-fragment-index="4" class="fragment">\(\mathbb{P}(B|A) = \mathbb{P}(B)\).</li>
<li data-fragment-index="5" class="fragment">\(\mathbb{P}(A|B^c) = \mathbb{P}(A)\).</li>
<li data-fragment-index="6" class="fragment">\(\mathbb{P}(B|A^c) = \mathbb{P}(B)\).</li>

</ul>

</section>
</section>
<section>
<section id="slide-org5553e05">
<h4 id="org5553e05">Definition (for three events)</h4>
<p class="fragment">
The events \(A_1, A_2, A_3\) are independent if <span style="color: rgb(30,144,255)">all</span> of the following conditions hold:
</p>
<ul class="fragment">
<li>\(\mathbb{P}(A_1\cap A_2\cap A_3) = \mathbb{P}(A_1)\mathbb{P}(A_2)\mathbb{P}(A_3)\).</li>
<li>\(\mathbb{P}(A_1\cap A_2) = \mathbb{P}(A_1)\mathbb{P}(A_2)\).</li>
<li>\(\mathbb{P}(A_1\cap A_3) = \mathbb{P}(A_1)\mathbb{P}(A_3)\).</li>
<li>\(\mathbb{P}(A_2\cap A_3) = \mathbb{P}(A_2)\mathbb{P}(A_3)\).</li>

</ul>

</section>
</section>
<section>
<section id="slide-orge7313a0">
<h4 id="orge7313a0">Example</h4>
<p>
Flip a fair coin twice.
</p>

<p class="fragment">
\[
S = \{HH, TT, TH, HT\}.
\]
</p>

<p class="fragment">
Let
</p>
<div class="fragment">
\begin{align*}
  A & = ~\text{the first coin is H} ~ = \{HH, HT\},\\
  B & = ~\text{the second coin is H} ~ = \{HH, TH\},\\
  C & = ~\text{the first and second are the same} ~ = \{HH, TT\}.
\end{align*}

</div>

<p class="fragment">
Then
</p>
<p class="fragment">
\[
\mathbb{P}(A) = \mathbb{P}(B) = \mathbb{P}(C) = \frac{2}{4} = \frac{1}{2}.
\]
</p>

</section>
<section>
<p>
Are \(A\) and \(B\) independent?
</p>

<p class="fragment">
\[
\mathbb{P}(A\cap B) = \frac{1}{4} = \frac{1}{2}\cdot \frac{1}{2} = \mathbb{P}(A)\mathbb{P}(B).
\]
</p>

<p class="fragment">
However,
</p>

<p class="fragment">
\[
\mathbb{P}(A\cap B \cap C) = \mathbb{P}(\{HH\}) = \frac{1}{4},
\]
and
</p>
<p class="fragment">
\[
\mathbb{P}(A) \mathbb{P}(B) \mathbb{P}(C) = \frac{1}{2}\cdot \frac{1}{2}\cdot\frac{1}{2} = \frac{1}{8}.
\]
</p>
<p class="fragment">
Therefore, \(A, B\) and \(C\) are <span style="color: rgb(255,0,0)">not</span> independent.
</p>

<p class="fragment">
<b>Read</b>: Example 2.2.5.
</p>

</section>
</section>
<section>
<section id="slide-org4a7e681">
<h4 id="org4a7e681">Definition (for \(n\) events)</h4>
<p class="fragment">
The events \(A_1, A_2, \dots, A_n\) are <b>independent</b> if
</p>
<p class="fragment">
\[
\mathbb{P}(\cap_{i\in I} A_i) = \prod_{i\in I} \mathbb{P}(A_i)
\]
for any index subset \(I\subseteq \{1, 2, \dots, n\}\).
</p>

</section>
</section>
<section>
<section id="slide-org83c5b6b">
<h4 id="org83c5b6b">Another equivalent definition</h4>
<p class="fragment">
The events \(A_1, A_2, \dots, A_n\) are <b>independent</b> if
</p>
<p class="fragment">
\[
\mathbb{P}(\cap_{i\in I} A_i^{\ast}) = \prod_{i\in I} \mathbb{P}(A_i^{\ast})
\]
for any subset \(I\subseteq \{1, 2, \dots, n\}\), where
\[
A^{\ast}_i = A_i ~\text{or}~ A^c_i.
\]
</p>
<p class="fragment">
In particular, if \(A\) and \(B\) are independent, then
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(A\cap B)&  = \mathbb{P}(A)\mathbb{P}(B),\\
  \mathbb{P}(A^{c}\cap B)&  = \mathbb{P}(A^{c})\mathbb{P}(B),\\
\cdots & = \cdots
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orge6168ae">
<h4 id="orge6168ae">Example 2.2.5 (Inspecting items)</h4>
<p class="fragment">
A machine produces a defective item with probability \(p\), and a non-defective item with probability \(1-p\).
</p>

<p class="fragment">
\(6\) items are produced, and randomly selected, inspected. What&rsquo;s the probability that there are exactly \(2\) items are defective?
</p>

<p class="fragment">
Label the items by \(1, 2, 3, 4, 5, 6\), and define
</p>
<p class="fragment">
\[
D_j = \{ j\text{-th item is defective} \}.
\]
</p>
<p class="fragment">
Then \(D_1, D_2, \dots, D_6\) are independent.
</p>

</section>
<section>
<p>
A typical desired outcome:
</p>
<p class="fragment">
\[
E = D^c_1 \cap D_2 \cap D_3^c \cap D_4^c \cap D_5 \cap D^c_6.
\]
</p>

<div class="fragment">
\begin{align*}
  \mathbb{P}(E)
& = \mathbb{P}(D^c_1) \mathbb{P}(D_2) \mathbb{P}(D^c_3) \mathbb{P}(D^c_4) \mathbb{P}(D_{5}) \mathbb{P}(D^c_6)\\
& = (1 - p) \cdot p \cdot (1-p) \cdot (1-p) \cdot p \cdot (1-p)\\
& = p^2 (1-p)^4.
\end{align*}

</div>

<p class="fragment">
<b>Key observation</b>: all desired outcomes have the same probability \(p^2 (1-p)^4\).
</p>

<p class="fragment">
Thus, we only need to count the number of such outcomes, which is
</p>
<p class="fragment">
\[
\binom{6}{2}.
\]
</p>
<p class="fragment">
Therefore,
\[
\mathbb{P}(\{\text{exactly $2$ defective items}\}) = \binom{6}{2} p^2 (1-p)^4.
\]
</p>
</section>
</section>
<section>
<section id="slide-org7da36c2">
<h3 id="org7da36c2">2.3. Bayes&rsquo; Theorem</h3>
<p>
\[
\text{"conditional probability"} ~+~ \text{"law of total probability"}
\]
</p>

</section>
</section>
<section>
<section id="slide-org6f1fdd3">
<h4 id="org6f1fdd3">Version 1</h4>
<p class="fragment">
\[
\mathbb{P}(A|B) = \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)} = \frac{\mathbb{P}(B|A)\mathbb{P}(A)}{\mathbb{P}(B)}.
\]
</p>

<p class="fragment">
Bayes&rsquo; formula allows you to <span style="color: rgb(30,144,255)">reverse</span> the order of conditioning.
</p>

</section>
</section>
<section>
<section id="slide-org94bf686">
<h4 id="org94bf686">Version 2</h4>
<p class="fragment">
\[
\mathbb{P}(A|B) =  \frac{\mathbb{P}(B|A)\mathbb{P}(A)}{\mathbb{P}(B|A)\mathbb{P}(A) + \mathbb{P}(B|A^c)\mathbb{P}(A^c)}.
\]
</p>

</section>
</section>
<section>
<section id="slide-orgf8e9cb8">
<h4 id="orgf8e9cb8">Version 3</h4>
<p class="fragment">
Let \(A_1, A_2,\dots\), be a countable partition of \(S\), then
</p>

<p class="fragment">
\[
\mathbb{P}(A_k|B) =  \frac{\mathbb{P}(B|A_k)\mathbb{P}(A_k)}{\sum_i \mathbb{P}(B|A_i)\mathbb{P}(A_i)}
\]
</p>



</section>
</section>
<section>
<section id="slide-orgfd7d840">
<h4 id="orgfd7d840">Example (Medical test)</h4>
<p>
Suppose \(0.1\%\) of the population carries a certain disease. For people with disease, there is a test that correctly gives a positive result \(99.8\%\) of the time.
For people without disease, the test correctly gives a negative result \(99.7\%\) of the time.
</p>

<p class="fragment">
If one&rsquo;s test is positive, what is the probability that the person has the disease?
</p>

<p class="fragment">
Define
</p>

<div class="fragment">
\begin{align*}
  A & = \{ \text{has the disease} \},\\
B & = \{ \text{test is positive} \}.
\end{align*}

</div>

<p class="fragment">
<b>Have</b>:
</p>

<p class="fragment">
\[
\mathbb{P}(A), \quad \mathbb{P}(B|A), \quad \mathbb{P}(B^c|A^c).
\]
</p>

</section>
<section>

<p>
<b>Have</b>:
\[
\mathbb{P}(A), \quad \mathbb{P}(B|A), \quad \mathbb{P}(B^c|A^c).
\]
</p>

<p class="fragment">
<b>Want</b>:
</p>

<p class="fragment">
\(\mathbb{P}(A\cap B)\)?
</p>

<p class="fragment">
No, but
\[
\mathbb{P}(A|B) = \frac{\mathbb{P}(B|A)\mathbb{P}(A)}{\mathbb{P}(B|A)\mathbb{P}(A) + \mathbb{P}(B|A^c)\mathbb{P}(A^c)}.
\]
</p>

</section>
<section>
<p>
How to compute \(\mathbb{P}(B|A^c)\) ?
</p>
<p class="fragment">
\[
\mathbb{P}(B|A^c) = 1 - \mathbb{P}(B^c|A^c) = 0.003
\]
</p>
<p class="fragment">
Thus,
</p>
<p class="fragment">
\[
\mathbb{P}(A|B) = \frac{0.998\cdot 0.001}{0.998 \cdot 0.001 + 0.003 \cdot 0.999} \approx 24.98\%.
\]
</p>

</section>
</section>
<section>
<section id="slide-org5e4f2f0">
<h4 id="org5e4f2f0">Terminology</h4>
<ul>
<li>\(\mathbb{P}(B|A) = 0.998\): true positive rate</li>
<li>\(\mathbb{P}(B^c|A) = 0.002\): false negative rate</li>
<li>\(\mathbb{P}(B^c|A^c) = 0.997\): true negative rate</li>
<li>\(\mathbb{P}(B|A^c) = 0.003\): false positive rate</li>

</ul>

<p class="fragment">
In this example, \(\mathbb{P}(A)\) is often called the <span style="color: rgb(30,144,255)">prior probability</span>, and \(\mathbb{P}(A|B)\) is called the <span style="color: rgb(30,144,255)">posterior probability</span>.
</p>

</section>
</section>
<section>
<section id="slide-org5abbc9d">
<h4 id="org5abbc9d">Example</h4>
<p>
A grocery store gets eggs from \(3\) different farms.
</p>
<ul>
<li>\(20\%\) of eggs come from farm \(1\)</li>
<li>\(30\%\) of eggs come from farm \(2\)</li>
<li>\(50\%\) of eggs come from farm \(3\)</li>
<li>\(5\%\) of egg cartons from farm \(1\) contain a cracked egg</li>
<li>\(3\%\) of egg cartons from farm \(2\) contain a cracked egg</li>
<li>\(2\%\) of egg cartons from farm \(3\) contain a cracked egg</li>

</ul>

<p class="fragment">
If you open a carton, and find a cracked egg, what is the probability that the carton came from farm \(3\)?
</p>

</section>
<section>
<p>
Define
</p>

<div class="fragment">
\begin{align*}
  A_i & = \{ \text{carton from farm $i$ }\}, i = 1, 2, 3,\\
B &  = \{ \text{carton has a cracked egg} \}.
\end{align*}

</div>

<p class="fragment">
<b>Want</b>:
</p>

<p class="fragment">
\[
\mathbb{P}(A_3|B) = \frac{\mathbb{P}(B|A_3)\mathbb{P}(A_3)}{\mathbb{P}(B)}.
\]
</p>

<p class="fragment">
Since
</p>

<div class="fragment">
\begin{align*}
  \mathbb{P}(B) & = \mathbb{P}(B\cap A_1) + \mathbb{P}(B\cap A_2) + \mathbb{P}(B\cap A_3)\\
& = \mathbb{P}(B|A_1)\mathbb{P}(A_1) + \mathbb{P}(B|A_2)\mathbb{P}(A_2) + \mathbb{P}(B|A_3)\mathbb{P}(A_3),
\end{align*}

</div>

<p class="fragment">
\[
\mathbb{P}(A_3|B) = \frac{10}{29}.
\]
</p>

</section>
</section>
<section>
<section id="slide-orgb7968ff">
<h2 id="orgb7968ff">Chapter 3 - Random Variables and Distributions</h2>
<div class="outline-text-2" id="text-orgb7968ff">
</div>
</section>
</section>
<section>
<section id="slide-org5297ea1">
<h3 id="org5297ea1">3.1. Random Variables and Discrete Distributions</h3>
<div class="outline-text-3" id="text-org5297ea1">
</div>
</section>
</section>
<section>
<section id="slide-orgd4aeac0">
<h4 id="orgd4aeac0">Definition</h4>
<p class="fragment">
Given an probability model \((S, \mathbb{P}, \mathcal{F})\), a <b>random variable</b> is a function \(X\) mapping from \(S\) to a set of real numbers:
</p>

<p class="fragment">
\[
X : S \mapsto \mathbb{R}.
\]
</p>

<p class="fragment">
To each possible outcome \(\omega\in S\), \(X\) assigns a real number \(X(\omega)\), which is called an experimental value or a realization of \(X\).
</p>

</section>
</section>
<section>
<section id="slide-org74192b9">
<h4 id="org74192b9">Example</h4>
<p>
Roll two fair six-sided dice.
</p>

<p class="fragment">
Define
</p>
<div class="fragment">
\begin{align*}
  X_1 & = \{ \text{outcome from the first die}\},\\
  X_2 & = \{ \text{outcome from the second die}\},\\
  X & = \{ \text{ sum of the two dice}\},\\
  Y & = \{ \text{ outcome of the second die raised to the fourth power}\},\\
\end{align*}

</div>

<p class="fragment">
Sample space
</p>
<p class="fragment">
\[
S = \{ (i, j) \mid 1\le i, j\le 6, i, j \in \mathbb{N} \},
\]
and \(\# S = 36\).
</p>

</section>
<section>
<p>
Are these functions (mappings) random variables?
</p>

<div class="fragment">
\begin{align*}
  X_1((i, j)) & = i\\
X_2((i,j)) & = j\\
X((i,j)) & = i + j\\
Y((i,j)) & = j^4.
\end{align*}

</div>

<p class="fragment">
<b>Questions</b>: How can we use such notations to express events?
</p>

</section>
<section>
<p>
Let&rsquo;s compute the probability that the outcome from the first die is \(3\).
</p>

<div class="fragment">
\begin{align*}
  & \{ \text{outcome from the first die is $3$}\} = \{ X_1 = 3\}\\
= & \{(i, j) \in S \mid X_1((i,j)) = 3\} = \{(i, j) \in S \mid i = 3\}\\
= & \{(3, 1), (3, 2), \dots, (3, 6)\}.
\end{align*}

</div>

<p class="fragment">
So,
</p>

<p class="fragment">
\[
\mathbb{P}(\{X_1 = 3\}) = \mathbb{P}(X_1 = 3) = \frac{6}{36} = \frac{1}{6}.
\]
</p>

</section>
<section>
<p>
We can compute other probabilities, like
</p>
<p class="fragment">
\[
\mathbb{P}(X_1 = 3, X_2 = 5) = \mathbb{P}(\{X_1 = 3\} \cap \{X_2 = 5\}) = \frac{1}{36},
\]
</p>

<div class="fragment">
\begin{align*}
  \mathbb{P}(X_1 = 3~\text{or}~ X_2 = 5)
& = \mathbb{P}(X_1 = 3) + \mathbb{P}(X_2 = 5) - \mathbb{P}(X_1 = 3, X_2 = 5)\\
& = \frac{1}{6} + \frac{1}{6} - \frac{1}{36} = \frac{11}{36},
\end{align*}

</div>
<p class="fragment">
and
</p>
<p class="fragment">
\[
\mathbb{P}(X = 3) = \mathbb{P}(\{(1, 2), (2, 1)\}) = \frac{2}{36}.
\]
</p>

</section>
</section>
<section>
<section id="slide-org100c816">
<h4 id="org100c816">Notations</h4>
<ul>
<li data-fragment-index="1" class="fragment">\(\{X = c\} = \{\omega \in S \mid X(\omega) = c\}\).</li>
<li data-fragment-index="2" class="fragment">\(\{ a \le X \le b \} = \{ \omega \in S \mid a \le X(\omega) \le b\}\).</li>
<li data-fragment-index="3" class="fragment">\(\{X\in B\} = \{ \omega \in S \mid X(\omega) \in B \}\), \(B\) is a subset of \(\mathbb{R}\).</li>
<li data-fragment-index="4" class="fragment">\(\{X = a, Y = b\} = \{X = a\} \cap \{ Y = b\}\).</li>

</ul>

</section>
</section>
<section>
<section id="slide-orga51c753">
<h4 id="orga51c753">Definition (Probability distribution)</h4>
<p class="fragment">
The <b>probability distribution</b> of a random variable \(X\) is a collection of all probabilities of the form \(\mathbb{P}(X\in B)\), for all subset \(B\subseteq \mathbb{R}\), such that \(\{X\in B\} \in \mathcal{F}\).
</p>

</section>
</section>
<section>
<section id="slide-org6214558">
<h4 id="org6214558">Two types of random variables</h4>
<p class="fragment">
If the <span style="color: rgb(30,144,255)">range</span> of the random variable \(X\) is at most countable (finite or infinitely countable), we call \(X\) a <b>discrete</b> random variable. Otherwise, we call \(X\) is a <b>continuous</b> random variable.
</p>

</section>
</section>
<section>
<section id="slide-orge1ab802">
<h4 id="orge1ab802">Definition</h4>
<p class="fragment">
Let \(X\) be a discrete random variable. The <b>probability mass function</b> (p.m.f.) \(p_X\) is defined by
</p>
<p class="fragment">
\[
p_X(k) = \mathbb{P}(X = k), ~\text{for every real number } k.
\]
</p>

</section>
</section>
<section>
<section id="slide-orgecf564b">
<h4 id="orgecf564b">Theorem</h4>
<p class="fragment">
The probability distribution of a discrete random variable is completely determined by its p.m.f.
</p>

</section>
</section>
<section>
<section id="slide-org6fac0a3">
<h4 id="org6fac0a3">Proof</h4>
<p class="fragment">
For every \(B\subseteq \mathbb{R}\), we have
</p>
<p class="fragment">
\[
\{ X \in B\} = \{ X\in B \cap ~\text{Range}(X)\}.
\]
</p>

<p class="fragment">
Since \(X\) is discrete, \(\text{Range}(X)\) is at most countable, \(B\cap~\text{Range}(X)\) is also at most countable, say
\[
B\cap~\text{Range}(X) = \{k_1, \dots, k_n\} ~\text{or}~ \{k_1, \dots, k_n, \dots \}.
\]
</p>

<p class="fragment">
Therefore,
</p>
<div class="fragment">
\begin{align*}
\mathbb{P}(X \in B)
& = \mathbb{P}(X\in B \cap ~\text{Range}(X)) = \mathbb{P}(\cup_i \{X = k_i\})\\
& = \sum_i \mathbb{P}(X = k_i)\\
& = \sum_i p_X(k_i).
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org7398831">
<h4 id="org7398831">Example</h4>
<p>
Roll two fair dice. Let
</p>
<div>
\begin{align*}
  X_1 & = \{\text{outcome of the first die}\},\\
X & = \{\text{sum of the two dice}\}.
\end{align*}

</div>

<p class="fragment">
What are the p.m.f.s of \(X_1\) and \(X\)?
</p>

</section>
<section>
<p>
For \(X_1\),
</p>

<p class="fragment">
\(\text{Range}(X_1) = \{1, 2, 3, 4, 5, 6\}\), and so \(X_1\) is a discrete random variable.
</p>

<p class="fragment">
Obviously, if \(k\notin \text{Range}(X_1)\),
\[
p_{X_1} (k) = 0.
\]
</p>

<p class="fragment">
For example,
</p>

<p class="fragment">
\[
p_{X_1}(1.5) = \mathbb{P}(X_1 = 1.5) = 0.
\]
</p>

</section>
<section>
<p>
So we only need to consider the case that \(k\in \text{Range}(X_1)\):
</p>

<p class="fragment">
\[
p_{X_1}(k) = \mathbb{P}(X_1 = k) = \frac{1}{6}.
\]
</p>

<p class="fragment">
To sum up,
</p>

<p class="fragment">
\[
p_{X_1}(k) =\begin{cases}
\frac{1}{6}, & k\in \{1, 2, 3, 4, 5, 6\},\\
0, &  k\notin \{1, 2, 3, 4, 5, 6\}.
\end{cases}
\]
</p>

<p class="fragment">
Another way of presenting the probability mass function:
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides" class="fragment">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">\(k\)</th>
<th scope="col" class="org-left">\(1\)</th>
<th scope="col" class="org-left">\(2\)</th>
<th scope="col" class="org-left">\(3\)</th>
<th scope="col" class="org-left">\(4\)</th>
<th scope="col" class="org-left">\(5\)</th>
<th scope="col" class="org-left">\(6\)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">\(p_{X_1}(k)\)</td>
<td class="org-left">\(1/6\)</td>
<td class="org-left">\(1/6\)</td>
<td class="org-left">\(1/6\)</td>
<td class="org-left">\(1/6\)</td>
<td class="org-left">\(1/6\)</td>
<td class="org-left">\(1/6\)</td>
</tr>
</tbody>
</table>

</section>
<section>
<p>
What about \(X\)?
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides" class="fragment">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">\(k\)</th>
<th scope="col" class="org-left">\(2\)</th>
<th scope="col" class="org-left">\(3\)</th>
<th scope="col" class="org-left">\(4\)</th>
<th scope="col" class="org-left">\(5\)</th>
<th scope="col" class="org-left">\(6\)</th>
<th scope="col" class="org-left">\(7\)</th>
<th scope="col" class="org-left">\(8\)</th>
<th scope="col" class="org-left">\(9\)</th>
<th scope="col" class="org-left">\(10\)</th>
<th scope="col" class="org-left">\(11\)</th>
<th scope="col" class="org-left">\(12\)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">\(p_{X}(k)\)</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>
</tbody>
</table>


</section>
</section>
<section>
<section id="slide-org55e1349">
<h4 id="org55e1349">Theorem</h4>
<p class="fragment">
(1) \(p_X(k) = 0\) if \(k\notin \text{Range}(X)\).
</p>

<p class="fragment">
(2) \(\sum_{k\in \text{Range}(X)} p_X(k) = 1\).
</p>

</section>
</section>
<section>
<section id="slide-orga24c2b4">
<h4 id="orga24c2b4">Uniform Distribution on Integers</h4>
<p>
Let \(m< n\) be two integers. Suppose that the value of a random variable \(X\) is equally likely to be each of the integer \(m, m+1, \dots, n\).
</p>

<p class="fragment">
Then we say that \(X\) has the <b>uniform distribution on the integers</b> \(m, m+1, \dots, n\).
</p>

</section>
<section>
<p>
Also, the p.m.f. of \(X\)
</p>

<p class="fragment">
\[
p_X(k) = \begin{cases}
\frac{1}{n-m+1}, &\text{for}~k = m, m+1, \dots, n,\\
0, &\text{otherwise}.
\end{cases}
\]
</p>

<p class="fragment">
The random variable \(X_1\) in the previous example has the uniform distribution on the integers \(1, 2, \dots, 6\).
</p>

<p class="fragment">
<b>Note</b>: <span style="color: rgb(30,144,255)">Random Variables Can Have the Same Distribution without Being the Same Random Variable.</span>
</p>

</section>
</section>
<section>
<section id="slide-org22a1667">
<h4 id="org22a1667">Bernoulli Distributions.</h4>
<p class="fragment">
Flip a coin. Suppose the probability that you get heads is \(p\) (not necessarily to be \(1/2\)), \(p\in [0, 1]\).
</p>

<p class="fragment">
Define \(X\) to be the outcome of the experiment:
</p>

<p class="fragment">
\[
 X(H) = 1, X(T) = 0,
\]
</p>

<p class="fragment">
and
</p>

<p class="fragment">
\[
\text{Range}(X) = \{0, 1\}.
\]
</p>

<p class="fragment">
So the p.m.f. of \(X\):
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides" class="fragment">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">\(k\)</th>
<th scope="col" class="org-right">1</th>
<th scope="col" class="org-right">0</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">\(p_X(k)\)</td>
<td class="org-right">\(p\)</td>
<td class="org-right">\(1-p\)</td>
</tr>
</tbody>
</table>

</section>
</section>
<section>
<section id="slide-orgc108c65">
<h4 id="orgc108c65">Definition</h4>
<p>
Let \(0\le p\le 1\). A random variable \(X\) has the Bernoulli distribution with the &ldquo;success&rdquo; probability \(p\) if \(X\) is \(\{0, 1\}\text{-valued}\) and satisfies \(\mathbb{P}(X=1) = p\) and \(\mathbb{P}(X=0) = 1-p\).
</p>

<p class="fragment">
We write \(X\sim \text{Ber}(p)\).
</p>

</section>
</section>
<section>
<section id="slide-org1d5514d">
<h4 id="org1d5514d">Binomial Distribution</h4>
<p class="fragment">
Flip a (possibly biased) coin \(n\) times.
</p>

<p class="fragment">
\[
S = \{(i_1, i_2, \dots, i_n\}\mid i_1, i_2, \dots, i_n\in \{0, 1\}\}
\]
</p>

<p class="fragment">
Let
</p>

<p class="fragment">
\[
X_i = i\text{-th outcome}, i = 1, 2, \dots, n.
\]
</p>

<p class="fragment">
Then
</p>

<p class="fragment">
\[
X_i \sim \text{Ber}(p),
\]
</p>

<p class="fragment">
where
</p>
<p class="fragment">
\[
p = \mathbb{P}(\{H\}) = \mathbb{P}(X_i = 1).
\]
</p>


</section>
<section>
<p>
Now we define
</p>

<p class="fragment">
\[
X = X_1 + X_2 + \dots + X_n.
\]
</p>

<p class="fragment">
So what does \(X\) mean here?
</p>

<p class="fragment">
For example,
</p>

<p class="fragment">
\[
X((1, 0, \dots, 0)) = 1, X((1, 0, 1, 0, \dots, 0)) = 2.
\]
</p>

<p class="fragment">
What is the p.m.f. of \(X\)?
</p>

</section>
<section>
<p>
First of all,
\[
\text{Range}(X) = \{0, 1, \dots, n\},
\]
and
\[
p_X(k) = 0 \quad \text{if}~ k \notin \text{Range}(X).
\]
</p>

<p class="fragment">
If \(k\in \text{Range}(X)\),
</p>

<p class="fragment">
\[
\{X = k\} = \{\text{we have exactly $k$ times of successes (heads) out of $n$ flips}\}
\]
</p>


<p class="fragment">
Therefore,
</p>

<p class="fragment">
\[
\mathbb{P}(X = k) = \binom{n}{k} p^k (1 - p)^{n-k}.
\]
</p>

</section>
</section>
<section>
<section id="slide-org8cdf74a">
<h4 id="org8cdf74a">Definition</h4>
<p>
Let \(0\le p\le 1\). A random variable is \(X\) has the <b>binomial distribution</b> with parameter \(n\) and \(p\) if
\[
\mathbb{P}(X = k) = \binom{n}{k} p^k (1 - p)^{n-k},
\]
for \(k\in \{0, 1, \dots, n\}\).
</p>

<p class="fragment">
We write \(X\sim \text{Bin}(n, p)\).
</p>

</section>
<section>
<p>
<b>Note</b>:
</p>

<p>
\[
\sum_{k=0}^n \binom{n}{k}p^k (1-p)^{n-k} = ( p + (1-p) )^n = 1^n = 1.
\]
</p>


<p class="fragment">
In particular, if \(p=1/2\), we have
</p>

<p class="fragment">
\[
\sum_{k=0}^n \binom{n}{k} = 2^{n}.
\]
</p>

</section>
</section>
<section>
<section id="slide-org3a62e32">
<h4 id="org3a62e32">Example</h4>
<p>
What is the probability that five rolls of a fair die yield two or three sixes?
</p>

<p class="fragment">
Let \(S_5\) be the number of sixes that appear in the five rolls.
</p>

<p class="fragment">
Want:
</p>

<p class="fragment">
\[
\mathbb{P}(S_5 = 2 ~\text{or}~ S_5 = 3) = \mathbb{P}(S_5 = 2) + \mathbb{P}(S_5 =3).
\]
</p>

<p class="fragment">
Key: \(S_5 \sim \text{Bin}(5, 1/6)\).
</p>

<p class="fragment">
Thus,
</p>
<div class="fragment">
\begin{align*}
 \mathbb{P}(S_5 = 2 ~\text{or}~ S_5 = 3) &
= \mathbb{P}(S_5 = 2) + \mathbb{P}(S_5 =3)\\
& = \binom{5}{2} \left(\frac{1}{6}\right)^2 \left(\frac{5}{6}\right)^3 + \binom{5}{3} \left(\frac{1}{6}\right)^3 \left(\frac{5}{6}\right)^2\\
& \approx 0.193
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orgcd13b21">
<h3 id="orgcd13b21">3.2. Continuous Distributions</h3>
<p>
For a continuous random variable, we introduce its probability density function (p.d.f.).
</p>

</section>
</section>
<section>
<section id="slide-org149a68e">
<h4 id="org149a68e">Definition</h4>
<p>
For a continuous random variable \(X\), if there exists a function \(f_X\), such that
</p>

<p class="fragment">
\[
\mathbb{P}(X\in B) = \int_B f_X(x)\, dx, \quad B\subseteq \mathbb{R},
\]
</p>

<p class="fragment">
then we call this function \(f_X\) the <b>probability density function</b> of \(X\).
</p>

<p class="fragment">
In particular, \(B = [a, b]\),
</p>

<p class="fragment">
\[
\mathbb{P}(a\le X \le b) = \int_a^b f_X(x)\, dx.
\]
</p>

<p class="fragment">
<b>Note</b>:
</p>

<p class="fragment">
(1) \(f_{X}(x) \ge 0\).
</p>

<p class="fragment">
(2) \(\int_{-\infty}^{\infty} f_X(x)\, dx = \mathbb{P}(-\infty < X < \infty) = 1\).
</p>

</section>
</section>
<section>
<section id="slide-orgd03099c">
<h4 id="orgd03099c">Example (Uniform Distribution on Intervals)</h4>
<p class="fragment">
Choose a real number uniformly at random from the interval \([0, 1]\), so the sample space \(S = [0, 1]\).
Assume that \([a, b]\subseteq S\), the probability that the chosen number lies in the interval \([a, b]\) should be equal to the proportion of \(S\) covered by \([a, b]\),
</p>

<p class="fragment">
\[
\mathbb{P}([a, b]) = \frac{b-a}{1-0} = b-a.
\]
</p>

<p class="fragment">
We call the probability model in this example, the <b>uniform distribution</b> on \([0, 1]\), and we write \(X\sim \text{Unif}([0, 1])\).
</p>

</section>
</section>
<section>
<section id="slide-org291cb3e">
<h4 id="org291cb3e">Example</h4>
<p>
Let \(X\sim\text{Unif}([0, 1])\).
</p>

<p class="fragment">
\[
\mathbb{P}(0.5 \le X\le 0.8) = 0.8 - 0.5 = 0.3.
\]
</p>

</section>
</section>
<section>
<section id="slide-orge4ea794">
<h4 id="orge4ea794">Example</h4>
<p>
What if we change the sample space \(S\) to \([-1, 1]\)?
</p>

<p class="fragment">
Consider \([a, b]\subseteq [-1, 1]\),
</p>

<p class="fragment">
\[
\mathbb{P}([a, b]) = \frac{b-a}{1 - (-1)} = \frac{b-a}{2}.
\]
</p>

<p class="fragment">
In general, we say a random variable \(X\) has a uniform distribution on \([c, d], (d>c)\), if
</p>

<p class="fragment">
\[
\mathbb{P}([a, b]) = \frac{b-a}{d-c}, \quad\text{for}~ [a, b]\subseteq [c, d].
\]
</p>

</section>
<section>
<p>
Note that \(\text{Range}(X) = [c, d]\), so what is the p.d.f. of \(X\)?
</p>


<p class="fragment">
\[
f_X(x) = \begin{cases}
\frac{1}{d-c}, &\text{if}~ c\le x\le d;\\
0, &\text{otherwise}.
\end{cases}
\]
</p>

<p class="fragment">
For example, \([a, b] \subseteq [c, d]\),
</p>

<p class="fragment">
\[
\mathbb{P}(a\le X \le b) = \int_a^b f_X(x)\, dx = \int_a^b \frac{1}{d-c} \, dx = \frac{b-a}{d-c}.
\]
</p>

</section>
</section>
<section>
<section id="slide-org07b8f0a">
<h4 id="org07b8f0a">Other continuous distributions.</h4>
<p>
Incompletely specified p.d.f.
</p>

<p class="fragment">
Suppose \(X\) has the p.d.f. defined by
</p>

<p class="fragment">
\[
f_X(x) = \begin{cases}
c x, &\text{if}~ 0 < x < 4,\\
0, &\text{otherwise}.
\end{cases}
\]
</p>

</section>
<section>
<p>
(1) Find \(c\)?
</p>

<p class="fragment">
Fact:
</p>

<p class="fragment">
\[
\int_{-\infty}^{\infty} f_X(x) \, dx = 1.
\]
</p>

<p class="fragment">
But,
</p>

<p class="fragment">
\[
\int_{-\infty}^{\infty} f_X(x) \, dx = \int_{-\infty}^{0} f_X(x) \, dx  +  \int_{0}^{4} f_X(x) \, dx + \int_{4}^{\infty} f_X(x) \, dx  = \int_{0}^{4} f_X(x) \, dx,
\]
</p>

<p class="fragment">
and
</p>

<p class="fragment">
\[
\int_{0}^{4} f_X(x) \, dx = \int_{0}^{4} c x \, dx = 8c.
\]
</p>

<p class="fragment">
Therefore,
</p>

<p class="fragment">
\[
c = \frac{1}{8}.
\]
</p>

</section>
<section>
<p>
(2) Compute \(\mathbb{P}(1\le X\le 2)\).
</p>

<div class="fragment">
\begin{align*}
  \mathbb{P}(1 \le X \le 2)
& = \int_1^2 f_X(x)\, dx = \int_1^2 \frac{1}{8} x \, dx\\
& = \frac{3}{16}.
\end{align*}

</div>


</section>
<section>
<p>
(3) Compute \(\mathbb{P}(-5\le X\le 3)\).
</p>


<div class="fragment">
\begin{align*}
  \mathbb{P}(-5 \le X \le 3)
& = \int_{-5}^0 f_X(x)\, dx + \int_0^3 f_X(x)\, dx\\
& = \int_0^3 \frac{1}{8} x \, dx = \frac{9}{16}.
\end{align*}

</div>

</section>
<section>
<p>
(4) Compute \(\mathbb{P}(-5 \le X\le 5)\).
</p>

<div class="fragment">
\begin{align*}
  \mathbb{P}(-5 \le X \le 5)
& = \int_{-5}^5 f_X(x)\, dx = \int_0^4 \frac{1}{8} x \, dx\\
& = 1.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org2263a9e">
<h3 id="org2263a9e">3.3. The Cumulative Distribution Functions</h3>
<div class="outline-text-3" id="text-org2263a9e">
</div>
</section>
</section>
<section>
<section id="slide-org42a10a4">
<h4 id="org42a10a4">Example</h4>
<p class="fragment">
Suppose the p.d.f of \(X\) is defined by
</p>

<p class="fragment">
\[
  f_X(x) =\begin{cases}
  \dfrac{1}{(1+x)^2}, & x>0,\\
  0, & x\le 0.
\end{cases}
\]
</p>

<p class="fragment">
Compute
</p>

<p class="fragment">
\[
\mathbb{P}(X \le t),\quad \text{for all}~ t \in \mathbb{R}.
\]
</p>

</section>
<section>
<div>
\begin{align*}
  \mathbb{P}(X\le t)
& = \mathbb{P}(-\infty < X \le t) = \int_{-\infty}^t f_X(x)\, dx\\
& = \int_{-\infty}^0 f_X(x)\, dx + \int_0^t f_X(x)\, dx\\
& = \int_0^t \frac{1}{(1 + x)^2}\, dx = \int_1^{1+t} \frac{1}{u^{2}}\, du\\
& = - \left.\frac{1}{u}\right|_1^{1+t} = - \frac{1}{1+t} + 1\\
& =  1 - \frac{1}{1+t} = \frac{t}{1+t}.
\end{align*}

</div>

</section>
<section>
<p>
If \(t = 3\),
</p>


<p class="fragment">
\[
\mathbb{P}(X \le 3) = \frac{3}{1+3} = \frac{3}{4}.
\]
</p>

<p class="fragment">
If \(t= 2\),
</p>

<p class="fragment">
\[
\mathbb{P}(X \le 2) = \frac{2}{3}.
\]
</p>


</section>
<section>
<p>
Also, we can compute
</p>

<p class="fragment">
\[
\mathbb{P}(X > 2) = 1 - \mathbb{P}(X \le 2) = 1 - \frac{2}{3} = \frac{1}{3},
\]
and
</p>

<div class="fragment">
\begin{align*}
  \mathbb{P}(2 < X \le 3)
& = \mathbb{P}(X \le 3) - \mathbb{P}(X \le 2)\\
& = \frac{3}{4} - \frac{2}{3} = \frac{1}{12}.
\end{align*}

</div>

</section>
<section>
<p>
What if \(t = -1\)?
</p>

<p class="fragment">
\[
\mathbb{P}(X \le -1) = \frac{-1}{1 + (-1)} = \frac{-1}{0}?
\]
</p>

<p class="fragment">
Where went <span style="color: rgb(255,0,0)">wrong</span>?
</p>

<p class="fragment">
<span style="color: rgb(255,0,0)">Warning</span>:
</p>

<p class="fragment">
\[
\mathbb{P}(X \le t) = \frac{t}{1+t}, \quad \text{only when} ~t \ge 0!
\]
</p>

<p class="fragment">
If \(t<0\), we have
</p>


<p class="fragment">
\[
\mathbb{P}(X \le t) = 0.
\]
</p>

</section>
<section>
<p>
To sum up,
</p>

<p class="fragment">
\[
\mathbb{P}(X \le t) = \begin{cases}
\frac{t}{1+t}, & t\ge 0,\\
0, & t<0.
\end{cases}
\]
</p>

</section>
</section>
<section>
<section id="slide-org8f97053">
<h4 id="org8f97053">Definition</h4>
<p>
Let \(X\) be a random variable. The <b>cumulative distribution function</b> (CDF) of \(X\) is defined by
</p>

<p class="fragment">
\[
F_X(t) = \mathbb{P}(X \le t), \quad t\in \mathbb{R}.
\]
</p>

<p class="fragment">
<b>Note</b>: CDF can be defined for both discrete and continuous random variables.
</p>

</section>
</section>
<section>
<section id="slide-orgbc85994">
<h4 id="orgbc85994">Example</h4>
<p>
What is the CDF of a Bernoulli random variable?
</p>

<p class="fragment">
Suppose \(X\sim \text{Ber}(p)\), i.e., \(p_X(1) = p, p_X(0)=1-p\).
</p>

<p class="fragment">
<b>Want</b>: \(F_{X}(t) = \mathbb{P}(X \le t)\) for all \(t \in \mathbb{R}\).
</p>

<p class="fragment">
Let&rsquo;s just try out some values of \(t\).
</p>

<p class="fragment">
\[
F_X(0) = \mathbb{P}(X \le 0) = p_X(0) = \mathbb{P}(X =0) = 1 - p.
\]
</p>

<p class="fragment">
\[
F_X(0.5) = \mathbb{P}(X \le 0.5) = p_X(0)  = 1 - p.
\]
</p>

<p class="fragment">
\[
F_X(-1) = \mathbb{P}( X \le -1 ) = 0.
\]
</p>

<p class="fragment">
\[
F_X(5) = \mathbb{P}(X \le 5) = p_X(0) + p_X(1) = 1 - p + p = 1.
\]
</p>

</section>
<section>
<p>
To sum up,
</p>

<p class="fragment">
\[
F_X(t) = \begin{cases}
1, & t \ge 1,\\
1 - p , & 0 \le t < 1, \\
0, & t < 0.
\end{cases}
\]
</p>


<p class="fragment">
The following is the plot of the CDF of Ber\((p)\).
</p>


<div id="org999dab8" class="figure">
<p><img src="../img/beroulli-cdf.svg" alt="beroulli-cdf.svg" class="fragment middle" width="75%" />
</p>
</div>

</section>
</section>
<section>
<section id="slide-orgc4ec9e8">
<h4 id="orgc4ec9e8">Properties of CDF</h4>
<p class="fragment">
(1) \(F\) is non-decreasing: if \(s < t\), \(F(s) \le F(t)\).
</p>

<p class="fragment">
(2) \(\lim_{t \to -\infty} F(t) = \lim_{t \to -\infty} \mathbb{P}(X \le t) = 0\).
</p>

<p class="fragment">
(3) \(0 \le F(t) \le 1\).
</p>

<p class="fragment">
(4) \(F\) is right-continuous.
</p>

</section>
<section>
<p>
If \(X\) is discrete with p.m.f. \(p_X\), then
</p>

<p class="fragment">
\[
F_X(t) = \mathbb{P}(X \le t) = \sum_{k \le t} p_X(k).
\]
</p>

<p class="fragment">
The graph of \(F\) is a non-decreasing right-continuous staircase.
</p>


<div id="org42aeeff" class="figure">
<p><img src="../img/discrete-cdf.svg" alt="discrete-cdf.svg" class="fragment middle" width="75%" />
</p>
</div>

</section>
<section>
<p>
If \(X\) is continuous with p.d.f. \(f_X(x)\), then
</p>

<p class="fragment">
\[
F_X(t) = \mathbb{P}(X \le t) = \int_{-\infty}^t  f_X(x) \, dx.
\]
</p>

<p class="fragment">
\[
F'_X(t) = f_X(t).
\]
</p>

<p class="fragment">
The graph of \(F_X\) is non-decreasing and continuous.
</p>

<div id="orgd81d919" class="figure">
<p><img src="../img/normal-cdf.svg" alt="normal-cdf.svg" class="fragment middle" width="75%" />
</p>
</div>

</section>
</section>
<section>
<section id="slide-org94e187a">
<h4 id="org94e187a">Theorem</h4>
<p class="fragment">
For \(t \in \mathbb{R}\),
</p>

<p class="fragment">
(1) \(\mathbb{P}(X > t) = 1 - \mathbb{P}(X \le t) = 1 - F_X(t)\).
</p>

<p class="fragment">
(2) \(\mathbb{P}(s < X \le t) = \mathbb{P}(X \le t) - \mathbb{P}(X \le s) = F_X(t) - F_X(s)\).
</p>

<p class="fragment">
(3) \(\mathbb{P}(X < t) = \lim_{s \to t - } \mathbb{P}(X \le s) = F_X(t-)\).
</p>

<p class="fragment">
(4) \(\mathbb{P}(X = t) = \mathbb{P}(X \le t) - \mathbb{P}(X < t) = F_X(t) - F_X(t-)\).
</p>

<p class="fragment">
In particular, if \(F_X\) is continuous,
</p>

<p class="fragment">
\[
\mathbb{P}(X = t) = 0,
\]
</p>

<p class="fragment">
which can also be derived by the fact that
</p>

<p class="fragment">
\[
\int_t^t  f_X(x) \, dx = 0.
\]
</p>

</section>
<section>
<p>
<b>Note</b>:
</p>

<p class="fragment">
\[
X~ \text{is continuous} \Rightarrow F_X~ \text{is continuous}
\]
</p>

<p class="fragment">
<span style="color: rgb(255,0,0)">Warning</span>:
</p>

<p class="fragment">
\[
\mathbb{P}(A) = 0 \nRightarrow A = \emptyset.
\]
</p>

<p class="fragment">
For example, Let \(A\) be the event that you pick \(0.4\) uniformly from \([0, 1]\), then \(\mathbb{P}(A) = 0\), but \(A \neq \emptyset\).
</p>

</section>
</section>
<section>
<section id="slide-org146d25d">
<h3 id="org146d25d">3.4. Bivariate Distributions</h3>
<div class="outline-text-3" id="text-org146d25d">
</div>
</section>
</section>
<section>
<section id="slide-orgcceb624">
<h4 id="orgcceb624">Definition</h4>
<p>
Let \(X\) and \(Y\) be two random variables. The <b>bivariate (or joint) distributions</b> of \(X\) and \(Y\) is the collection of all probabilities of the form \(\mathbb{P}((X, Y) \in C)\) for all sets \(C\) of pair of real numbers such that
</p>

<p class="fragment">
\[
\{ (X, Y) \in C\} = \{ \omega \in S \mid ((X(\omega), Y(\omega)) \in C\},
\]
</p>

<p class="fragment">
where \(C \in \mathbb{R}^2 = \mathbb{R}\times \mathbb{R}\).
</p>

</section>
</section>
<section>
<section id="slide-orgb136dad">
<h4 id="orgb136dad">Discrete Joint Distributions</h4>
<p class="fragment">
<b>Theorem</b>. If \(X\) and \(Y\) are both discrete, then \((X, Y)\) has a discrete joint distribution.
</p>

</section>
</section>
<section>
<section id="slide-orga223aea">
<h4 id="orga223aea">Joint Probability Mass Function</h4>
<p class="fragment">
Recall: p.m.f. of \(X\)
</p>

<p class="fragment">
\[
p_X(k) = \mathbb{P}(X = k).
\]
</p>

<p class="fragment">
For \((X, Y)\), we define
</p>

<p class="fragment">
\[
p_{X, Y}(k, l) = \mathbb{P}(X = k, Y = l), \quad \text{for all}~ k, l \in \mathbb{R}.
\]
</p>

<p class="fragment">
Facts:
</p>

<p class="fragment">
(1) \(p_{X, Y}(k, l) = 0\) if either \(k \notin \text{Range}(X)\) or \(l \notin \text{Range}(Y)\).
</p>

<p class="fragment">
(2) \(\sum_{k, l} p_{X, Y}(k, l) = 1\).
</p>

</section>
</section>
<section>
<section id="slide-orge49d808">
<h4 id="orge49d808">Example</h4>
<p>
Roll 2 fair four sided dice.
</p>

<p class="fragment">
Let \(U\) be the outcome of the first die and \(V\) be the outcome of the second die. Then
</p>

<p class="fragment">
\[
\text{Range}(U) = \text{Range}(V) = \{1, 2, 3, 4\}.
\]
</p>

<p class="fragment">
The joint p.m.f. of \((U, V)\) is
</p>

<p class="fragment">
\[
p_{U, V}(k, l) = \mathbb{P}(U = k, V = l) = \begin{cases}
\frac{1}{16}, & k, l \in \{1, 2, 3, 4\},\\
0, & \text{otherwise}.
\end{cases}
\]
</p>

</section>
<section>
<p>
We can also use a two way table to present the joint p.m.f. as follows:
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides" class="fragment">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">\(1\)</th>
<th scope="col" class="org-left">\(2\)</th>
<th scope="col" class="org-left">\(3\)</th>
<th scope="col" class="org-left">\(4\)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">\(1\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/16\)</td>
</tr>

<tr>
<td class="org-left">\(2\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/16\)</td>
</tr>

<tr>
<td class="org-left">\(3\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/16\)</td>
</tr>

<tr>
<td class="org-left">\(4\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/16\)</td>
</tr>
</tbody>
</table>

</section>
<section>
<p>
Now define
</p>

<div class="fragment">
\begin{align*}
  X & = \min\{U, V\},\\
Y & = |U - V|.
\end{align*}

</div>

<p class="fragment">
For example,
</p>

<p class="fragment">
\[
U = 2, V = 4 \Rightarrow X = 2, Y = 2,
\]
</p>

<p class="fragment">
and
</p>

<p class="fragment">
\[
U = 3, V = 1 \Rightarrow X = 1, Y = 2.
\]
</p>

<p class="fragment">
Note that
</p>

<div class="fragment">
\begin{align*}
  \text{Range}(X) & = \{1, 2, 3, 4\},\\
\text{Range}(Y) & = \{0, 1, 2, 3\}.
\end{align*}

</div>

</section>
<section>
<p>
What is the joint p.m.f. of \((X, Y)\)?
</p>

<p>
For example,
</p>
<p class="fragment">
\[
p_{X, Y}(3, 0) = \mathbb{P}(X = 3, Y = 0) = \mathbb{P}(U = 3, V = 3) = \frac{1}{16},
\]
</p>

<p class="fragment">
and
</p>
<div class="fragment">
\begin{align*}
p_{X, Y}(1, 3) & = \mathbb{P}(X = 1, Y = 3) \\
& = \mathbb{P}(U = 1, V = 4) + \mathbb{P}(U = 4, V = 1) = \frac{1}{8}.
\end{align*}

</div>

<p class="fragment">
However,
</p>

<p class="fragment">
\[
p_{X, Y}(2, 3) = \mathbb{P}(X = 2, Y = 3) = 0.
\]
</p>

</section>
<section>
<p>
(1) For \(k \in \{1, 2, 3, 4\}, l = 0\):
</p>

<p class="fragment">
\[
p_{X, Y}(k, 0) = \mathbb{P}(X = k, Y = 0) = \mathbb{P}(U = k, V = k) = \frac{1}{16}.
\]
</p>

<p class="fragment">
(2) For \(k\in \{1, 2, 3, 4\}, l \in \{1, 2, 3\}\):
</p>

<div class="fragment">
\begin{align*}
  p_{X, Y}(k, l) & = \mathbb{P}(\text{one die is $k$, and the other is $k+l$})\\
& = \mathbb{P}(U = k, V = k+ l) + \mathbb{P}(U = k + l, V = k)\\
& \begin{cases}
\frac{1}{8}, & \text{if}~k + l \le 4,\\
0, & \text{if}~ k + l > 4.
\end{cases}
\end{align*}

</div>

</section>
<section>
<p>
Therefore, we have the following table:
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides" class="fragment">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">\(0\)</th>
<th scope="col" class="org-left">\(1\)</th>
<th scope="col" class="org-left">\(2\)</th>
<th scope="col" class="org-left">\(3\)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">\(1\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/8\)</td>
<td class="org-left">\(1/8\)</td>
<td class="org-left">\(1/8\)</td>
</tr>

<tr>
<td class="org-left">\(2\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/8\)</td>
<td class="org-left">\(1/8\)</td>
<td class="org-left">\(0\)</td>
</tr>

<tr>
<td class="org-left">\(3\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/8\)</td>
<td class="org-left">\(0\)</td>
<td class="org-left">\(0\)</td>
</tr>

<tr>
<td class="org-left">\(4\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(0\)</td>
<td class="org-left">\(0\)</td>
<td class="org-left">\(0\)</td>
</tr>
</tbody>
</table>

<p class="fragment">
Now we can even compute:
</p>

<p class="fragment">
\[
\mathbb{P}(X \le 2, Y \le 1) = \frac{1}{16} + \frac{1}{8} +\frac{1}{16} + \frac{1}{8} = \frac{3}{8}.
\]
</p>

</section>
</section>
<section>
<section id="slide-orgdc9567d">
<h4 id="orgdc9567d">Continuous Joint Distributions</h4>
<p>
<b>Definition</b>
Two random variables \(X\) and \(Y\) have a <b>continuous joint distribution</b> if there exists a non-negative function \(f\) such that
</p>

<p class="fragment">
\[
\mathbb{P}((X, Y) \in C) = \iint_C f(x, y) \, dx dy.
\]
</p>

<p class="fragment">
Here, \(f(x, y)\) is called the joint p.d.f. of \(X\) and \(Y\).
</p>


<p class="fragment">
<b>Note</b>:
</p>

<p class="fragment">
(1) \(f(x, y) \ge 0, \forall x, y \in \mathbb{R}\).
</p>

<p class="fragment">
(2) \(\int_{-\infty}^\infty \int_{-\infty}^\infty f(x, y) \, dx dy = 1\).
</p>

</section>
</section>
<section>
<section id="slide-org2055220">
<h4 id="org2055220">Example 3.4.7</h4>
<p>
Suppose that the joint p.d.f. of \(X\) and \(Y\) is
</p>

<p class="fragment">
\[
f(x, y) = \begin{cases}
c x^2y, & x^2 \le y \le 1,\\
0, & \text{otherwise}.
\end{cases}
\]
</p>

<p class="fragment">
(1) Find \(c\)?
</p>

<div class="column" style="float:left; width: 50%">
<div class="fragment">
\begin{align*}
 1 & = \int_{-\infty}^\infty \int_{-\infty}^\infty f(x, y) \, dx dy\\
& = \iint_A c x^2 y \, dx dy\\
& = \int_{-1}^1  \int_{x^2}^1 c x^2 y \, dy dx\\
& = \frac{4}{21} c,
\end{align*}

</div>

</div>
<div class="column" style="float:right; width: 50%">

<div id="org392e721" class="figure">
<p><img src="../img/eg3-4-7.svg" alt="eg3-4-7.svg" class="fragment" />
</p>
</div>
</div>

<p class="fragment">
so \(c = 21/4\).
</p>

</section>
<section>
<p>
(2) Compute \(\mathbb{P}(X \ge Y)\).
</p>

<p class="fragment">
Recall that
</p>

<p class="fragment">
\[
\mathbb{P}((X, Y) \in C) = \iint_C f(x, y) \, dx dy.
\]
</p>

<p class="fragment">
Thus,
</p>

<div class="column" style="float:left; width: 50%">
<div class="fragment">
\begin{align*}
  \mathbb{P}(X \ge Y)
& = \iint_{\{x \ge y\}} f(x, y) \, dx dy \\
& = \iint_{\{x \ge y\} \cap A} \frac{21}{4} x^2 y \, dx dy \\
& = \int_{0}^1 \int_{x^2}^x  \frac{21}{4} x^2 y \, dy dx\\
&  = \frac{3}{20}.
\end{align*}

</div>

</div>
<div class="column" style="float:right; width: 50%">

<div id="orgc7e005d" class="figure">
<p><img src="../img/eg3-4-7-2.svg" alt="eg3-4-7-2.svg" class="fragment" />
</p>
</div>
</div>

</section>
</section>
<section>
<section id="slide-org7ffd6c2">
<h4 id="org7ffd6c2">Bivariate CDF</h4>
<p>
<b>Definition</b>.
Given two random variables \(X\) and \(Y\), then the <b>joint CDF</b> of \((X, Y)\) is
</p>

<p class="fragment">
\[
F_{X, Y}(x, y) = F(x, y) = \mathbb{P}(X \le x, Y \le y).
\]
</p>

</section>
</section>
<section>
<section id="slide-org5876e5a">
<h4 id="org5876e5a">Example</h4>
<p class="fragment">
Suppose \(a < b, c < d\).
</p>

<p class="fragment">
Express \(\mathbb{P}(a < X \le b, c < Y \le d)\) in terms of \(F_{X, Y}\).
</p>

<p class="fragment">
Recall that
</p>

<div class="fragment">
\begin{align*}
  \mathbb{P}(X \le t)& = F_X(t),\\
\mathbb{P}(s < X \le t) & = F_X(t) - F_X(s).
\end{align*}

</div>

</section>
<section>
<div>
\begin{align*}
  \mathbb{P}(a < X \le b, c < Y \le d)
& = \mathbb{P}(X \le b, c < Y \le d) - \mathbb{P}(X \le a, c < Y, \le d)\\
& = \mathbb{P}(X \le b, Y \le d) - \mathbb{P}(X \le b, Y \le c )\\
& \quad - \left(\mathbb{P}( X \le a, Y \le d ) - \mathbb{P}(X \le a, Y \le c)\right)\\
& = F(b, d)  - F(b, c) - F(a, d) + F(a, c).
\end{align*}

</div>

</section>
<section>
<p>
Recall that if \(X\) is continuous with p.d.f. \(f(x)\), then
</p>

<p class="fragment">
\[\begin{cases}
F(x) & = \mathbb{P}(X \le x) = \int_{-\infty}^x f(t) \, dt, \\
F'(x) &= f(x).
\end{cases}
\]
</p>

<p class="fragment">
If \(X, Y\) are continuous, then
</p>

<p class="fragment">
\[
F(x, y) = \mathbb{P}(X \le x, Y \le y) = \int_{-\infty}^y \int_{-\infty}^x f(u, v)\, du dv,
\]
</p>

<p class="fragment">
and
</p>

<p class="fragment">
\[
f(x, y) = \frac{\partial^2 F(x, y)}{\partial x \partial y}.
\]
</p>

</section>
</section>
<section>
<section id="slide-orge6c16d7">
<h4 id="orge6c16d7">Example</h4>
<p>
Suppose the joint CDF of \((X, Y)\) is
</p>
<p class="fragment">
\[
F(x, y) = \begin{cases}
\frac{1}{16} x y (x + y), & 0\le x \le 2, 0 \le y \le 2,\\
0, & \text{otherwise}.
\end{cases}
\]
</p>

<p class="fragment">
Find \(f(x, y)\).
</p>

<div class="fragment">
\begin{align*}
  \frac{\partial F}{\partial x}
& = \frac{\partial}{\partial x}\left[\frac{1}{16} x y(x+y)\right] = \frac{1}{16} \frac{\partial}{\partial x}(x^2 y + xy^2)\\
& = \frac{1}{16}( 2xy + y^2 ).
\end{align*}

</div>

<p class="fragment">
Then
</p>

<div class="fragment">
\begin{align*}
  \frac{\partial^2 F}{\partial x \partial y}
& = \frac{\partial}{\partial y}\left[\frac{1}{16}( 2xy + y^2 )\right] = \frac{1}{16}(2x + 2y) = \frac{x + y}{8}.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org0ad5ac3">
<h3 id="org0ad5ac3">3.5. Marginal Distributions</h3>
<div class="outline-text-3" id="text-org0ad5ac3">
</div>
</section>
</section>
<section>
<section id="slide-org1196207">
<h4 id="org1196207">Theorem</h4>
<p class="fragment">
(1) If \(X\) and \(Y\) are discrete random variables, then the p.m.f. of \(X\) and \(Y\) are obtained from the joint p.m.f. of \((X, Y)\) by
</p>

<div class="fragment">
\begin{align*}
  p_X(k) & = \sum_l p_{X, Y}(k, l),\\
p_Y(l) & = \sum_k p_{X, Y}( k, l ).
\end{align*}

</div>

<p class="fragment">
Idea of the proof: <span style="color: rgb(30,144,255)">law of total probability.</span>
</p>

<p class="fragment">
\[
\mathbb{P}(A) = \sum_{k=1}^{\infty} \mathbb{P}(A \cap B_{k}).
\]
</p>
</section>
<section>
<p>
(2) If \(X\) and \(Y\) are continuous random variables, then the p.d.f.s of \(X\) and \(Y\) are obtained from the joint p.d.f. of \((X, Y)\) by
</p>

<div class="fragment">
\begin{align*}
  f_X(x) = \int_{-\infty}^{\infty} f_{X, Y}(x, y) \, dy,\\
f_Y(y) = \int_{-\infty}^{\infty} f_{X, Y}(x, y) \, dx.
\end{align*}

</div>

</section>
<section>
</section>
</section>
<section>
<section id="slide-orgb0ee76d">
<h4 id="orgb0ee76d">Example (Deriving Marginal p.m.f. from Joint p.m.f.)</h4>
<p class="fragment">
Recall
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides" class="fragment">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">\(0\)</th>
<th scope="col" class="org-left">\(1\)</th>
<th scope="col" class="org-left">\(2\)</th>
<th scope="col" class="org-left">\(3\)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">\(1\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/8\)</td>
<td class="org-left">\(1/8\)</td>
<td class="org-left">\(1/8\)</td>
</tr>

<tr>
<td class="org-left">\(2\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/8\)</td>
<td class="org-left">\(1/8\)</td>
<td class="org-left">\(0\)</td>
</tr>

<tr>
<td class="org-left">\(3\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/8\)</td>
<td class="org-left">\(0\)</td>
<td class="org-left">\(0\)</td>
</tr>

<tr>
<td class="org-left">\(4\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(0\)</td>
<td class="org-left">\(0\)</td>
<td class="org-left">\(0\)</td>
</tr>
</tbody>
</table>

<div class="fragment">
\begin{align*}
  \mathbb{P}(X = 1)
& = \mathbb{P}(X = 1, Y = 0) + \mathbb{P}(X = 1, Y = 1) \\
& \quad + \mathbb{P}(X = 1, Y = 2) + \mathbb{P}(X = 1, Y = 3)\\
& = \frac{1}{16} + \frac{1}{8} + \frac{1}{8} + \frac{1}{8} = \frac{7}{16}.
\end{align*}

</div>

<p class="fragment">
\[
\mathbb{P}(Y = 2) = \frac{1}{8} + \frac{1}{8} + 0 + 0 = \frac{1}{4}.
\]
</p>

</section>
</section>
<section>
<section id="slide-orgedc72c3">
<h4 id="orgedc72c3">Example (Deriving Marginal p.d.f. from Joint p.d.f.)</h4>
<p class="fragment">
Recall
</p>

<p class="fragment">
\[
f(x, y) = \begin{cases}
\frac{21}{4} x^2y, & x^2 \le y \le 1,\\
0, & \text{otherwise}.
\end{cases}
\]
</p>

<p class="fragment">
What is \(f_X(x)\, (f_Y(y))\)?
</p>

</section>
<section>
<div class="column" style="float:left; width: 50%">
<div>
\begin{align*}
  f_X(x)
& = \int_{-\infty}^{\infty} f_{X, Y}(x, y) \, dy\\
& \neq   \int_{-\infty}^{\infty} \frac{21}{4} x^2y  \, dy\\
& \neq \int_0^1 \frac{21}{4} x^2y  \, dy\\
& = \begin{cases}
\int_{x^{2}}^1 \frac{21}{4} x^2y \, dy, & -1 \le x \le 1,\\
0, & x< -1 ~\text{or}~ x>1.
\end{cases}\\
& = \begin{cases}
\frac{21}{8} x^2 ( 1 - x^{4} ), & -1 \le x \le 1,\\
0, & x< -1 ~\text{or}~ x>1.
\end{cases}
\end{align*}

</div>

</div>

<div class="column" style="float:right; width: 50%">

<div id="org365a7a4" class="figure">
<p><img src="../img/eg3-4-7.svg" alt="eg3-4-7.svg" class="fragment" />
</p>
</div>
</div>


</section>
<section>
<div>
\begin{align*}
  f_Y(y)
& = \int_{-\infty}^{\infty} f_{X, Y}(x, y) \, dx\\
& = \begin{cases}
\int_{-\sqrt{y}}^{\sqrt{y}} \frac{21}{4} x^2y \, dx, & 0 \le y \le 1,\\
0, & y > 1 ~\text{or}~ y < 0.
\end{cases}\\
& = \begin{cases}
\frac{7}{2} y^{5/2}, & 0 \le y \le 1,\\
0, & y > 1 ~\text{or}~ y < 0.
\end{cases}
\end{align*}

</div>


<div id="org3839da2" class="figure">
<p><img src="../img/eg3-4-7.svg" alt="eg3-4-7.svg" class="fragment middle" width="60%" />
</p>
</div>

</section>
</section>
<section>
<section id="slide-org9776e7b">
<h4 id="org9776e7b">Independent Random Variables</h4>
<p class="fragment">
Recall: Events \(A\) and \(B\) are independent, if
</p>

<p class="fragment">
\[
\mathbb{P}(A \cap B) = \mathbb{P}(A) \mathbb{P}(B).
\]
</p>

<p class="fragment">
<b>Definition</b>
</p>

<p class="fragment">
We say random variables \(X\) and \(Y\) are independent, if
</p>

<p class="fragment">
\[
\mathbb{P}(X \in A , Y \in B) = \mathbb{P}(X \in A) \mathbb{P}(Y \in B)
\]
</p>
<p class="fragment">
for all \(A, B \subseteq \mathbb{R}\).
</p>

<p class="fragment">
In particular, if \(A = (-\infty, x], B = (-\infty, y]\), then
</p>

<p class="fragment">
\[
X ~\text{and}~ Y ~\text{are independent}~ \Rightarrow \mathbb{P}(X \le x, Y \le y) = \mathbb{P}(X \le x) \mathbb{P}(Y \le y).
\]
</p>

</section>
</section>
<section>
<section id="slide-org58b9b95">
<h4 id="org58b9b95">Theorem</h4>
<p class="fragment">
(1) \(X\) and \(Y\) are independent if and only if
</p>

<p class="fragment">
\[
F_{X, Y}(x, y) = F_X(x) F_Y(y) \quad \forall x, y \in \mathbb{R}.
\]
</p>

<p class="fragment">
(2) \(X\) and \(Y\) are independent if and only if the following factorization is satisfied:
</p>

<p class="fragment">
<span style="color: rgb(30,144,255)">Continuous</span> case: \[f_{X, Y}(x, y) = f_1(x) f_2(y), \, \forall x, y \in \mathbb{R}.\]
</p>

<p class="fragment">
<span style="color: rgb(30,144,255)">Discrete</span> case: \[p_{X, Y}(k, l) = p_X(k) p_Y(l), \, \forall k, l \in \mathbb{R}.\]
</p>

</section>
</section>
<section>
<section id="slide-orgbd0f457">
<h4 id="orgbd0f457">Example</h4>
<p>
Flip a fair coin twice.
</p>

<p class="fragment">
Let \(X\) be the outcome of the first flip, and \(Y\) be the second. Then we have
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides" class="fragment">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">\(0\)</th>
<th scope="col" class="org-left">\(1\)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">\(0\)</td>
<td class="org-left">\(1/4\)</td>
<td class="org-left">\(1/4\)</td>
</tr>

<tr>
<td class="org-left">\(1\)</td>
<td class="org-left">\(1/4\)</td>
<td class="org-left">\(1/4\)</td>
</tr>
</tbody>
</table>

<p class="fragment">
It is easy to check that
</p>

<p class="fragment">
\[
p_{X, Y}(k, l) = p_X(k) p_Y(l), \, \forall k, l.
\]
</p>

<p class="fragment">
So \(X\) and \(Y\) are independent.
</p>

</section>
</section>
<section>
<section id="slide-org7f9e3df">
<h4 id="org7f9e3df">Example</h4>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">\(0\)</th>
<th scope="col" class="org-left">\(1\)</th>
<th scope="col" class="org-left">\(2\)</th>
<th scope="col" class="org-left">\(3\)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">\(1\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/8\)</td>
<td class="org-left">\(1/8\)</td>
<td class="org-left">\(1/8\)</td>
</tr>

<tr>
<td class="org-left">\(2\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/8\)</td>
<td class="org-left">\(1/8\)</td>
<td class="org-left">\(0\)</td>
</tr>

<tr>
<td class="org-left">\(3\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(1/8\)</td>
<td class="org-left">\(0\)</td>
<td class="org-left">\(0\)</td>
</tr>

<tr>
<td class="org-left">\(4\)</td>
<td class="org-left">\(1/16\)</td>
<td class="org-left">\(0\)</td>
<td class="org-left">\(0\)</td>
<td class="org-left">\(0\)</td>
</tr>
</tbody>
</table>

<p class="fragment">
Are \(X\) and \(Y\) independent?
</p>

<p class="fragment">
No!
</p>

<p class="fragment">
For example, \(p_X(1) = 7/16, p_Y(0) = 1/4\), but \(p_{X, Y}(1, 0) = 1/16\), and
</p>

<p class="fragment">
\[
p_{X, Y}(1, 0) \neq p_X(1) p_Y(0).
\]
</p>

</section>
</section>
<section>
<section id="slide-orgfee1515">
<h4 id="orgfee1515">Example</h4>
<p class="fragment">
Let \((X, Y) \sim \text{Unif}(A)\), where \(A = [a, b]\times [c, d]\), i.e.,
</p>

<p class="fragment">
\[
f(x, y) = \begin{cases}
\frac{1}{\text{area}(A)} = \frac{1}{(b-a)(d-c)}, & (x, y) \le A,\\
0, & \text{otherwise}.
\end{cases}
\]
</p>

<p class="fragment">
Are \(X\) and \(Y\) independent?
</p>

<p class="fragment">
<b>Check</b>: \(f(x, y) = f_1(x) f_2(y)\) ?
</p>

</section>
<section>
<p>
First, we need to calculate the marginal p.d.f.s.
</p>

<div class="fragment">
\begin{align*}
  f_X(x)
& = \int_{-\infty}^{\infty} f(x, y) \, dy\\
& = \begin{cases}
\int_c^d \frac{1}{(b-a)(d-c)} \, dy, & a \le x \le b,\\
0, & x < a ~\text{or}~ x >b.
\end{cases}\\
& = \begin{cases}
\frac{1}{b-a}, & a \le x \le b,\\
0, & x < a ~\text{or}~ x >b.
\end{cases}
\end{align*}

</div>


<div id="org80a335f" class="figure">
<p><img src="../img/joint-uniform.svg" alt="joint-uniform.svg" class="fragment middle" width="60%" />
</p>
</div>

</section>
<section>
<p>
Similarly, we have
</p>

<p class="fragment">
\[
f_Y(y) = \begin{cases}
\frac{1}{d- c}, & c \le y \le d,\\
0, & y < c ~\text{or}~ y > d.
\end{cases}
\]
</p>

<p class="fragment">
So,
</p>

<p class="fragment">
\[
f_{X, Y}( x, y ) = f_X(x) f_Y(y),
\]
</p>

<p class="fragment">
and thus \(X\) and \(Y\) are independent.
</p>

</section>
</section>
<section>
<section id="slide-orgfecbb6a">
<h4 id="orgfecbb6a">Example</h4>
<p>
Let \((X, Y) \sim \text{Unif}(A)\), where \(A\) is a triangle with vertices \((0, 0), (0, 1)\) and \((1, 0)\).
</p>

<p class="fragment">
The joint p.d.f. of \((X, Y)\) is:
</p>

<p class="fragment">
\[
f(x, y) = \begin{cases}
\frac{1}{\text{area}(A)} = 2, & (x, y) \in A,\\
0, & \text{otherwise}.
\end{cases}
\]
</p>

<p class="fragment">
Are \(X\) and \(Y\) independent?
</p>

</section>
<section>
<div>
\begin{align*}
  f_X(x)
& = \int_{-\infty}^{\infty} f(x, y) \, dy\\
& = \begin{cases}
\int_0^{1-x} 2 \, dy, & 0 \le x \le 1,\\
0, & x < 0 ~\text{or}~ x > 1.
\end{cases}\\
& = \begin{cases}
2(1 - x), & 0 \le x \le 1,\\
0, & x < 0 ~\text{or}~ x > 1.
\end{cases}
\end{align*}

</div>


<div id="orgfe0413d" class="figure">
<p><img src="../img/joint-uniform-triangle.svg" alt="joint-uniform-triangle.svg" class="fragment middle" width="60%" />
</p>
</div>

</section>
<section>
<p>
Similarly,
</p>

<p class="fragment">
\[
  f_Y(y)
 = \begin{cases}
2(1 - y), & 0 \le y \le 1,\\
0, & y < 0 ~\text{or}~ y > 1.
\end{cases}
\]
</p>


<p class="fragment">
Thus,
</p>

<div class="fragment">
\begin{align*}
 f_X(x) f_Y(y)
& = \begin{cases}
4(1 - x)(1 -y), & (x, y) \in [0, 1]^2,\\
0, & \text{otherwise}.
\end{cases}\\
& \neq \begin{cases}
2, & (x, y) \in A,\\
0, & \text{otherwise}.
\end{cases}
\end{align*}

</div>

<p class="fragment">
Therefore, \(X\) and \(Y\) are not independent.
</p>
</section>
</section>
<section>
<section id="slide-org4c54b47">
<h3 id="org4c54b47">3.6. Conditional Distributions</h3>
<div class="outline-text-3" id="text-org4c54b47">
</div>
</section>
</section>
<section>
<section id="slide-orgdf46273">
<h4 id="orgdf46273">Definition</h4>
<p class="fragment">
Recall
</p>

<p class="fragment">
\[
\mathbb{P}(A | B) = \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)}.
\]
</p>

<p class="fragment">
Let \(X\) and \(Y\) be two discrete random variables, then
</p>
<div class="fragment">
\begin{align*}
  p_{X | Y}(k | l)
& = \mathbb{P}(X = k | Y = l) \\
& = \frac{\mathbb{P}( X = k , Y = l )}{\mathbb{P}(Y = l)}\\
& = \frac{p_{X, Y}(k, l)}{p_Y(l)}.
\end{align*}

</div>
<p class="fragment">
is called the <b>conditional p.m.f.</b> of \(X\) and \(Y\).
</p>

</section>
</section>
<section>
<section id="slide-orgf76435e">
<h4 id="orgf76435e">Example</h4>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">\(0\)</th>
<th scope="col" class="org-left">\(1\)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">\(0\)</td>
<td class="org-left">\(3/10\)</td>
<td class="org-left">\(2/10\)</td>
</tr>

<tr>
<td class="org-left">\(1\)</td>
<td class="org-left">\(1/10\)</td>
<td class="org-left">\(4/10\)</td>
</tr>
</tbody>
</table>

<p class="fragment">
From the table, we have \(X \sim \text{Ber}(1/2)\), and \(Y \sim \text{Ber}(3/5)\).
</p>

<p class="fragment">
What is the conditional p.m.f. of \(X\) given \(Y\)?
</p>

</section>
<section>
<p>
<b>Want</b>:
</p>
<p class="fragment">
\[
p_{X | Y}(k | l) = ? \quad \forall k, l \in \mathbb{R}
\]
</p>

<p class="fragment">
If \(k \notin \{ 0, 1\}\) or \(l \notin \{0, 1\}\),
</p>

<p class="fragment">
\[
p_{X | Y}(k | l) = 0.
\]
</p>

<div class="fragment">
\begin{align*}
  p_{X|Y}(0|0) & = \frac{p_{X|Y}(0, 0)}{p_Y(0)} = \frac{3/10}{2/5} = \frac{3}{4}.\\
  p_{X|Y}(0|1) & = \frac{p_{X|Y}(0, 1)}{p_Y(0)} = \frac{1/5}{3/5} = \frac{1}{3}.\\
\end{align*}

</div>

<p class="fragment">
Similarly,
</p>
<div class="fragment">
\begin{align*}
  p_{X|Y}(1|0) & = \frac{1}{4}.\\
  p_{X|Y}(0|0) & = \frac{2}{3}.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orgc6aa7c4">
<h4 id="orgc6aa7c4">Definition</h4>
<p>
Let \(X\) and \(Y\) be two continuous random variables, then
</p>

<p class="fragment">
\[
f_{X|Y}(x|y) = \frac{f_{X, Y}(x, y)}{f_Y(y)}.
\]
</p>

<p class="fragment">
is called the <b>conditional p.d.f.</b> of \(X\) given \(Y\).
</p>


</section>
</section>
<section>
<section id="slide-orgd98f749">
<h4 id="orgd98f749">Example</h4>
<p>
Recall
\[
f(x, y) = \begin{cases}
\frac{21}{4} x^2 y, & x^2 \le y \le 1,\\
0, & \text{otherwise}.
\end{cases}
\]
</p>

<p>
Also,
\[
f_X(x) = \begin{cases}
\frac{21}{8} x^2 (1 - x^4), & -1 \le x \le 1,\\
0, & \text{otherwise}.
\end{cases}
\]
</p>

<p class="fragment">
Therefore,
</p>

<p class="fragment">
\[
f_{Y|X}(y|x) = \frac{f(x, y)}{f_X(x)} = \begin{cases}
\frac{2y}{1 - x^4}, & x^2 \le y \le 1,\\
0, & \text{otherwise}.
\end{cases}
\]
</p>

</section>
<section>
<p>
In particular,
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}( Y \ge 3/4 | X = 1/2)
& = \int_{3/4}^{\infty} f_{Y | X}(y | 1/2) \, dy\\
& = \int_{3/4}^1 \frac{2y}{1 - (1/2)^4}, \, dy\\
& = \frac{7}{15}.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org18b141e">
<h4 id="org18b141e">Multiplication Rule for Conditional Random Variables</h4>
<p class="fragment">
Recall
</p>
<p class="fragment">
\[
\mathbb{P}(A \cap B) = \mathbb{P}(A | B)  \mathbb{P}(B) = \mathbb{P}(B | A)  \mathbb{P}(A).
\]
</p>

<p class="fragment">
<b>Theorem</b>
</p>
<div class="fragment">
\begin{align*}
  f_{X, Y}(x, y) &= f_{X | Y}(x|y) f_Y(y) = f_{Y|X}(y|x) f_X(x),\\
p_{X, Y}(k, l) &= p_{X | Y}(k | l )p_Y(l) = p_{Y | X}(l|k) p_X(k).
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org4313a81">
<h4 id="org4313a81">Law of Total Probability for Random Variables</h4>
<p class="fragment">
Recall
</p>
<p class="fragment">
\[
\mathbb{P}(A) = \sum_i \mathbb{P}(A | B_i) \mathbb{P}(B_i).
\]
</p>

<p class="fragment">
<b>Theorem</b>
</p>
<div class="fragment">
\begin{align*}
  f_X(x) & = \int_{-\infty}^{\infty} f_{X | Y}(x | y) f_Y(y) \, dy,\\
p_X(k) & = \sum_l p_{X | Y}( k | l  )p_Y(l).
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orgbbfddb0">
<h4 id="orgbbfddb0">Bayes&rsquo; Theorem for Random Variables</h4>
<div class="fragment">
\begin{align*}
  f_{X | Y}(x | y) & = \frac{f_{Y|X}(y|x) f_X(x)}{\int_{-\infty}^{\infty} f_{Y|X}(y|x) f_X(x) \, dx},\\
p_{X|Y}(k | l) & = \frac{p_{Y|X}(l|k) p_X(k)}{\sum_k p_{Y|X}(l | k) p_X(k)}.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org9305e80">
<h4 id="org9305e80">Example 3.6.10</h4>
<p>
Let \(X \sim \text{Unif}([0,1])\). For \(0 < x < 1\), after \(X=x\) has been observed, a point \(Y\) is chosen from a uniform distribution on \([x, 1]\).
</p>

<p class="fragment">
What&rsquo;s the p.d.f. of \(Y\)?
</p>

<p class="fragment">
<b>Have</b>:
</p>
<p class="fragment">
(1)
\[
f_X(x) = \begin{cases}
1, & 0 < x < 1, \\
0, & \text{otherwise}.
\end{cases}
\]
</p>

</section>
<section>
<p>
(2) If \(X = 0.3\), then \(Y \sim \text{Unif}([0.3, 1])\), i.e.,
</p>
<p class="fragment">
\[
f_{Y|X}(y | 0.3) = \begin{cases}
\frac{1}{1 - 0.3}, & 0.3 < y < 1,\\
0, & \text{otherwise}.
\end{cases}
\]
</p>

<p class="fragment">
In general,
</p>
<p class="fragment">
\[
f_{Y|X}(y | x) = \begin{cases}
\frac{1}{1-x}, & x < y < 1,\\
0, & \text{otherwise}.
\end{cases}
\]
</p>

</section>
<section>
<p>
<b>Want</b>: \(f_Y(y) =?\)
</p>

<div class="fragment">
\begin{align*}
  f_Y(y) & = \int_{-\infty}^{\infty} f(x, y) \, dx = \int_{-\infty}^{\infty} f_{Y|X}(y|x) f_X(x) \, dx\\
& = \begin{cases}
\int_0^y \frac{1}{1 - x} \cdot 1 \, dx, & 0 < y < 1,\\
0, & \text{otherwise}
\end{cases}\\
& = \begin{cases}
- \log ( 1- y ), & 0 < y < 1,\\
0, & \text{otherwise}.
\end{cases}
\end{align*}

</div>

<div id="orga4d280e" class="figure">
<p><img src="../img/eg3-6-10.svg" alt="eg3-6-10.svg" class="fragment middle" width="60%" />
</p>
</div>

</section>
<section>
<p>
What about \(f_{X|Y}(x | y) = ?\)
</p>

<div class="fragment">
\begin{align*}
  f_{X|Y}(x | y)
& = \frac{f_{X, Y}(x, y)}{f_Y(y)}\\
& = \begin{cases}
- \frac{1}{(1-x) \log(1 - y)}, & 0 < x < y< 1,\\
0, & \text{otherwise}.
\end{cases}
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orgffa0e73">
<h4 id="orgffa0e73">Independence of Two Random Variables</h4>
<p class="fragment">
Recall: if two events \(A\) and \(B\) are independent,
</p>
<p class="fragment">
\[
\mathbb{P}(A | B) = \mathbb{P}(A).
\]
</p>

<p class="fragment">
<b>Theorem</b>
</p>
<p class="fragment">
Two random variables \(X\) and \(Y\) are independent if and only if
</p>
<div class="fragment">
\begin{align*}
  f_{X|Y}(x |y ) = f_X(x),\\
p_{X|Y}(k | l) = p_X(k).
\end{align*}

</div>
</section>
</section>
<section>
<section id="slide-org24c5765">
<h3 id="org24c5765">3.8. Functions of a Random Variable</h3>
<p>
<b>Question</b>: Given the distribution of a random variable \(X\), what&rsquo;s the distribution of \(Y = h(X)\) for some function \(h\)?
</p>

</section>
</section>
<section>
<section id="slide-org5253250">
<h4 id="org5253250">Discrete Case</h4>
<p class="fragment">
<b>Example</b>
</p>
<p class="fragment">
Let \(X\) be the uniform distribution on integers \(\{1, 2, \dots, 9\}\), i.e.,
</p>
<p class="fragment">
\[
p_X(k) = \mathbb{P}(X = k) = \frac{1}{9}, \quad\text{if}~ k \in \{1, 2, \dots, 9\}.
\]
</p>

<p class="fragment">
Let \(Y = |X - 5|\), what&rsquo;s \(p_Y(l)\)?
</p>

</section>
<section>
<p>
Note that \(\range (Y) = \{0, 1, 2, 3, 4\}\).
</p>
<div class="fragment">
\begin{align*}
  p_Y(0)
& = \mathbb{P}(Y = 0) = \mathbb{P}(|X - 5| = 0)\\
& = \mathbb{P}(X = 5) = p_X(5) = \frac{1}{9}.
\end{align*}

</div>

<div class="fragment">
\begin{align*}
  p_Y(1) & = \mathbb{P}(Y = 1) = \mathbb{P}(|X - 5| = 1)\\
& = \mathbb{P}(X = 4 ~\text{or}~ X = 6)\\
& = p_X(4) + p_X(6) = \frac{2}{9}.
\end{align*}

</div>

<p class="fragment">
Similarly, for \(k = 1, 2, 3, 4\),
</p>

<p class="fragment">
\[
p_Y(k) = \mathbb{P}(| X - 5| = k) = \mathbb{P}(X = 5 + k ~\text{or}~ 5 - k) = \frac{2}{9}
\]
</p>
</section>
<section>
<p>
To sum up,
</p>
<p class="fragment">
\[
p_Y(k) = \begin{cases}
\frac{1}{9}, & k = 0,\\
\frac{2}{9}, & k = 1, 2, 3, 4,\\
0, & \text{otherwise}.
\end{cases}
\]
</p>

</section>
</section>
<section>
<section id="slide-orgddb7849">
<h4 id="orgddb7849">Theorem</h4>
<p class="fragment">
Let \(X\) be a discrete random variable with p.m.f. \(p_X\) and \(Y = h(X)\) for some function \(h\) defined on the set of possible values of \(X\). Then the p.m.f. of \(Y\) is
</p>
<div class="fragment">
\begin{align*}
  p_Y(l)
& = \mathbb{P}(Y = l) = \mathbb{P}(h(X) = l)\\
& = \sum_{k: h(k)=l} p_X(k).
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orgfd52361">
<h4 id="orgfd52361">Continuous Case</h4>
<p class="fragment">
<b>Example</b> (Averaging waiting time)
</p>
<p class="fragment">
Let \(Z\) be the rate at which customers are served in a queue, and suppose \(Z\) is continuous with CDF, say \(F_Z\).
</p>

<p class="fragment">
The average waiting time is \(Y = 1/Z\) (\(h(x) = 1/x\)).
</p>

<p class="fragment">
Find \(F_Y\) (in terms of \(F_Z\)).
</p>

</section>
<section>
<div>
\begin{align*}
  F_Y(y)
& = \mathbb{P}(Y \le y) = \mathbb{P}( 1/Z \le y )\\
& = \mathbb{P}( Z \ge y ) = \mathbb{P}(Z > 1/y)\\
& = 1 - \mathbb{P}(Z \le 1/ y) = 1 - F_Z(1/y).
\end{align*}

</div>

<p class="fragment">
In general, given the p.d.f. of \(f_X\) of \(X\), we can write
</p>
<div class="fragment">
\begin{align*}
F_Y(y) & = \mathbb{P}(Y \le y) = \mathbb{P}(h(X) \le y )\\
& = \int_{h(X) \le y} f_X(x) \, dx.
\end{align*}

</div>

</section>
<section>
<p>
If \(Y = h(X)\) is continuous, then
</p>

<p class="fragment">
\[
\frac{d F_Y(y)}{dy} = f_Y(y) \quad\text{p.d.f. of } Y.
\]
</p>

<p class="fragment">
<b>Question</b>: If \(X\) is continuous, is \(Y = h(X)\) always continuous? If not, counterexample?
</p>


</section>
</section>
<section>
<section id="slide-org9156ba3">
<h4 id="org9156ba3">Example</h4>
<p>
Let \(X \sim \text{Unif}([-1, 1])\), and \(Y = X^2\). Find p.d.f. of \(Y\)?
</p>

<p class="fragment">
Note that \(\range (Y) = [0, 1]\), uncountable.
</p>

<p class="fragment">
First of all, find the CDF of \(Y\).
</p>

<div class="fragment">
\begin{align*}
  F_Y(y) & = \mathbb{P}(Y \le y) = \mathbb{P}(X^2 \le y)\\
& = \begin{cases}
\mathbb{P}(-\sqrt{y} \le X \le \sqrt{y}), & y \ge 0,\\
0, & y < 0.
\end{cases}
\end{align*}

</div>

</section>
<section>
<div>
\begin{align*}
  F_Y(0) & = \mathbb{P}(0 \le X \le 0) = \mathbb{P}(X = 0) = 0,\\
F_Y(1) & = \mathbb{P}(-1 \le X \le 1) = 1.
\end{align*}

</div>

<p class="fragment">
So,
</p>
<p class="fragment">
\[
F_Y(y) = 1, y \ge 1, \quad F_Y(y) = 0, y \le 0.
\]
</p>

</section>
<section>
<p>
If \(0 < y < 1\), then \([-\sqrt{y}, \sqrt{y}] \subseteq [-1, 1]\).
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(-\sqrt{y} \le X \le \sqrt{y} )
& = \int_{-\sqrt{y}}^{\sqrt{y}} f_X(x) \, dx\\
& = \int_{-\sqrt{y}}^{\sqrt{y}} \frac{1}{2} \, dx\\
& = \sqrt{y}.
\end{align*}

</div>
<p class="fragment">
To sum up,
\[
F_Y(y) = \begin{cases}
\sqrt{y}, & 0 < y < 1,\\
1, & y \ge 1,\\
0, & y \le 0.
\end{cases}
\]
</p>

</section>
<section>
<p>
Finally,
</p>
<p class="fragment">
\[
f_Y(y) = F'_Y(y) = \begin{cases}
\frac{1}{2\sqrt{y}}, & 0 < y < 1,\\
0, & \text{otherwise}.
\end{cases}
\]
</p>

</section>
</section>
<section>
<section id="slide-orgb2ba41b">
<h4 id="orgb2ba41b">Linear Transformation</h4>
<p>
\[
h(x) = a x + b, \quad a \neq 0.
\]
</p>

<p class="fragment">
<b>Theorem</b>
</p>
<p class="fragment">
Suppose \(X\) has p.d.f. \(f_X\), and \(Y = a X + b\), then
</p>
<p class="fragment">
\[
f_Y(y) = \frac{1}{|a|} f_X\left(\frac{y - b}{a}\right), \quad a \neq 0.
\]
</p>

<p class="fragment">
Read the proof.
</p>

</section>
</section>
<section>
<section id="slide-org0feb096">
<h4 id="org0feb096">The Probability Integral Transformation</h4>
<p>
<b>Example</b>
Let \(X\) be continuous with p.d.f.
</p>
<p class="fragment">
\[
f_X(x) = \begin{cases}
e^{-x}, & x > 0, \\
0, & x \le 0,
\end{cases}
\]
</p>
<p class="fragment">
and CDF
</p>
<p class="fragment">
\[
F_X(x) = 1 - e^{-x}, \quad x>0.
\]
</p>

<p class="fragment">
Now \(h = F_X\), i.e., \(h(x) = 1 - e^{-x}\).
</p>

<p class="fragment">
Define
</p>
<p class="fragment">
\[
Y = h(X) = F_X(X) = 1 - e^{-X}.
\]
</p>

<p class="fragment">
What&rsquo;s the distribution of \(Y\)?
</p>

</section>
<section>
<div>
\begin{align*}
  F_Y(y) = \mathbb{P}(Y \le y)
& = \mathbb{P}(1 - e^{-X} \le y) = \mathbb{P}(e^{-X} \ge 1 - y)\\
& = \mathbb{P}(-X \ge \log(1 - y)) = \mathbb{P}(X \le -\log(1 - y))\\
& = F_X( -\log(1-y) ) = 1 - e^{-[-\log(1 -y)]} = y.
\end{align*}

</div>
<p class="fragment">
So,
</p>
<p class="fragment">
\[
F_Y(y) = \begin{cases}
y, & 0 < y < 1,\\
1, & y \ge 1,\\
0, & y \le 0,
\end{cases}
\]
</p>

<p class="fragment">
and
</p>
<p class="fragment">
\[
f_Y(y) = \begin{cases}
1, & 0 < y < 1,\\
0, & \text{otherwise}.
\end{cases}
\]
</p>

<p class="fragment">
Therefore, \(Y \sim \text{Unif}([0, 1])\).
</p>
</section>
</section>
<section>
<section id="slide-orgbfb018e">
<h2 id="orgbfb018e">Chapter 4 - Expectation</h2>
<div class="outline-text-2" id="text-orgbfb018e">
</div>
</section>
</section>
<section>
<section id="slide-org2c559a1">
<h3 id="org2c559a1">4.1. The Expectation of a Random Variable</h3>
<p>
Roughly speaking,
\[
\text{Expectation} ~=~ \text{Weighted Average}.
\]
</p>

</section>
</section>
<section>
<section id="slide-org21024a2">
<h4 id="org21024a2">Definition</h4>
<p class="fragment">
(1) If \(X\) is discrete with p.m.f. \(p_X\), then the <b>expectation</b> of \(X\) is
</p>

<p class="fragment">
\[
\mathbb{E}(X) = \sum_{k \in \range (X)} k p_X(k).
\]
</p>

<p class="fragment">
(2) If \(X\) is continuous with p.d.f. \(f_X\), then the <b>expectation</b> of \(X\) is
</p>

<p class="fragment">
\[
\mathbb{E}(X) = \int_{-\infty}^{\infty} x f_X(x) \, dx.
\]
</p>

<div class="fragment">
\begin{align*}
  \text{Expectation}
& =~ \text{mean} ~=~ \text{first moment}\\
& =~ \text{average value}\\
& =~ \text{expected value}
\end{align*}

</div>
</section>
</section>
<section>
<section id="slide-orgbe29334">
<h4 id="orgbe29334">Example</h4>
<p>
\(X \sim \text{Ber}(p)\), i.e.,
</p>
<p class="fragment">
\[
\mathbb{P}(X = 1) = p, \quad \mathbb{P}(X = 0) = 1 - p.
\]
</p>

<p class="fragment">
Then
</p>
<p class="fragment">
\[
\mathbb{E}(X = 1 \cdot \mathbb{P}(X = 1) + 0 \cdot \mathbb{P}(X = 0) = p.
\]
</p>

</section>
</section>
<section>
<section id="slide-org2c68c73">
<h4 id="org2c68c73">Example</h4>
<p>
Suppose you got:
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">HW</td>
<td class="org-left">\(9/10\)</td>
</tr>

<tr>
<td class="org-left">M1</td>
<td class="org-left">\(45/50\)</td>
</tr>

<tr>
<td class="org-left">M2</td>
<td class="org-left">\(40/50\)</td>
</tr>

<tr>
<td class="org-left">Final</td>
<td class="org-left">\(83/100\)</td>
</tr>
</tbody>
</table>

<p class="fragment">
According to our syllabus, what&rsquo;s your weighted average of your final grade?
</p>

<p class="fragment">
\[
90 \cdot 0.1 + 90 \cdot 0.25 + 83 \cdot 0.25 + 83 \cdot 0.4 = 85.45.
\]
</p>

</section>
</section>
<section>
<section id="slide-orgb580792">
<h4 id="orgb580792">Example</h4>
<p>
\(X \sim \text{Bin}(n, p)\), Find \(\mathbb{E}(X)\).
</p>

<p class="fragment">
If \(n=1\), \(X \sim \text{Bin}(1, p) = \text{Ber}(p)\), so
</p>

<p class="fragment">
\[
\mathbb{E}(X) = p.
\]
</p>

<p class="fragment">
Recall that \(X\) is the number of &ldquo;successes&rdquo;, so
</p>
<p class="fragment">
\[
\mathbb{E}(X) = \text{Expected number of successes} = np.
\]
</p>

</section>
</section>
<section>
<section id="slide-org791ace8">
<h4 id="org791ace8">Proof</h4>
<p class="fragment">
Note that \(\range (X) = \{0, 1, 2, \dots, n\}\). By definition,
</p>

<div class="fragment">
\begin{align*}
  \mathbb{E}(X)
& = \sum_{k=0}^n k \mathbb{P}(X = k) = \sum_{k=0}^n k \binom{n}{k} p^k  (1 - p)^{n-k}\\
& = \sum_{k=1}^n k \binom{n}{k} p^k  (1 - p)^{n-k}\\
& = \sum_{k=1}^n k \frac{n!}{k!(n-k)!} p^k  (1 - p)^{n-k}\\
& = \sum_{k=1}^n k \frac{n!}{(k-1)!(n-k)!} p^k  (1 - p)^{n-k}\\
& = n p \sum_{k=1}^n k \frac{(n - 1)!}{(k-1)!(n-k)!} p^k  (1 - p)^{n-k}\\
\end{align*}

</div>

</section>
<section>
<div>
\begin{align*}
\sum_{k=1}^n k \frac{(n - 1)!}{(k-1)!(n-k)!} p^k  (1 - p)^{n-k}
& = \sum_{k=1}^n k \binom{n-1}{k-1} p^k  (1 - p)^{n-k}\\
& =  \sum_{j=0}^{n-1} \binom{n-1}{j} p^j ( 1 - p)^{n-j-1}\\
& = \sum_{j=0}^m  \binom{m}{j} p^j (1-p)^{m-j}\\
\end{align*}

</div>

<div class="fragment">
\begin{align*}
  \sum_{j=0}^m  \binom{m}{j} p^j (1-p)^{m-j}
& = ( p + (1-p))^m\\
& = 1^m = 1.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orgad25173">
<h4 id="orgad25173">Example</h4>
<p>
\(X \sim \text{Unif}([a, b])\), i.e.,
\[
f_X(x) = \begin{cases}
\frac{1}{b-a}, & a \le x \le b,\\
0, & \text{otherwise}.
\end{cases}
\]
</p>

<p class="fragment">
Find \(\mathbb{E}(X)\).
</p>

<div class="fragment">
\begin{align*}
  \mathbb{E}(X)
& = \int_{-\infty}^{\infty} x f_X(x) \, dx = \int_a^b x \cdot \frac{1}{b-a}\, dx\\
& = \frac{b+a}{2}.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org463afd3">
<h4 id="org463afd3">Expectation of a Function of Random Variables</h4>
<p class="fragment">
Given a random variable \(X\) and a function \(g: \mathbb{R} \mapsto \mathbb{R}\), by definition directly,
</p>
<p class="fragment">
\[
\mathbb{E}(g(X)) = \begin{cases}
\sum_{k \in \range (Y)} k p_Y(k), & \text{discrete case}\\
\int_{-\infty}^{\infty} y f_Y(y)\, dy, & \text{continuous case}.
\end{cases}
\]
</p>

<p class="fragment">
Most of the time, we don&rsquo;t know the p.m.f. or p.d.f. of \(Y\), what can we do?
</p>

</section>
</section>
<section>
<section id="slide-org8d26c92">
<h4 id="org8d26c92">Law of the Unconscious Statistician (LOTUS)</h4>
<p class="fragment">
Discrete:
</p>
<p class="fragment">
\[
\mathbb{E}(g(X)) = \sum_{k \in \range (X)} g(k) p_X(k).
\]
</p>

<p class="fragment">
Continuous:
</p>
<p class="fragment">
\[
\mathbb{E}(g(X)) = \int_{-\infty}^{\infty}  g(x) f_X(x) \, dx.
\]
</p>


<p class="fragment">
In particular, if \(g(x)=x\), LOTUS is just the usual definition of the expectation.
</p>

</section>
</section>
<section>
<section id="slide-orgbd95e6b">
<h4 id="orgbd95e6b">Example</h4>
<p>
Roll a fair six sided die.
</p>

<p class="fragment">
Let \(X\) be the outcome, i.e.,
</p>
<p class="fragment">
\[
p_X(k) = \frac{1}{6}, \quad \text{if}~k \in \{1, 2, 3, 4, 5, 6\}.
\]
</p>

<p class="fragment">
Then
</p>
<div class="fragment">
\begin{align*}
\mathbb{E}(X^2 )
& = \sum_{k \in \range (X)} k^2 p_X(k)\\
& = 1^2 \cdot \frac{1}{6} + 2^2 \cdot \frac{1}{6} + \cdots + 6^2 \cdot \frac{1}{6}\\
& = \frac{91}{6}.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org3b35726">
<h4 id="org3b35726">Example 4.1.6</h4>
<p class="fragment">
Let \(X\) be a continuous random variable with p.d.f.
</p>
<p class="fragment">
\[
f_X(x) = \begin{cases}
2x, & 0 < x < 1, \\
0, & \text{otherwise}.
\end{cases}
\]
</p>

<p class="fragment">
Define
</p>
<p class="fragment">
\[
Y = g(X) = X^{1/2} = \sqrt{X}.
\]
</p>

<p class="fragment">
Find \(\mathbb{E}(X)\).
</p>

</section>
</section>
<section>
<section id="slide-org221436d">
<h4 id="org221436d">Solution 1</h4>
<p>
Find p.d.f. of \(Y\).
</p>

<p class="fragment">
To this end, we need to find the CDF first.
</p>

<div class="fragment">
\begin{align*}
  F_Y(y)
& = \mathbb{P}(Y \le y) = \mathbb{P}(\sqrt{X} \le y) = 0 \quad \text{if}~ y<0\\
& = \mathbb{P}(X \le y^2) \quad \text{if}~ y \ge 0\\
& = \int_{-\infty}^{y^2}  f_X(x) \, dx\\
& = \int_0^{y^2} 2x \, dx\quad (\text{for what $y$?})\\
& = \left. x^2 \right|_0^{y^2} = y^4.
\end{align*}

</div>

</section>
<section>
<p>
To sum up,
</p>
<p class="fragment">
\[
F_Y(y) = \begin{cases}
0, & y < 0,\\
y^4, & 0 \le y \le 1,\\
1, & y \ge 1.
\end{cases}
\]
</p>

<p class="fragment">
Thus,
</p>
<p class="fragment">
\[
f_Y(y) = F'_Y(y) = \begin{cases}
4y^3, & 0 \le y \le 1,\\
0, & \text{otherwise}.
\end{cases}
\]
</p>

<p class="fragment">
Finally,
</p>
<div class="fragment">
\begin{align*}
  \mathbb{E}(Y)
& = \int_{-\infty}^{\infty} y f_Y(y) \, dy = \int_{0}^1 y \cdot 4 y^3 \, dy\\
& = \frac{4}{5}.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org62768fa">
<h4 id="org62768fa">Solution 2 (LOTUS)</h4>
<div class="fragment">
\begin{align*}
  \mathbb{E}(Y)
& = \mathbb{E}(\sqrt{X}) = \int_{-\infty}^{\infty} \sqrt{x} f_X(x) \, dx\\
& = \int_0^1 \sqrt{x} \cdot 2 x \, dx = \frac{4}{5}.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org40fe88b">
<h3 id="org40fe88b">4.2. Properties of Expectations</h3>
<div class="outline-text-3" id="text-org40fe88b">
</div>
</section>
</section>
<section>
<section id="slide-org4cabcd2">
<h4 id="org4cabcd2">Theorem (Linearity)</h4>
<p class="fragment">
If \(Y = aX + b\), where \(a, b \in \mathbb{R}\), then
</p>
<p class="fragment">
\[
\mathbb{E}(Y ) = a \mathbb{E}(X) + b.
\]
</p>

<p class="fragment">
In particular, if \(a = 0\), \(Y = a X + b = b\), then
</p>
<p class="fragment">
\[
\mathbb{E}(Y) = \mathbb{E}(b) = b.
\]
</p>


</section>
</section>
<section>
<section id="slide-org5967a2b">
<h4 id="org5967a2b">Proof (Continuous case)</h4>
<div class="fragment">
\begin{align*}
  \mathbb{E}(Y)
& = \mathbb{E}(a X + b) = \int_{-\infty}^{\infty} (a x + b) f_X(x) \, dx\\
& = \int_{-\infty}^{\infty}  a x f_X(x) \, dx + \int_{-\infty}^{\infty} b f_X(x) \, dx\\
& = a \int_{-\infty}^{\infty} x f_X(x)\, dx + b \int_{-\infty}^{\infty} f_X(x) \, dx\\
& = a \mathbb{E}(X) + b.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org822df2b">
<h4 id="org822df2b">Theorem</h4>
<p class="fragment">
Assume \(\mathbb{E}(X_i)\) is finite for \(i = 1, 2, \dots, n\). Then
</p>
<p class="fragment">
\[
\mathbb{E}(a_1 X_1 + a_2 X_2 + \cdots + a_n X_n) = a_1 \mathbb{E}(X_1) + a_2 \mathbb{E}(X_2) + \cdots + a_n \mathbb{E}(X_n).
\]
</p>

<p class="fragment">
In particular,
</p>
<p class="fragment">
\[
\mathbb{E}(X + Y) = \mathbb{E}(X) + \mathbb{E}(Y).
\]
</p>

</section>
</section>
<section>
<section id="slide-org0ed77c8">
<h4 id="org0ed77c8">Example</h4>
<p>
Recall that if \(X \sim \text{Bin}(n, p)\), we computed
</p>
<p class="fragment">
\[
\mathbb{E}(X) = np,
\]
</p>
<p class="fragment">
where
</p>
<p class="fragment">
\[
X = \sum_{i=0}^n X_i, \quad X_i \sim \text{Ber}(p), \, \mathbb{E}(X_i) = p.
\]
</p>
<p class="fragment">
Thus,
</p>
<div class="fragment">
\begin{align*}
  \mathbb{E}(X)
& = \mathbb{E}(X_1) + \cdots + \mathbb{E}(X_n)\\
& = p + \cdots + p = np.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org47be7a2">
<h4 id="org47be7a2">Example (Match Problem Revisited)</h4>
<p>
Suppose \(n\) men throw their hats into the center of a room. Then hats are mixed up, and each man randomly selects a hat.
</p>

<p>
Let \(X\) be the number of men who gets his own hat.
</p>

<p class="fragment">
Find \(\mathbb{E}(X)\).
</p>

</section>
<section>
<p>
Define
</p>
<p class="fragment">
\[
X_i = \begin{cases}
1, & i^{\text{th}}~ \text{man gets his own hat},\\
0, & \text{otherwise}.
\end{cases}
\]
</p>

<p class="fragment">
Then
</p>
<p class="fragment">
\[
X = X_1 + X_2 + \cdots + X_n.
\]
</p>

<p class="fragment">
Note that \(X_i \sim \text{Ber}(p_i)\), where
</p>
<p class="fragment">
\[
p_i = \mathbb{P}(X_i = 1) = \frac{1}{n}.
\]
</p>

<p class="fragment">
So
</p>
<p class="fragment">
\[
\mathbb{E}(X) = \sum_{i=1}^n \mathbb{E}(X_i) = \sum_{i=1}^n \frac{1}{n} = 1.
\]
</p>

</section>
</section>
<section>
<section id="slide-org6838ccf">
<h4 id="org6838ccf">Independence and Expectation</h4>
<p>
<b>Theorem</b>
</p>
<p class="fragment">
If two random variables \(X\) and \(Y\) are independent, and \(\mathbb{E}(X), \mathbb{E}(Y)\) are finite. Then
</p>
<p class="fragment">
\[
\mathbb{E}(XY) = \mathbb{E}(X) \mathbb{E}(Y).
\]
</p>

<p class="fragment">
In general, if \(X_1, \dots, X_n\) are independent, then
</p>
<p class="fragment">
\[
\mathbb{E}\left(\prod_{i=1}^n X_i\right) = \prod_{i=1}^n \mathbb{E}(X_i).
\]
</p>

</section>
</section>
<section>
<section id="slide-org080209a">
<h4 id="org080209a">Example</h4>
<p>
Suppose \(X_1, X_2, X_3\) form a random sample, i.e., independent and identically distributed, such that
\(\mathbb{E}(X_1) = 0, \mathbb{E}(X_1^2) = 1\).
</p>

<p class="fragment">
Compute
</p>
<p class="fragment">
\[
\mathbb{E}(X_1^2 ( X_2 - 4X_3)^2).
\]
</p>

<div class="fragment">
\begin{align*}
\mathbb{E}(X_1^2 ( X_2 - 4X_3)^2)
& = \mathbb{E}(X_1^2) \mathbb{E}(X_2 - 4X_3)^2\\
& = \mathbb{E}(X_2^2 - 8 X_2 X_3 + 16 X_3^2)\\
& = \mathbb{E}(X_2^2) - 8 \mathbb{E}(X_2 X_3) + 16 \mathbb{E}(X_3^2)\\
& = 1 - 8 \mathbb{E}(X_2) \mathbb{E}(X_3) + 16\\
& = 1 - 0 + 16 = 17.
\end{align*}

</div>
</section>
</section>
<section>
<section id="slide-org83e4a3f">
<h3 id="org83e4a3f">4.4. Moments</h3>
</section>
</section>
<section>
<section id="slide-orge9c1a4c">
<h3 id="orge9c1a4c">4.5. The Mean and Median</h3>
</section>
</section>
<section>
<section id="slide-orgf422dce">
<h3 id="orgf422dce">4.7. Conditional Expectation</h3>
</section>
</section>
</div>
</div>
<script src="../dist/reveal.js"></script>
<script src="../plugin/markdown/markdown.js"></script>
<script src="../plugin/notes/notes.js"></script>
<script src="../plugin/search/search.js"></script>
<script src="../plugin/zoom/zoom.js"></script>
<script src="../plugin/reveal.js-menu/menu.js"></script>
<script src="../reveal.js-plugins/chalkboard/plugin.js"></script>
<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

controls: true,
progress: true,
history: false,
center: true,
slideNumber: false,
rollingLinks: false,
keyboard: true,
mouseWheel: false,
fragmentInURL: false,
hashOneBasedIndex: false,
pdfSeparateFragments: true,
overview: true,

transition: 'none',
transitionSpeed: 'default',

// Plugins with reveal.js 4.x
plugins: [ RevealMarkdown, RevealNotes, RevealSearch, RevealZoom, RevealMenu, RevealChalkboard ],

// Optional libraries used to extend reveal.js
dependencies: [
]

,chalkboard: {src: "chalkboard/chalkboard.json", storage: "chalkboard-demo", toggleChalkboardButton: { left: "80px" },	toggleNotesButton: { left: "130px" },	colorButtons: 5}});
</script>
</body>
</html>

<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>MATH 4750 - Introduction to Mathematical Statistics</title>
<meta name="author" content="\\
Jie Zhong \\
Department of Mathematics \\
California State University, Los Angeles"/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="../dist/reveal.css"/>

<link rel="stylesheet" href="../dist/theme/serif.css" id="theme"/>

<link rel="stylesheet" href="../reveal.js-plugins/chalkboard/style.css"/>

<link rel="stylesheet" href="../reveal.js-plugins/menu/font-awesome/css/fontawesome.css"/>

<link rel="stylesheet" href="../gnohz.css"/>
<script>window.MathJax = { TeX: {Macros: {range: "\\text{Range}", ow: "\\text{otherwise}"}} }</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide">
<h1>MATH 4750 - Introduction to Mathematical Statistics</h1><h2></h2><h6> <br />
Jie Zhong <br />
Department of Mathematics <br />
California State University, Los Angeles</h6>
</section>


<section>
<section id="slide-org5c05363">
<h2 id="org5c05363">Chapter 9 Testing Hypotheses</h2>
<div class="outline-text-2" id="text-org5c05363">
</div>
</section>
</section>
<section>
<section id="slide-org31f8b86">
<h3 id="org31f8b86">9.1 Problems of Testing Hypotheses</h3>
<p>
In general, hypothesis testing concerns trying to decide whether a parameter \(\theta\) lies in one subset of the parameter space or in its complement. When \(\theta\) is one-dimensional, at least one of the two subsets will typically be an interval, possibly degenerate. In this section, we introduce the notation and some common methodology associated with hypothesis testing.
</p>

<p>
We recommend to read the part of an equivalence between hypothesis tests and confidence intervals.
</p>

</section>
</section>
<section>
<section id="slide-org8b2ede4">
<h4 id="org8b2ede4">The Null and Alternative Hypotheses</h4>
<p class="fragment">
Consider a statistical problem involving a parameter \(\theta \in \Omega\), where \(\Omega\) is a certain parameter space.
</p>
<p class="fragment">
Suppose that
</p>
<div class="fragment">
\begin{align*}
  \Omega = \Omega_0 \cup \Omega_1, \quad \Omega_0 \cap \Omega_1 = \varnothing.
\end{align*}

</div>
<p class="fragment">
Let
</p>
<div class="fragment">
\begin{align*}
  H_0: \theta \in \Omega_0, \quad H_1: \theta \in \Omega_1.
\end{align*}

</div>

<p class="fragment">
<span style="color: rgb(24,116,205)">Goal</span>: To decide which of hypothesis \(H_0\) or \(H_1\) appears to be true.
</p>

</section>
</section>
<section>
<section id="slide-org324eb74">
<h4 id="org324eb74">The Null and Alternative Hypotheses - Continued</h4>
<p>
<span style="color: rgb(24,116,205)">Goal</span>: To decide which of hypothesis \(H_0\) or \(H_1\) appears to be true.
</p>

<p class="fragment">
A problem of this type, in which there are only two possible decisions, is called a problem of <i>testing hypotheses</i>.
</p>

<p class="fragment">
A procedure for deciding which hypothesis to choose is called a <i>test procedure</i> or simply a <i>test</i>.
</p>

</section>
</section>
<section>
<section id="slide-org547dea4">
<h4 id="org547dea4">Definition</h4>
<p class="fragment">
The hypothesis \(H_0\) is called the <i>null hypothesis</i> and the hypothesis \(H_1\) is called the <i>alternative hypothesis</i>.
</p>

<p class="fragment">
When performing a test, if we decide that \(\theta\) lies in \(\Omega_1\), we are said to <i>reject</i> \(H_0\). If we decide that \(\theta\) lies in \(\Omega_0\), we are said <i>not to reject</i> \(H_0\).
</p>

</section>
</section>
<section>
<section id="slide-orgcc247b4">
<h4 id="orgcc247b4">Example 9.1.2</h4>
<p>
<span style="color: rgb(24,116,205)">Egyptian Skulls</span>
</p>

<p class="fragment">
Observations: breadth measurements (in mm) of the skulls found in Egypt from various time periods
</p>
<p class="fragment">
Model: \(\mathcal{N}(\mu, \sigma^2)\).
</p>
<p class="fragment">
Goal: Interest might lie in how \(\mu\) compares to the breadth of a modern-day skull, about 140mm.
</p>
<p class="fragment">
Hypotheses setup:
</p>
<div class="fragment">
\begin{align*}
  & H_0: \mu \ge 140,\\
  & H_1: \mu < 140.
\end{align*}

</div>

</section>
<section>
<p>
<span style="color: rgb(24,116,205)">Question</span>: How did we decide that the null hypothesis should be \(H_0: \mu \ge 140\) rather than \(\mu < 140\)? Would we be led to the same conclusion either way?
</p>
<p class="fragment">
We can address these issues after we introduce the possible errors that can arise in hypothesis testing.
</p>

</section>
</section>
<section>
<section id="slide-orgcf2b9a8">
<h4 id="orgcf2b9a8">Simple and Composite Hypotheses</h4>
<p class="fragment">
For \(i = 0\) or \(i=1\), if \(\Omega_i\) contains just a single value of \(\theta\), then \(H_i\) is a <i>single hypothesis</i>.
</p>

<p class="fragment">
If the set \(\Omega_i\) contains more than one value of \(\theta\), then \(H_i\) is a <i>composite hypothesis</i>.
</p>
<p class="fragment">
For example, a simple null hypothesis \(H_0\) must have the form
</p>
<div class="fragment">
\begin{align*}
  H_0: \theta = \theta_0.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orgfecd0f1">
<h4 id="orgfecd0f1">Definition</h4>
<p>
Let \(\theta\) be a one-dimensional parameter. <i>One-sided</i> null hypotheses are of the form \(H_0 : \theta \le \theta_0\) or \(H_0 : \theta \ge \theta_0\), with the corresponding one-sided alternative hypotheses being \(H_1 : \theta>\theta_0\) or \(H_1: \theta < \theta_0\).
</p>

<p class="fragment">
When the null hypothesis is simple, the alternative hypothesis is usually two-sided, \(H_1: \theta \neq \theta_0\).
</p>

</section>
</section>
<section>
<section id="slide-org6676672">
<h4 id="org6676672">The Critical Region and Test Statistic</h4>
<p>
<span style="color: rgb(24,116,205)">Example 9.1.3</span>
Suppose that \(\vec{X} = (X_1, \dots, X_n)\) is random sample from \(\mathcal{N}(\mu, \sigma^2)\).
</p>
<p class="fragment">
We wish to test the hypotheses:
</p>
<div class="fragment">
\begin{align*}
  & H_0: \mu = \mu_0,\\
  & H_1: \mu \neq \mu_0.
\end{align*}

</div>

<p class="fragment">
<span style="color: rgb(24,116,205)">Question</span>:
What is a reasonable criterion to reject \(H_0\)?
</p>
<p class="fragment">
Reject \(H_0\) if \(\overline{X}_n\) is far from \(\mu_0\).
</p>

</section>
<section>
<p>
For example, we could choose a number \(c\) and reject \(H_0\) if
</p>
<div>
\begin{align*}
  |\overline{X}_n - \mu_0| \ge c.
\end{align*}

</div>

<p class="fragment">
Alternatively, we can also based on theoretical considerations, choose a number \(c\) and reject \(H_0\) if \(|U| \ge c\), where
</p>
<div class="fragment">
\begin{align*}
  U = \frac{n^{1/2}(\overline{X}_n - \mu_0)}{\sigma'}.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org5081a10">
<h4 id="org5081a10">The Critical Region and Test Statistic - Continued</h4>
<p>
In such a way, we actually divide the sample space \(S\) into two sets
</p>
<div class="fragment">
\begin{align*}
  S_0 = \{\vec{x}: - c < \overline{X}_n -\mu_0< c\}, \quad \text{and}\quad S_1 = S^C_0.
\end{align*}

</div>
<p class="fragment">
We then reject \(H_0\) if \(\vec{X}\in S_1\), and we don&rsquo;t reject \(H_0\) if \(\vec{X}\in S_0\).
</p>

<p class="fragment">
A simpler way to express the procedure is to define the statistic \(T = |\overline{X}_n - \mu_0|\), and reject \(H_0\) if \(T\ge c\).
</p>

</section>
</section>
<section>
<section id="slide-org9c7846f">
<h4 id="org9c7846f">The Critical Region and Test Statistic - Continued</h4>
<p>
In general, we can specify a test procedure by partitioning \(S\) into two subsets:
</p>
<div class="fragment">
\begin{align*}
  S_1 = \{\vec{x}: ~\text{reject } H_0\},\quad \text{and}\quad S_1 = S^C_0.
\end{align*}

</div>
<p class="fragment">
The set defined above is called the <i>critical region</i> of the test.
</p>

<p class="fragment">
In summary, a test procedure is determined by specifying the critical region of the test. In most hypothesis-testing problems, the critical region is defined in terms of a statistic, \(T = r(\vec{X})\).
</p>

</section>
</section>
<section>
<section id="slide-orgdc61d13">
<h4 id="orgdc61d13">Definition</h4>
<p>
Let \(\vec{X}\) be a random sample from a distribution that depends on a parameter \(\theta\).
</p>

<p class="fragment">
Let \(T = r(\vec{X})\) be a statistic, and let \(R\) be a subset of the real line. Suppose that a test procedure for the hypotheses is of the form &ldquo;reject \(H_0\) if \(T \in R\).&rdquo;
</p>

<p class="fragment">
Then we call \(T\) a <i>test statistic</i>, and we call \(R\) the <i>rejection region</i> of the test.
</p>

<p class="fragment">
When a test is defined in terms of a test statistic \(T\) and rejection region \(R\), the set \(S_1 = \{\vec{x}: r(\vec{x}) \in R\}\) is the critical region.
</p>

<p class="fragment">
In Example 9.1.3, we reject \(H_0\) if \(T = |\overline{X}_n - \mu_0| \ge c\), and the rejection region \(R = [c, \infty]\).
</p>

</section>
</section>
<section>
<section id="slide-orgd6aa334">
<h4 id="orgd6aa334">Definition</h4>
<p>
Let \(\delta\) be a test procedure, and \(S_1\) be the critical region of \(\delta\), we call the probability given a \(\theta\in \Omega\) that the test \(\delta\) will reject \(H_0\), i.e.,
</p>
<div class="fragment">
\begin{align*}
  \pi(\theta|\delta) = \mathbb{P}(\vec{X} \in S_1 |\theta)
\end{align*}

</div>
<p class="fragment">
the <i>power function</i> of the test \(\delta\).
</p>
<p class="fragment">
If \(\delta\) is described in terms of a test statistic \(T\) and rejection region \(R\), the power function is
</p>
<div class="fragment">
\begin{align*}
  \pi(\theta|\delta) = \mathbb{P}(T\in R|\theta).
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org763f920">
<h4 id="org763f920">Example 9.1.5</h4>
<p>
<span style="color: rgb(24,116,205)">Testing Hypotheses about the Mean of a Normal Distribution with Known Variance</span>
</p>
<p class="fragment">
In Example 9.1.3, the test \(\delta\) is based on the test statistic \(T = |\overline{X}_n - \mu_0|\) with rejection region \(R = [c, \infty)\).
</p>
</section>
</section>
<section>
<section id="slide-orgd153179">
<h4 id="orgd153179">Example 9.1.5 - Continued</h4>
<p>
Note that \(\overline{X}_n \sim \mathcal{N}(\mu, \sigma^2/n)\), then the power function
</p>
<div class="fragment">
\begin{align*}
  \pi(\mu|\delta) & = \mathbb{P}(T\in R|\mu)\\
& = \mathbb{P}(|\overline{X}_n-\mu_0| \ge c|\mu)\\
& = \mathbb{P}(\overline{X}_n \ge \mu_0 + c |\mu) + \mathbb{P}(\overline{X}_n \le \mu_0 - c |\mu)\\
& = 1 - \Phi \left( \frac{\mu_0 + c - \mu}{\sigma/\sqrt{n}} \right) + \Phi \left( \frac{\mu_0 - c - \mu}{\sigma/\sqrt{n}} \right).
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org46bd560">
<h4 id="org46bd560">Example 9.1.5 - Continued</h4>
<p>
The following figure plots the power functions of three different tests with \(c = 1, 2, 3\) in the specific example in which \(\mu_0 =4, n=15\), and \(\sigma^2 =9\).
</p>

<div id="orgf1f7880" class="figure">
<p><img src="../img/math4750/fig9-1.png" alt="fig9-1.png" class="fragment middle" width="65%" />
</p>
</div>

</section>
</section>
<section>
<section id="slide-org9ae14ef">
<h4 id="org9ae14ef">Ideal Power Function?</h4>
<p>
Recall that the power function \(\pi(\theta|\delta)\) specifies, for each possible value of the parameter \(\theta\), the probability that \(\delta\) will reject \(H_0\), it follows that the ideal power function would be one for which
</p>
<div class="fragment">
\begin{align*}
  \pi(\theta|\delta) = \begin{cases}
0, & \text{for each } \theta \in \Omega_0,\\
1, & \text{for each } \theta \in \Omega_1.
\end{cases}
\end{align*}

</div>

<p class="fragment">
&ldquo;Ideal&rdquo; here means that test \(\delta\) would lead to the correct decision with probability \(1\).
</p>

<p class="fragment">
In a practical problem, however, there would seldom exist any test procedure having such an ideal power function.
</p>

</section>
</section>
<section>
<section id="slide-org736ace2">
<h4 id="org736ace2">Definition</h4>
<p>
An erroneous decision to reject a true null hypothesis is a <i>type I error</i>, and an erroneous decision not to reject a false null hypothesis is called a <i>type II error</i>.
</p>

<p class="fragment">
In terms of the power function,
</p>
<div class="fragment">
\begin{align*}
  \pi(\theta|\delta) & = \mathbb{P}(\text{type I error}), & \theta \in \Omega_0\\
  1 - \pi(\theta|\delta) & = \mathbb{P}(\text{type II error}), & \theta \in \Omega_1\\
\end{align*}

</div>

<p class="fragment">
Now our goal is to choose a test \(\delta\) so that the power function \(\pi(\theta|\delta)\) is low for \(\theta\in \Omega_0\), and high for \(\theta\in \Omega_1\).
</p>

</section>
</section>
<section>
<section id="slide-org2342a77">
<h4 id="org2342a77">Example</h4>
<p>
Consider the test \(\delta_0\) that <b>never rejects</b> \(H_0\), then we have
</p>
<div class="fragment">
\begin{align*}
  \pi(\theta|\delta_0) = 0, \quad \text{for all }  \theta \in \Omega.
\end{align*}

</div>

<p class="fragment">
<span style="color: rgb(24,116,205)">Question</span>: What are the probabilities of making type I and type II errors, respectively?
</p>


<p class="fragment">
Consider the test \(\delta_1\) that <b>always rejects</b> \(H_0\), then we have
</p>
<div class="fragment">
\begin{align*}
  \pi(\theta|\delta_0) = 1, \quad \text{for all }  \theta \in \Omega.
\end{align*}

</div>

<p class="fragment">
<span style="color: rgb(24,116,205)">Question</span>: What are the probabilities of making type I and type II errors, respectively?
</p>


</section>
</section>
<section>
<section id="slide-org0527bc0">
<h4 id="org0527bc0">Definition</h4>
<p>
Given a number \(\alpha_0\in (0, 1)\), the test \(\delta\) such that
</p>
<div class="fragment">
\begin{align*}
  \pi(\theta|\delta) \le \alpha_0, \quad \text{for all }  \theta\in \Omega_0
\end{align*}

</div>
<p class="fragment">
is called a <i>level \(\alpha_0\) test</i>,  and we say that the test has <i>level of significance \(\alpha_0\)</i>.
</p>
<p class="fragment">
In addition, the <i>size \(\alpha(\delta)\) of a test \(\delta\)</i> is defined as follows:
</p>
<div class="fragment">
\begin{align*}
  \alpha(\delta) = \sup_{\theta\in \Omega_0}\pi(\theta|\delta).
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org3d13ebd">
<h4 id="org3d13ebd">Corollary</h4>
<p>
A test \(\delta\) is a level \(\alpha_0\) test if and only if its size is at most \(\alpha_0\) (i.e. \(\alpha(\delta)\le \alpha_0\)). If the null hypothesis is simple, that is, \(H_0: \theta = \theta_0\), then the size of \(\delta\) will be \(\alpha(\delta) = \pi(\theta_0|\delta)\).
</p>

</section>
</section>
<section>
<section id="slide-org61b9171">
<h4 id="org61b9171">Example 9.1.7</h4>
<p>
Observations: \(X_1, \dots, X_n \sim \text{Unif}([0, \theta])\), with \(\theta\) unknown.
</p>
<p class="fragment">
Hypotheses:
</p>
<div class="fragment">
\begin{align*}
  H_0: & 3 \le \theta \le 4,\\
  H_1: & \theta < 3 ~\text{or}~ \theta>4.
\end{align*}

</div>

<p class="fragment">
We know (from Example 7.5.7) that the M.L.E. of \(\theta\) is
</p>
<div class="fragment">
\begin{align*}
  Y_n = \max\{X_1, \dots, X_n\}.
\end{align*}

</div>
<p class="fragment">
Since \(Y_n \to \theta\) as \(n\to \infty\) in probability, we can define a test \(\delta\) such that it does not reject \(H_0\) if \(2.9< Y_n < 4\) and rejects \(H_0\) if \(Y_n\) does not lie in this interval.
</p>
</section>
</section>
<section>
<section id="slide-org981c90b">
<h4 id="org981c90b">Example 9.1.7 - Continued</h4>
<p>
<span style="color: rgb(24,116,205)">Question</span>:
</p>
<p class="fragment">
What is the critical region, rejection region, power function, size of the test, level of significance?
</p>


<p class="fragment">
Critical region:
</p>
<div class="fragment">
\begin{align*}
  S_1 = \{\vec{x}: Y_n \le 2.9, ~ \text{or}~ Y_n \ge 4\}.
\end{align*}

</div>

<p class="fragment">
Rejection region:
</p>
<div class="fragment">
\begin{align*}
  R = (-\infty, 2.9]\cup [4, \infty).
\end{align*}

</div>

<p class="fragment">
The power function:
</p>
<div class="fragment">
\begin{align*}
  \pi(\theta|\delta) = \mathbb{P}(Y_n \le 2.9|\theta) + \mathbb{P}(Y_n\ge 4|\theta).
\end{align*}

</div>

</section>
<section>
<p>
If \(\theta \le 2.9\),
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(Y_n \le 2.9|\theta) = 1, \quad \mathbb{P}(Y_n\ge 4|\theta) = 0.
\end{align*}

</div>
<p class="fragment">
So in this case,
</p>
<div class="fragment">
\begin{align*}
  \pi(\theta|\delta) = 1.
\end{align*}

</div>

<p class="fragment">
If \(2.9 < \theta \le 4\),
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(Y_n \le 2.9|\theta) = \left( \frac{2.9}{\theta} \right)^n, \quad \mathbb{P}(Y_n\ge 4|\theta) = 0.
\end{align*}

</div>
<p class="fragment">
So in this case,
</p>
<div class="fragment">
\begin{align*}
  \pi(\theta|\delta) = \left( \frac{2.9}{\theta} \right)^n.
\end{align*}

</div>

</section>
<section>
<p>
If \(\theta > 4\),
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(Y_n \le 2.9|\theta) = \left( \frac{2.9}{\theta} \right)^n, \quad \mathbb{P}(Y_n\ge 4|\theta) = 1 - \left( \frac{4}{\theta} \right)^n.
\end{align*}

</div>
<p class="fragment">
So in this case,
</p>
<div class="fragment">
\begin{align*}
  \pi(\theta|\delta) = \left( \frac{2.9}{\theta} \right)^n + 1 - \left( \frac{4}{\theta} \right)^n.
\end{align*}

</div>

<div id="org533a4f1" class="figure">
<p><img src="../img/math4750/fig9-2.png" alt="fig9-2.png" class="fragment middle" width="80%" />
</p>
</div>

</section>
<section>
<p>
The size of \(\delta\):
</p>
<div class="fragment">
\begin{align*}
  \alpha(\delta) = \sup_{3\le \theta \le 4}\pi(\theta|\delta) = \pi(3|\delta) = \left( \frac{29}{30} \right)^n.
\end{align*}

</div>

<p class="fragment">
In particular, if the sample size \(n=68\), then the size of \(\delta\) is
</p>
<div class="fragment">
\begin{align*}
  \left( \frac{29}{30} \right)^{68} = 0.0997,
\end{align*}

</div>
<p class="fragment">
and so \(\delta\) is a level \(\alpha_0\) test for every level of significance
</p>
<div class="fragment">
\begin{align*}
  \alpha_0 \ge 0.0997.
\end{align*}

</div>
</section>
</section>
<section>
<section id="slide-orgc827a8c">
<h4 id="orgc827a8c">Making a Test Have a Specific Significance Level</h4>
<p>
<span style="color: rgb(24,116,205)">Example 9.1.8</span>
In Example 9.1.5, our test is
</p>
<div class="fragment">
\begin{align*}
  \text{reject} ~ H_0: \mu = \mu_0 \quad \text{if}~ T = |\overline{X}_n - \mu_0| \ge c.
\end{align*}

</div>
<p class="fragment">
To specify this test is to specify the value of \(c\).
</p>

<p class="fragment">
Now suppose we desire our test to have the level of significance \(\alpha_0\). That is,
</p>
<div class="fragment">
\begin{align*}
  \sup_{\theta\in \Omega_0} \pi(\theta|\delta) = \sup_{\theta\in \Omega_0} \mathbb{P}(T\ge c|\theta) \le \alpha_0.
\end{align*}

</div>

<p class="fragment">
Since the null hypothesis here is <b>simple</b>, the above inequality becomes
</p>
<div class="fragment">
\begin{align*}
    \mathbb{P}(|\overline{X}_n-\mu_0|\ge c |\mu_0) \le \alpha_0.
\end{align*}

</div>

</section>
<section>
<p>
Also we have \(\overline{X}_n \sim \mathcal{N}(\mu_0, \sigma^2/n)\), so we can find a value of \(c\) that makes the size of the test exactly \(\alpha_0\) for each \(\alpha_0\).
</p>
<div class="fragment">
\begin{align*}
    \mathbb{P}(|\overline{X}_n-\mu_0|\ge c |\mu_0) & = \mathbb{P}\left(\left| \frac{\overline{X}_n-\mu_0}{\sigma/\sqrt{n}}\right| \ge \frac{c}{\sigma/\sqrt{n}}\bigg|\mu_0 \right)\\
& = \mathbb{P}(|Z|\ge \sqrt{n}c/\sigma) = 2 \Phi(-\sqrt{n}c/\sigma) = 2 - 2 \Phi(\sqrt{n}c/\sigma),
\end{align*}

</div>
<p class="fragment">
where \(Z\sim \mathcal{N}(0, 1)\), and \(\Phi\) is the C.D.F. of \(Z\).
</p>

<div id="org0c82fd4" class="figure">
<p><img src="../img/math4750/fig9-3.png" alt="fig9-3.png" class="fragment middle" width="45%" />
</p>
</div>


</section>
<section>
<p>
In other words, we need
</p>
<div class="fragment">
\begin{align*}
  2 - 2 \Phi(\sqrt{n}c/\sigma)  = \alpha_0,
\end{align*}

</div>
<p class="fragment">
which gives
</p>
<div class="fragment">
\begin{align*}
  c = \frac{\sigma \Phi^{-1}(1 - \alpha_0/2)}{\sqrt{n}}.
\end{align*}

</div>
<p class="fragment">
Therefore, the desired test is
</p>
<div class="fragment">
\begin{align*}
  \text{reject} ~ H_0: \mu = \mu_0 \quad \text{if}~ |Z| \ge \Phi^{-1}(1 - \alpha_0/2),
\end{align*}

</div>
<p class="fragment">
where \(Z = \sqrt{n}(\overline{X}_n - \mu_0)/\sigma\).
</p>

</section>
</section>
<section>
<section id="slide-orgb4cfedc">
<h4 id="orgb4cfedc">Example 9.1.10</h4>
<p>
In Example 9.1.8, suppose that we choose to test the null hypothesis at level \(\alpha_0 = 0.05\).
</p>
<p class="fragment">
Then
</p>
<div class="fragment">
\begin{align*}
  \Phi^{-1}(1- 0.05/2) = 1.96.
\end{align*}

</div>
<p class="fragment">
So the test is
</p>
<div class="fragment">
\begin{align*}
  \text{reject} ~ H_0: \mu = \mu_0 \quad \text{if}~ |Z| \ge 1.96.
\end{align*}

</div>

<p class="fragment">
<span style="color: rgb(24,116,205)">Question</span>: Any issues with the result of this test?
</p>

<p class="fragment">
Please read about the <i>\(p\) value</i> up to Example 9.1.12.
</p>

</section>
</section>
<section>
<section id="slide-org8d733f5">
<h3 id="org8d733f5">9.2 Testing Simple Hypotheses</h3>
<p>
The simplest hypothesis-testing situation is that in which there are only two possible values of the parameter.
</p>

<p class="fragment">
In such cases, it is possible to identify a collection of test procedures that have certain optimal properties.
</p>

</section>
</section>
<section>
<section id="slide-org66d46a3">
<h4 id="org66d46a3">Example 9.2.1</h4>
<p>
In Example 3.7.5, we modeled the service times \(\vec{X} = (X_1, \dots, X_n)\) of \(n\) customers in a queue having the joint p.d.f.
</p>
<div class="fragment">
\begin{align*}
  f_1(\vec{x}) = \begin{cases}
\frac{2(n!)}{\left( 2+ \sum_{i=1}^n x_i \right)^{n+1}}, & \mbox{for all}~x_i>0,\\
0, & \mbox{otherwise}.
\end{cases}
\end{align*}

</div>
<p class="fragment">
Another model using the exponential distribution is proposed:
</p>
<div class="fragment">
\begin{align*}
  f_0(\vec{x}) = \begin{cases}
    \frac{1}{2^n} \exp\left(- \frac{1}{2} \sum_{i=1}^n x_i \right), & \mbox{for all}~x_i>0,\\
    0, & \mbox{otherwise}.
\end{cases}
\end{align*}

</div>


<p class="fragment">
<span style="color: rgb(24,116,205)">Question</span>:
</p>
<p class="fragment">
If the manager observes several service times, how can she test which of the two distributions appears to describe the data?
</p>

</section>
<section>
<p>
In general, we assume
</p>
<div class="fragment">
\begin{align*}
  \vec{X} = (X_1, \dots, X_n) \sim f_0(\vec{x}) \, \text{or} \, f_1(\vec{x}).
\end{align*}

</div>
<p class="fragment">
In this case, we  use the notation
</p>
<div class="fragment">
\begin{align*}
  \Omega = \{\theta_0, \theta_1\},
\end{align*}

</div>
<p class="fragment">
for the parameter space, where
</p>
<div class="fragment">
\begin{align*}
  \theta = \theta_i \, \text{means }
 \vec{X} \sim f_i(\vec{x})  \, \text{for }  i = 0, 1.
\end{align*}

</div>
<p class="fragment">
Then we are interested in testing the following simple hypotheses:
</p>
<div class="fragment">
\begin{align*}
  &H_0: \theta = \theta_0,\\
  &H_1: \theta = \theta_1.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org0b634d6">
<h4 id="org0b634d6">The Two Types of Errors</h4>
<p>
We denote by
</p>
<div class="fragment">
\begin{align*}
  \alpha(\delta) & = \mathbb{P}(\text{reject } H_0 |\theta = \theta_0 ),\\
  \beta(\delta) & = \mathbb{P}(\text{not reject } H_0 |\theta = \theta_1 ).
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org7835dac">
<h4 id="org7835dac">Example 9.2.2</h4>
<p>
Below are the two p.d.f.&rsquo;s for the case of \(n=1\) in Example 9.2.1.
</p>
<div class="fragment">
\begin{align*}
  f_1(x) & = \begin{cases}
\frac{2}{\left( 2+ x \right)^2}, & \mbox{for}~x>0,\\
0, & \mbox{otherwise}.
\end{cases}, \\
  f_0(x) & = \begin{cases}
    \frac{1}{2} \exp\left( -\frac{1}{2} x \right), & \mbox{for all}~x_i>0,\\
    0, & \mbox{otherwise}.
\end{cases}
\end{align*}

</div>

<p class="fragment">
<span style="color: rgb(24,116,205)">Question</span>: If the manager observes one service time, \(X_1\). What is a reasonable test?
</p>

</section>
</section>
<section>
<section id="slide-org0b563ed">
<h4 id="org0b563ed">Example 9.2.2 - Continued</h4>
<p>
The figure below shows two p.d.f.&rsquo;s for the case of \(n=1\) in Example 9.2.1.
</p>

<div id="org3335e95" class="figure">
<p><img src="../img/math4750/fig9-5.png" alt="fig9-5.png" class="fragment middle" width="65%" />
</p>
</div>

</section>
</section>
<section>
<section id="slide-org6824120">
<h4 id="org6824120">Example 9.2.2 - Continued</h4>
<p>
Assume the test that she chooses is
</p>
<div class="fragment">
\begin{align*}
  \text{reject} \, H_0, \, \text{if} ~X_1 \ge 4.
\end{align*}

</div>

<p class="fragment">
Please compute the type I and type II error probabilities for this test.
</p>
<div class="fragment">
\begin{align*}
  f_1(x) & = \begin{cases}
\frac{2}{\left( 2+ x \right)^2}, & \mbox{for}~x>0,\\
0, & \mbox{otherwise}.
\end{cases}, \\
  f_0(x) & = \begin{cases}
    \frac{1}{2} \exp\left( -\frac{1}{2} x \right), & \mbox{for all}~x_i>0,\\
    0, & \mbox{otherwise}.
\end{cases}
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orgd47e106">
<h4 id="orgd47e106">Example 9.2.2 - Continued</h4>
<p>
<i>Solution</i>
</p>
<p class="fragment">
To compute \(\alpha(\delta)\), we assume \(\theta= \theta_0\), i.e., use \(f_0\) as the p.d.f. of \(X_1\):
</p>
<div class="fragment">
\begin{align*}
  \alpha(\delta) & = \mathbb{P}(X_1 \ge 4|\theta_0)\\
& = e^{-0.5 \cdot 4} = 0.135.
\end{align*}

</div>
<p class="fragment">
To compute \(\beta(\delta)\), we assume \(\theta= \theta_1\), i.e., use \(f_1\) as the p.d.f. of \(X_1\):
</p>
<div class="fragment">
\begin{align*}
  \beta(\delta) & = \mathbb{P}(X_1 < 4|\theta_1)\\
& = \int_0^4 \frac{2}{(2+x)^2}\, dx = \frac{2}{3}=0.667.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org80b41c4">
<h4 id="org80b41c4">Minimizing a Linear Combination</h4>
<p>
<span style="color: rgb(24,116,205)">Theorem 9.2.1</span>
</p>
<p class="fragment">
Suppose \(a\) and \(b\) are specified positive constants. Let \(\delta^\ast\) denote a test such that the hypothesis \(H_0\) is not rejected if \(a f_0(\vec{x})> b f_1(\vec{x})\) and the hypothesis \(H_0\) is rejected if \(a f_0(\vec{x})< b f_1(\vec{x})\). The null hypothesis \(H_0\) can be either rejected or not if \(a f_0(\vec{x}) = b f_1(\vec{x})\).
</p>
<p class="fragment">
Then for every other test \(\delta\),
</p>
<div class="fragment">
\begin{align*}
  a \alpha(\delta^\ast) + b \beta(\delta^\ast) \le a \alpha(\delta) + b \beta(\delta).
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org78395c5">
<h4 id="org78395c5">Proof</h4>
<p>
For simplicity, we assume that the samples follow a <b>discrete</b> distribution.
</p>

<p class="fragment">
Let \(S_1\) be the critical region, so if \(\vec{x}\in S_1\), then reject \(H_0\); if \(\vec{x}\in S_1^C=S_0\), then not reject \(H_0\).
</p>
<div class="fragment">
\begin{align*}
  a \alpha(\delta) + b \beta(\delta)
& = a \sum_{\vec{x} \in S_1} f_0(\vec{x}) + b \sum_{\vec{x}\in S_0} f_1(\vec{x})\\
& = a\sum_{\vec{x} \in S_1} f_0(\vec{x}) + b \left( 1 - \sum_{\vec{x}\in S_1} f_1(\vec{x})\right)\\
& = b + \sum_{\vec{x}\in S_1} \left[ a f_0(\vec{x}) - bf_1(\vec{x}) \right].
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org338977e">
<h4 id="org338977e">Proof - Continued</h4>
<p>
Now note that to specify a test \(\delta^\ast\) is equivalent to choosing \(S_1\).
</p>
<p class="fragment">
In order to minimize the linear combination \(\alpha(\delta) + b \beta(\delta)\), we choose
</p>
<div class="fragment">
\begin{align*}
  S_1 = \{\vec{x}: a f_0(\vec{x}) < bf_1(\vec{x})\}.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orga17f83e">
<h4 id="orga17f83e">Likelihood Ratio</h4>
<p>
If we define by \(f_1(\vec{x})/f_0(\vec{x})\), the <i>likelihood ratio</i> of the sample, then Theorem 9.2.1 can be reworded as follows.
</p>

<p class="fragment">
<span style="color: rgb(24,116,205)">Corollary 9.2.1</span>
</p>
<p class="fragment">
Assume the condition of Theorem 9.2.1, and assume that \(a>0\) and \(b>0\). Then the test \(\delta\) for which the value of \(a\alpha(\delta)+ b \beta(\delta)\) is a minimum rejects \(H_0\) when the likelihood ratio exceeds \(a/b\) and does not reject \(H_0\) when the likelihood ratio is less than \(a/b\).
</p>

</section>
</section>
<section>
<section id="slide-orgb6bb78c">
<h4 id="orgb6bb78c">Example 9.2.3</h4>
<p>
Instead of rejecting \(H_0\) if \(X_1 \ge 4\) in Example 9.2.2, the manager could apply Theorem 9.2.1.
</p>
<p class="fragment">
Suppose that she chooses the test such that it rejects \(H_0\) if \(f_1(x_1)/f_0(x_1)>1\). That is, if
</p>
<div class="fragment">
\begin{align*}
  \frac{4}{(2+x_1)^2}\exp \left( \frac{x_1}{2} \right)>1.
\end{align*}

</div>
<p class="fragment">
By numerical approximation, we solve the inequality above and obtain
</p>
<div class="fragment">
\begin{align*}
  x_1 > 5.025725.
\end{align*}

</div>
</section>
</section>
<section>
<section id="slide-org0a4d7a0">
<h4 id="org0a4d7a0">Example 9.2.3 - Continued</h4>
<p>
Then
</p>
<div class="fragment">
\begin{align*}
  \alpha(\delta^\ast) & = 1 - F_0(5.025725) = \exp(-2.513) = 0.081,\\
\beta(\delta^\ast) & = F_1(5.025725) = 1 - \frac{2}{7.026} = 0.715,
\end{align*}

</div>
<p class="fragment">
and
</p>
<div class="fragment">
\begin{align*}
  \alpha(\delta^\ast) + \beta(\delta^\ast) = 0.796 < 0.802,
\end{align*}

</div>
<p class="fragment">
where the latter is the sum of the two error probabilities in Example 9.2.2.
</p>
<p class="fragment">
In this sense, the test that rejects \(H_0\) if \(X_1 > 5.025725\) is better than the test that rejects \(H_0\) if \(X_1 \ge 4\).
</p>

</section>
</section>
<section>
<section id="slide-orgd4d3012">
<h4 id="orgd4d3012">Example</h4>
<p>
Suppose \(\vec{X} = (X_1, \dots, X_n)\) ia a random sample from \(\mathcal{N}(\mu, \sigma^2)\), with unknown mean \(\mu\) but known variance \(\sigma^2=1\).
</p>

<p class="fragment">
Hypotheses to be tested:
</p>
<div class="fragment">
\begin{align*}
  H_0: \quad \mu = 0,\\
  H_1: \quad \mu = 1.
\end{align*}

</div>

<p class="fragment">
Determine the test \(\delta_0\) for which the value of \(2\alpha(\delta_0) + \beta(\delta_0)\) is a minimum.
</p>

</section>
</section>
<section>
<section id="slide-orgb9d2855">
<h4 id="orgb9d2855">Example - Continued</h4>
<p class="fragment">
When \(H_0\) is true, the joint p.d.f. is
</p>
<div class="fragment">
\begin{align*}
  f_0(\vec{x}) = \frac{1}{(2\pi)^{n/2}} \exp \left( -\frac{1}{2} \sum_{i=1}^n x_i^2 \right);
\end{align*}

</div>
<p class="fragment">
When \(H_1\) is true, the joint p.d.f. is
</p>
<div class="fragment">
\begin{align*}
  f_1(\vec{x}) = \frac{1}{(2\pi)^{n/2}} \exp \left( -\frac{1}{2} \sum_{i=1}^n (x_i-1)^2 \right).
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orgc1d8fba">
<h4 id="orgc1d8fba">Example - Continued</h4>
<p>
The likelihood ration is
</p>
<div>
\begin{align*}
  \frac{f_1(\vec{x})}{f_0(\vec{x})}
& = \frac{\exp \left( -\frac{1}{2} \sum_{i=1}^n x_i^2 \right)}{\exp \left( -\frac{1}{2} \sum_{i=1}^n (x_i-1)^2 \right)} = e^{\sum_{i=1}^n [x_i^2 - (x_i-1)^2]}\\
& = e^{\sum_{i=1}^n (2x_i -1)} = e^{2 \sum_{i=1}^n x_i -n}\\
& = e^{2n\cdot \overline{x}_n -n} = e^{n(2 \overline{x}_n - 1)}.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org41e05ef">
<h4 id="org41e05ef">Example - Continued</h4>
<p>
Then by Corollary 9.2.1, the desired test \(\delta_0\) rejects \(H_0\) if
</p>
<div class="fragment">
\begin{align*}
  \frac{f_1(\vec{x})}{f_0(\vec{x})} > 2,
\end{align*}

</div>
<p class="fragment">
which is equivalent to
</p>
<div class="fragment">
\begin{align*}
 \overline{X}_n > k' = \frac{1}{2} + \frac{1}{n}\log 2.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org8437b83">
<h4 id="org8437b83">Example - Continued</h4>
<p>
For example, if \(n=9\), the optimal test \(\delta_0\) rejects \(H_0\) when \(\overline{X}_n > 0.577\).
</p>
<p class="fragment">
Therefore,
</p>
<div class="fragment">
\begin{align*}
  \alpha(\delta_0) & = \mathbb{P}(\overline{X}_n> 0.577|\mu =0)\\
& = 1 - \Phi \left( \frac{0.577  - 0}{1/3} \right) = 1 - \Phi(1.731) = 0.0417.
\end{align*}

</div>
<div class="fragment">
\begin{align*}
  \beta(\delta_0) & = \mathbb{P}(\overline{X}_n< 0.577|\mu =1)\\
& = \Phi \left( \frac{0.577  - 1}{1/3} \right) = \Phi(-1.269) = 0.1022.
\end{align*}

</div>
<p class="fragment">
The minimum value of the linear combination is
</p>
<div class="fragment">
\begin{align*}
  2\alpha(\delta_0) + \beta(\delta_0) = 2(0.0417)+0.1022=0.1856.
\end{align*}

</div>


</section>
</section>
<section>
<section id="slide-orgf913f38">
<h4 id="orgf913f38">Neyman-Pearson Lemma</h4>
<p>
Next, we consider another type of optimal tests where the probability \(\alpha(\delta)\) is upper bounded, and we seek a test \(\delta\) for which \(\beta(\delta)\) will be minimized.
</p>

<p class="fragment">
<span style="color: rgb(24,116,205)">Theorem 9.2.2</span>
</p>
<p class="fragment">
Suppose that \(\delta'\) is a test that has the following form for some constant \(k>0\):
</p>
<div class="fragment">
\begin{align*}
  \text{not reject } H_0, & \text{ if } f_1(\vec{x})< kf_0(\vec{x}),\\
\text{reject } H_0, & \text{ if } f_1(\vec{x}) > k f_0(\vec{x}),\\
\text{undetermined}, & \text{ if }f_1(\vec{x}) = k f_0(\vec{x}).
\end{align*}

</div>
<p class="fragment">
If \(\delta\) is another test, then
</p>
<div class="fragment">
\begin{align*}
  \alpha(\delta) \le \alpha(\delta') & \Longrightarrow \beta(\delta) \ge \beta(\delta'),\\
  \alpha(\delta) < \alpha(\delta') & \Longrightarrow \beta(\delta) > \beta(\delta').
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org6a99c59">
<h4 id="org6a99c59">Proof</h4>
<p class="fragment">
Apply Theorem 9.2.1 and set \(a=k, b = 1\), we have
</p>
<div class="fragment">
\begin{align*}
  k \alpha(\delta') + \beta(\delta') \le k \alpha(\delta) + \beta(\delta).
\end{align*}

</div>
<p class="fragment">
If \(\alpha(\delta) \le \alpha(\delta')\), the we must have \(\beta(\delta)\ge \beta(\delta')\).
</p>

</section>
<section>
<p>
<span style="color: rgb(24,116,205)">Question</span>: How to make use of the Neyman-Pearson lemma?
</p>

<p class="fragment">
Suppose our goal is to find a test for which \(\alpha(\delta) = \alpha_0\), and \(\beta(\delta)\) is a minimum.
</p>

<p class="fragment">
According to the lemma, you only need to find a value of \(k\) for which
</p>
<div class="fragment">
\begin{align*}
  \alpha(\delta') = \alpha_0.
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-orgfc0c92f">
<h4 id="orgfc0c92f">Example 9.2.5</h4>
<p>
Suppose \(\vec{X} = (X_1, \dots, X_n)\) ia a random sample from \(\mathcal{N}(\mu, \sigma^2)\), with unknown mean \(\mu\) but known variance \(\sigma^2=1\).
</p>

<p class="fragment">
Hypotheses to be tested:
</p>
<div class="fragment">
\begin{align*}
  H_0: \quad \mu = 0,\\
  H_1: \quad \mu = 1.
\end{align*}

</div>

<p class="fragment">
Find a test \(\delta\) to minimize \(\beta(\delta)\) such that \(\alpha(\delta)\le 0.05\).
</p>

</section>
</section>
<section>
<section id="slide-orgfa75497">
<h4 id="orgfa75497">Example 9.2.5 - Continued</h4>
<p>
The likelihood ratio is
</p>
<div class="fragment">
\begin{align*}
  \frac{f_1(\vec{x})}{f_0(\vec{x})}
& = \frac{\exp \left( -\frac{1}{2} \sum_{i=1}^n x_i^2 \right)}{\exp \left( -\frac{1}{2} \sum_{i=1}^n (x_i-1)^2 \right)} = e^{\sum_{i=1}^n [x_i^2 - (x_i-1)^2]}\\
& = e^{\sum_{i=1}^n (2x_i -1)} = e^{2 \sum_{i=1}^n x_i -n}\\
& = e^{2n\cdot \overline{x}_n -n} = e^{n(2 \overline{x}_n - 1)}.
\end{align*}

</div>
<p class="fragment">
Then
</p>
<div class="fragment">
\begin{align*}
  \frac{f_1(\vec{x})}{f_0(\vec{x})} > k \Longleftrightarrow \overline{x}_n > k',
\end{align*}

</div>
<p class="fragment">
where \(k' = 1/2 + 1/2 \cdot \log k\).
</p>

</section>
</section>
<section>
<section id="slide-org886fa19">
<h4 id="org886fa19">Example 9.2.5 - Continued</h4>
<p>
Suppose that we can find a value of \(k'\) such that
</p>
<div>
\begin{align*}
  \mathbb{P}(\overline{X}_n > k' |\mu = 0) = 0.05.
\end{align*}

</div>
<p class="fragment">
Then the test \(\delta'\), which rejects \(H_0\) when \(\overline{X}_n > k'\), will satisfy \(\alpha(\delta') = 0.05\).
</p>

<p class="fragment">
Now it suffices to find \(k'\).
</p>
<p class="fragment">
In fact,
</p>
<div class="fragment">
\begin{align*}
  \overline{X}_n | \mu =0 \sim \mathcal{N}(0, 1/n).
\end{align*}

</div>

</section>
</section>
<section>
<section id="slide-org1c213c7">
<h4 id="org1c213c7">Example 9.2.5 - Continued</h4>
<p>
In other words,
</p>
<div class="fragment">
\begin{align*}
  \mathbb{P}(\overline{X}_n > k' |\mu = 0) = \mathbb{P}(Z > \sqrt{n} \cdot k') = 0.05,
\end{align*}

</div>
<p class="fragment">
and thus
</p>
<div class="fragment">
\begin{align*}
  1 - \Phi(\sqrt{n} \cdot k') = 0.05.
\end{align*}

</div>
<p class="fragment">
So
</p>
<div class="fragment">
\begin{align*}
  k' =\frac{\Phi^{-1}(0.95)}{\sqrt{n}} = \frac{1.645}{\sqrt{n}}.
\end{align*}

</div>

<p class="fragment">
In summary, among all tests for which \(\alpha(\delta) \le 0.05\), the test \(\delta'\) that rejects \(H_0\) when \(\overline{X}_n>1.645 n^{-1/2}\) has the smallest probability of type II error.
</p>

</section>
</section>
<section>
<section id="slide-org6e19a31">
<h4 id="org6e19a31">Example 9.2.5 - Continued</h4>
<p>
<span style="color: rgb(24,116,205)">Question</span>: What is this smallest \(\beta(\delta')\)?
</p>

<p class="fragment">
Recall that
</p>
<div class="fragment">
\begin{align*}
  \beta(\delta') = \mathbb{P}(\overline{X}_n < 1.645 n^{-1/2}|\mu =1).
\end{align*}

</div>

<p class="fragment">
Given \(\mu = 1\), we have \(\overline{X}_n | \mu =1 \sim \mathcal{N}(1, 1/n)\).
</p>
<p class="fragment">
Thus,
</p>
<div class="fragment">
\begin{align*}
  \beta(\delta') = \Phi \left( \frac{1.645 n^{-1/2}-1}{n^{-1/2}} \right) = \Phi(1.645 - n^{1/2}).
\end{align*}

</div>

<p class="fragment">
For instance, when \(n=9\), we have
</p>
<div class="fragment">
\begin{align*}
  \beta(\delta') = \Phi(-1.355)= 1 - \Phi(1.355) = 0.0877.
\end{align*}

</div>
</section>
</section>
</div>
</div>
<script src="../dist/reveal.js"></script>
<script src="../plugin/markdown/markdown.js"></script>
<script src="../plugin/notes/notes.js"></script>
<script src="../plugin/search/search.js"></script>
<script src="../plugin/zoom/zoom.js"></script>
<script src="../plugin/reveal.js-menu/menu.js"></script>
<script src="../reveal.js-plugins/chalkboard/plugin.js"></script>
<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

controls: true,
progress: true,
history: false,
center: true,
slideNumber: false,
rollingLinks: false,
keyboard: true,
mouseWheel: false,
fragmentInURL: false,
hashOneBasedIndex: false,
pdfSeparateFragments: true,
overview: true,

transition: 'none',
transitionSpeed: 'default',

// Plugins with reveal.js 4.x
plugins: [ RevealMarkdown, RevealNotes, RevealSearch, RevealZoom, RevealMenu, RevealChalkboard ],

// Optional libraries used to extend reveal.js
dependencies: [
]

,chalkboard: {src: "chalkboard/chalkboard.json", storage: "chalkboard-demo", toggleChalkboardButton: { left: "80px" },	toggleNotesButton: { left: "130px" },	colorButtons: 5}});
</script>
</body>
</html>
